title,score,id,url,comms_num,created,body,timestamp
Use a custom ckpt file for dreamfusion?,2,ydpptd,https://www.reddit.com/r/StableDiffusion/comments/ydpptd/use_a_custom_ckpt_file_for_dreamfusion/,0,1666761351.0,"I'm looking for a way to turn my art made from a personally trained dream booth model into 3D, I know dreamfusion can do the 3D, but am wondering how to use my own ckpt file, or if there's a good alternative. IMG to IMG rotating? and then use photogrammetry?",2022-10-26 01:15:51
Cat Escapes Mirror Dimension,2,ydphr7,https://i.redd.it/1hms2z7e13w91.jpg,1,1666760586.0,,2022-10-26 01:03:06
Running a video through img2img frame by frame gives very interesting results,1,ydpahq,https://youtu.be/JlO02se5Yw8,0,1666759912.0,,2022-10-26 00:51:52
Are there AI Model Commissions?,2,ydp6r5,https://www.reddit.com/r/StableDiffusion/comments/ydp6r5/are_there_ai_model_commissions/,0,1666759559.0,"Bit of a weird question, but do people take commissions for developing models for SD? I was gearing up to make my own when the thought occurred to me. 

Example:
I want models that can consistently and accurately draw Transformers. Is there someone who would give me a list of image requirements, take the necessary images and info from me, and use them to make models that meet my needs? (Ideally a single model that could draw a bunch of different transformers and relevant settings if I used in-painting or something. Better still if it could generate art with a consistent style, even if the references aren’t in that style...)

Is this a thing? I was planning to learn how to do it myself, so it’s no big deal if not, but I wanted to ask just in case. Searching this subreddit didn’t seem to help me find anything of the sort…",2022-10-26 00:45:59
Medium Format Film Portraits,0,ydp2d3,https://www.reddit.com/gallery/ydp2d3,0,1666759151.0,,2022-10-26 00:39:11
"wallpapers, men(and women) in black",0,ydp040,https://www.reddit.com/gallery/ydp040,1,1666758931.0,,2022-10-26 00:35:31
Stock image companies checking for AI generated art,37,ydoy1k,https://i.redd.it/c9nosqvwv2w91.jpg,3,1666758734.0,,2022-10-26 00:32:14
"Dreambooth Google Colab, help passing int args to !accelerate launch train_dreambooth.py",1,ydovd1,https://www.reddit.com/r/StableDiffusion/comments/ydovd1/dreambooth_google_colab_help_passing_int_args_to/,0,1666758488.0,"I am trying to add a markup param for the seed but I keep getting this error

`--seed: invalid int value: ''`

&#x200B;

I have other markup paramaters being sent as args only integers don't seem to work.

Here is the code I used to make the variable

`AiSeed = 420 #@param {type:""number""}`

I've also tried 

`AiSeed = 420 #@param {type:""integer""}`

Here is my config, I'm expecting other Integers not to work as well with the current method

`!accelerate launch train_dreambooth.py \`  
  `--pretrained_model_name_or_path=$TrainingModelName \`  
  `--pretrained_vae_name_or_path=""stabilityai/sd-vae-ft-mse"" \`  
  `--instance_data_dir=$INSTANCE_DIR \`  
  `--class_data_dir=$CLASS_DIR \`  
  `--output_dir=$OUTPUT_DIR \`  
  `--with_prior_preservation --prior_loss_weight=1.0 \`  
  `--instance_prompt=$Prompt \`  
  `--class_prompt=$CLASS_NAME \`  
  `--seed=$AiSeed \`  
  `--resolution=$ImgResolution \`  
  `--train_batch_size=1 \`  
  `--train_text_encoder \`  
  `--mixed_precision=""fp16"" \`  
  `--use_8bit_adam \`  
  `--gradient_accumulation_steps=1 \`  
  `--learning_rate=1e-6 \`  
  `--lr_scheduler=""constant"" \`  
  `--lr_warmup_steps=0 \`  
  `--num_class_images=$ClassImgCount \`  
  `--sample_batch_size=4 \`  
  `--max_train_steps=$MaxSteps \`  
  `--save_interval=$SaveInterval \`  
  `--gradient_checkpointing`

Does anyone know the proper way to pass int arguments to accelerate?

I've also tried

`f""{AiSeed}""`

`""{AiSeed}""`",2022-10-26 00:28:08
Thought I Finally Successfully Installed SD...But I See NEW Errors,2,ydomgy,https://www.reddit.com/gallery/ydomgy,1,1666757668.0,,2022-10-26 00:14:28
"Need inspiration for another Sci-fi game, look no further !",1,ydolpg,https://www.reddit.com/gallery/ydolpg,0,1666757602.0,,2022-10-26 00:13:22
hi i'm messing with stable-dreamfusion. wondering about the seed input.,1,ydofq4,https://www.reddit.com/r/StableDiffusion/comments/ydofq4/hi_im_messing_with_stabledreamfusion_wondering/,0,1666757054.0,"I've gotten some really interesting and novel 3d models from both stable-dreamfusion and dreamfields-3D.  but they aren't quite satisfactory enough to be significant or useable.  

there is a seed input for stable-dreamfusion... I am wondering, can I feed it a seed from any stable diffusion render and it then goes off of that?  or is the seeds in stable dreamfusion native only to itself?

I know its looking up the text prompt and rendering the 3d from that, but i would like to guide it a little better since the prompts i am using seem to have some variety that messes up the single 3d render.

I tried feeding images to dreamfields through their image input but really i must say after quite a few days its all so close to being presentable but has a big element of gobbledy gook.

I see people are rendering some nice looking coherent stuff, I was just wondering if anybody was aware of the seed input and if I can just enter any seed from stable diffusion and it will start from that image?  

I have alot to learn, but thought i would ask- thanks",2022-10-26 00:04:14
"""Sunblind in the Shadowseed""",2,ydoegc,https://i.redd.it/gtixcbkdq2w91.png,0,1666756937.0,,2022-10-26 00:02:17
Quick Tips - XY Plot Script,3,ydod83,https://youtu.be/EoO9GZevkEk,0,1666756836.0,,2022-10-26 00:00:36
Tried Canva Text to Image feature currently in Beta https://www.canva.com/apps/text-to-image-(beta).,1,ydo97m,https://i.redd.it/8hp3g870p2w91.png,0,1666756471.0,,2022-10-25 23:54:31
Quick Drop in SD API I can run on my machine or the cloud?,1,ydo2au,https://www.reddit.com/r/StableDiffusion/comments/ydo2au/quick_drop_in_sd_api_i_can_run_on_my_machine_or/,0,1666755861.0,"Looking for low cost self hosted DP API, I'll reckon I can find something like that but maybe one of you guys knows a really good option?",2022-10-25 23:44:21
Could a kinda soul point me to the direction of a colab that uses the 1.5 model? I don't have a good computer to run locally and has only been using colabs..,1,ydo1ph,https://www.reddit.com/r/StableDiffusion/comments/ydo1ph/could_a_kinda_soul_point_me_to_the_direction_of_a/,5,1666755807.0,Title. I have some copied to my drive that now seem obsolete. Anyone know a good recent one to go to atm?,2022-10-25 23:43:27
Highres Fix. Firstpass Width and Height?,2,ydnxn1,https://www.reddit.com/r/StableDiffusion/comments/ydnxn1/highres_fix_firstpass_width_and_height/,1,1666755450.0,"I've searched online for a while, read Automatic1111's Features (light) manual.
I just have no idea what those mean or how to use it well. Most of the time, if sd is generating something pretty, highres then comes and changes it to something lame :(
If SD is generating a human hydra however, then it stays a human hydra even after the fix.

On the other hand, I just noticed the firstpass width and height thing, so I assume it's because I left it empty.

Heeeelp please!",2022-10-25 23:37:30
The Scream Of Shrek Artwork By Georges De La Tour,1,ydnxdl,https://www.youtube.com/watch?v=kLYFyFB44tc,0,1666755430.0,,2022-10-25 23:37:10
Narures' Beauty 🦌Generated w/SD'S Beta Site,3,ydnsas,https://www.reddit.com/gallery/ydnsas,1,1666754991.0,,2022-10-25 23:29:51
War ducks. Portraits,17,ydnomm,https://www.reddit.com/gallery/ydnomm,2,1666754662.0,,2022-10-25 23:24:22
Save without retraining,1,ydnmuy,https://www.reddit.com/r/StableDiffusion/comments/ydnmuy/save_without_retraining/,0,1666754503.0,"Greetings, 

I am new to stable diffusion and was wondering if you can save your notebook without retraining. I am running it on colab? 

Thanks in advance for your help",2022-10-25 23:21:43
"Anime guys to people, again. Today: Haikyuu first years",1,ydnlid,https://www.reddit.com/gallery/ydnlid,0,1666754393.0,,2022-10-25 23:19:53
enjoy,0,ydmvcd,https://youtu.be/iUWcPmkpRcA,0,1666752136.0,,2022-10-25 22:42:16
"Prompt to create ""3D Character""! Very flexible, can create simple character scenes. hope you enjoy it, and see you creations on PublicPrompts Discord :))",25,ydmn93,https://i.redd.it/mnrdjjzz92w91.png,1,1666751443.0,,2022-10-25 22:30:43
"I Used The Shivam Collab Last Week, Does That Mean My Model Is Based On 1.4?",0,ydmfag,https://www.reddit.com/r/StableDiffusion/comments/ydmfag/i_used_the_shivam_collab_last_week_does_that_mean/,0,1666750756.0,"Hey, I made a model of me using the Shivam Notebook, turned out pretty decent although I definitely want to improve it with more photos, experiment with higher res images, etc.

Anyway, because I made the model last week, does that mean if I want to make a new model based on v1.5 then I need to run my model again?

Thanks!",2022-10-25 22:19:16
Danny DeVito eating a steak,1,ydmf77,https://i.redd.it/v82rqfr682w91.jpg,0,1666750749.0,,2022-10-25 22:19:09
"I seen someone else do this on here, so I gave it a try. I only changed the name of the season in the prompt and it worked out pretty well. Winter is a bit off if you look at all the images on top of each other. In Krita I just copied and pasted the quarters and saved it.",6,ydmdjx,https://i.redd.it/dgkqmwe472w91.png,3,1666750614.0,,2022-10-25 22:16:54
Scott Steiner teaching math to Kindergarteners,5,ydm8pt,https://i.redd.it/0lzjcl6k62w91.jpg,3,1666750213.0,,2022-10-25 22:10:13
Dreamcore,2,ydm7q9,https://www.youtube.com/watch?v=88kx73SWE7c,0,1666750134.0,,2022-10-25 22:08:54
Prompt: Boris Johnson as a medieval peasant,5,ydlv7y,https://i.redd.it/q1k4cc6832w91.jpg,1,1666749096.0,,2022-10-25 21:51:36
A still of Homer Simpson in The Godfather (1972),2,ydlqmf,https://i.redd.it/foeytg7222w91.jpg,0,1666748707.0,,2022-10-25 21:45:07
DreamStudio Lite (beta) variations on a theme: Alternative Spocks,2,ydlpli,https://www.reddit.com/gallery/ydlpli,5,1666748616.0,Can you guess them all? :),2022-10-25 21:43:36
Stable Diffusion Posable Doll/Mannequin by Royal Skies released,2,ydl985,https://www.reddit.com/r/StableDiffusion/comments/ydl985/stable_diffusion_posable_dollmannequin_by_royal/,4,1666747251.0,"Link: https://www.artstation.com/marketplace/p/VOAyv/stable-diffusion-3d-posable-manekin-doll?utm_source=artstation&utm_medium=referral&utm_campaign=homepage&utm_term=marketplace
Video: https://www.youtube.com/watch?v=iPsX7z5imVY&ab_channel=RoyalSkies
I still find myself marveling at how fast all this is moving and advancing, even by my standards. This will probably help a lot with ensuring your images will look anatomically correct.",2022-10-25 21:20:51
Miles Davis in Latent Space,2,ydkxfs,https://i.redd.it/bt6qw5fvu1w91.jpg,1,1666746274.0,,2022-10-25 21:04:34
How to uninstall Stable Diffusion?,0,ydkvkn,https://www.reddit.com/r/StableDiffusion/comments/ydkvkn/how_to_uninstall_stable_diffusion/,6,1666746122.0,I Tried to install on D drive but it didnt work and I think it installed stuff on C,2022-10-25 21:02:02
PopStarWars,4,ydkti4,https://www.reddit.com/gallery/ydkti4,2,1666745970.0,,2022-10-25 20:59:30
Growth,18,ydkncy,https://i.imgur.com/sLgKkgF.jpg,1,1666745448.0,,2022-10-25 20:50:48
How to increase the value of the num_workers?,1,ydkd7l,https://www.reddit.com/r/StableDiffusion/comments/ydkd7l/how_to_increase_the_value_of_the_num_workers/,6,1666744628.0,"> Validation sanity check: 0it [00:00, ?it/s]C:\Users\chris.conda\envs\SD-Optimized\lib\site-packages\pytorch_lightning\trainer\data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the num_workers argument(try 20 which is the number of cpus on this machine) in theDataLoader` init to improve performance.

I have this message in Dreambooth. How exactly do I change the value of num workers? I keep googling looking and going around in a circle not finding anything direct. 

Thanks in advance for any help!",2022-10-25 20:37:08
"Ars Technica: Shutterstock partners with OpenAI to sell AI-generated artwork, compensate artists.",3,ydk9nw,https://arstechnica.com/information-technology/2022/10/shutterstock-partners-with-openai-to-sell-ai-generated-artwork-compensate-artists/,2,1666744331.0,,2022-10-25 20:32:11
Inktober Day 24 & 25 “Fairy & Tempting”,2,ydk467,https://www.reddit.com/gallery/ydk2td,1,1666743894.0,,2022-10-25 20:24:54
How many steps to train an embedding?,1,ydk269,https://www.reddit.com/r/StableDiffusion/comments/ydk269/how_many_steps_to_train_an_embedding/,1,1666743728.0,Has anyone done any tests on training embeddings in AUTOMATIC1111? How many steps does one need to get good results? is there a law of diminishing returns?,2022-10-25 20:22:08
Sugar and Pumpkin Spice and All Things Nice!,4,ydk0hl,https://i.redd.it/m3j2453em1w91.jpg,1,1666743592.0,,2022-10-25 20:19:52
Object placement by inpainting or Dreambooth or img2img blending,1,ydjzgz,https://www.reddit.com/r/StableDiffusion/comments/ydjzgz/object_placement_by_inpainting_or_dreambooth_or/,2,1666743508.0,"How can I place an object (e.g., a wine glass) in a scene (e.g., a family eating dinner on a dinner table) by drag and drop or by similar means where the placed object looks realistic? (correct shadows, light angles etc). I'm not talking about more complicated scenarios, e.g., taking a rolex watch and making someone wear it. Currently just trying to understand if it's a reasonable goal.

&#x200B;

I know recent inpainting model can do a pretty good job, but never seen anyone specifically use it for this.

  
My experimentation with Dreambooth was not successful: if I had a branded item (like a headphone with a specific text or logo on it), Dreambooth would ignore such details.

&#x200B;

I'm wondering if it is as simple as noising both object and the scene/image at different levels and adding them up, then denoising the composite. I didn't attempt this, because I know even if it'd be possible, there'll be very specific hyperparameters and I am really not good at that type of engineering.

&#x200B;

Any help, including similar literature not SD-based is appreciated!",2022-10-25 20:18:28
How can I use trained styles in Automatic1111?,0,ydjyho,https://www.reddit.com/r/StableDiffusion/comments/ydjyho/how_can_i_use_trained_styles_in_automatic1111/,0,1666743429.0,"So I've come across the huggingface dreambooth library. Now I'm wondering how to use the trained styles in automatic1111.  


I've discovered that if I find a checkpoint file and copy it to the 'models/Stable-Diffusion' directory, then the file will get picked up and I can swap it in in the web interface.  


However, for the style repos I can't find a checkpoint file.  


For example, this is the Herge Style repo:

[https://huggingface.co/sd-dreambooth-library/herge-style](https://huggingface.co/sd-dreambooth-library/herge-style)  


Navigating around the repo, I can't find a file with the suffix .pt or .chkpt.  


But there must be a trained model here somewhere, right?  


What am I not seeing?",2022-10-25 20:17:09
Deforum local + Nuke temporal smoothing + Topaz Video Enhance 2.6,1,ydjwpe,https://www.reddit.com/r/StableDiffusion/comments/ydjwpe/deforum_local_nuke_temporal_smoothing_topaz_video/,0,1666743288.0,"  


https://reddit.com/link/ydjwpe/video/h7jjuy8om1w91/player

Heyo! Temporal smoothing test for nice morphs.

Don't have the prompt anymore but if I recall it was something like ""Fashion, african art, liminal spaces, museum, surreal"" etc.

\- Local render with Deforum 0.4- Upsampled locally with FILM to 240 FPS- Then brought into NukeIndie to smooth it even more + general colors and sharpening- Then converted to 60 FPS- Then upscaled in Video Enhance 2.6 for final output! :)

If you have any questions let me know! :)",2022-10-25 20:14:48
Cinestill 5 0 D Candid Photographic Portrait By Helen Levitt Of A Feminine,2,ydjuww,https://www.youtube.com/watch?v=y7xryNjBRbQ,0,1666743138.0,,2022-10-25 20:12:18
Using a 3d artist reference doll as a base.,6,ydjtpu,https://www.reddit.com/r/StableDiffusion/comments/ydjtpu/using_a_3d_artist_reference_doll_as_a_base/,16,1666743040.0,"How hard would it be to transform a generic 3d artist reference doll into whatever character you want? What would be the workflow? I am attempting to do this in Auto1111 using inpainting with limited results. I can eventually wrangle it into generating a suit or a coat. But any outfit I generate remains gray, just like the 3d model. I feel like I'm going about it wrong. I'm a relative newbie, having only discovered Stable Diffusion last week. Any basic pointers would help. How do I go about this?

https://preview.redd.it/8kszi0udl1w91.jpg?width=1920&format=pjpg&auto=webp&s=af905e80612061615e66b7c7f5d624765d8bae2c",2022-10-25 20:10:40
The Alchemist's Workshop,14,ydjro1,https://www.reddit.com/gallery/ydjro1,2,1666742883.0,,2022-10-25 20:08:03
Creatures of the Sea - A1111 Deforum Test 2,3,ydjn8i,https://v.redd.it/c1d0uyfkj1w91,1,1666742527.0,,2022-10-25 20:02:07
heavy metal album cover with person wearing virtual reality goggles,3,ydjk9p,https://i.redd.it/45xqpj5wi1w91.png,0,1666742308.0,,2022-10-25 19:58:28
dcra_ia as Iron Man [Dreambooth+Img2Img],5,ydjjkd,https://www.reddit.com/gallery/ydjjkd,4,1666742250.0,,2022-10-25 19:57:30
"error with /huggingface/hub/models--openai--clip-vit-large-patch14, cant run SD",2,ydjdpw,https://www.reddit.com/r/StableDiffusion/comments/ydjdpw/error_with/,0,1666741761.0,"I am trying to run SD and keep getting this error: **FileNotFoundError: \[Errno 2\] No such file or directory: '/Users/x/.cache/huggingface/hub/models--openai--clip-vit-large-patch14/refs/main'**

did anyone else come across this? how did you resolve it? spent hours trying to resolve and no luck :( I tried to create the directory locally and then started getting this: 

*IsADirectoryError: \[Errno 21\] Is a directory: '/Users/x/.cache/huggingface/hub/models--openai--clip-vit-large-patch14/refs/main'*

would appreciate any help with this!!",2022-10-25 19:49:21
How do you turn off clip guidance?,1,ydj9sz,https://www.reddit.com/r/StableDiffusion/comments/ydj9sz/how_do_you_turn_off_clip_guidance/,1,1666741446.0,I am running stable diffusion using their official repo but I don’t see the ability to turn off clip guidance like you can on dream studio. Is there an argument I’m missing that allows you to do this? I’ve looked through the documentation but can’t find anything.,2022-10-25 19:44:06
Upscaling: how do I use Ultrasharp?,2,ydj6ri,https://www.reddit.com/r/StableDiffusion/comments/ydj6ri/upscaling_how_do_i_use_ultrasharp/,1,1666741205.0,"I keep seeing posts about using Ultrasharp or other models to upscale images. I downloaded it and it's all PTH files and not CTKP.

When I look around, everybody is being vague as hell about how to use this. ""Just download the model and put it in the folder."" ""Go to img2img and select it.""

It's not showing up in the webUI and it came with no readme. 

How do I use this?",2022-10-25 19:40:05
How to merge checkpoints in Automattic1111?,1,ydj46v,https://www.reddit.com/r/StableDiffusion/comments/ydj46v/how_to_merge_checkpoints_in_automattic1111/,2,1666740984.0,"Hi folks, 

How do I merge checkpoints in this UI? When going to the check point merger tab I don't get my checkpoints in the dropdowns. They appear in the dropdown at the top but not in the ones where you select Checkpoint A, Checkpoint B and Checkpoint C.  


I stored them in models/Stable-Diffusion

Why are they not appearing in those dropdowns?  


Anyone?",2022-10-25 19:36:24
I tried to input the first rhymes of the Jabberwocky Poem in SD,3,ydj1l9,https://i.redd.it/1dcrqm4ie1w91.png,1,1666740770.0,,2022-10-25 19:32:50
Smaller Worlds ft. Beecat,40,ydipb5,https://i.imgur.com/Jjo5leG.png,6,1666739797.0,,2022-10-25 19:16:37
[Guide] DreamBooth Training with ShivamShrirao's Repo on Windows Locally,25,ydip3s,https://www.reddit.com/r/StableDiffusion/comments/ydip3s/guide_dreambooth_training_with_shivamshriraos/,7,1666739780.0,"Hi,

I just set up Shivam's Repo on Windows. It works great. Subsystem for Linux is not necessary, nor is a HuggingFace account.

This guide assumes some familiarity with Python. I am using an Anaconda environment called ""diffusers"" on Python v3.8.

* First, download these files from Shivam's Repo and follow the installation instructions: [https://github.com/ShivamShrirao/diffusers/tree/main/examples/dreambooth](https://github.com/ShivamShrirao/diffusers/tree/main/examples/dreambooth)
* Create **train\_example.bat** in the same directory with this content: [https://pastebin.com/YEtrRKyu](https://pastebin.com/YEtrRKyu)
* Adjust lines 16 and 17 with the location of your Anaconda installation and environment name.
* Shivam's repo doesn't support the loading of ckpt files. Instead, you should convert your models to the diffuser format via the instructions in this post: [https://www.reddit.com/r/DreamBooth/comments/y1q7bo/comment/it8dh3p/?utm\_source=share&utm\_medium=web2x&context=3](https://www.reddit.com/r/DreamBooth/comments/y1q7bo/comment/it8dh3p/?utm_source=share&utm_medium=web2x&context=3)
* Adjust **pretrained\_model\_name\_or\_path** to your model.
* Download a vae of your choosing and place it in a folder called ""vae"" next to the Shivam files. You can grab the SD 1.5 vae here: [https://huggingface.co/stabilityai/sd-vae-ft-mse/tree/main](https://huggingface.co/stabilityai/sd-vae-ft-mse/tree/main) (Alternatively, remove the **--pretrained\_vae\_name\_or\_path** flag from train\_example.bat)
* If you wish to use 8bit adam from bitsandbytes, you need to modify the package for Windows compatibility by following the instructions in this post: [https://github.com/TimDettmers/bitsandbytes/issues/30#issuecomment-1257676341](https://github.com/TimDettmers/bitsandbytes/issues/30#issuecomment-1257676341)
* If you receive an error about a missing GPU, try ""pip uninstall torchvision"" then run the official PyTorch install command here (I'm using CUDA 11.3): [https://pytorch.org/](https://pytorch.org/)

Good luck. Feel free to share for visibility.",2022-10-25 19:16:20
Is there any sd 1.5 colab that generates good images?,1,ydimrq,https://www.reddit.com/r/StableDiffusion/comments/ydimrq/is_there_any_sd_15_colab_that_generates_good/,1,1666739591.0,,2022-10-25 19:13:11
"This is I love AI, it's my own little concept artist. I'm bad at coming up with designs but I'm great and reverse engineering.",15,ydij07,https://v.redd.it/atolsvp5a1w91,4,1666739303.0,,2022-10-25 19:08:23
Small Mario from Super Mario Bros. (img2img),3,ydiidb,https://www.reddit.com/r/StableDiffusion/comments/ydiidb/small_mario_from_super_mario_bros_img2img/,1,1666739251.0,https://preview.redd.it/5tobqwdi91w91.png?width=512&format=png&auto=webp&s=99db21a15227a55721d01c5aa8b2584e65f806b9,2022-10-25 19:07:31
Music video by Mubert and StableDiffusion,1,ydihwa,https://youtube.com/watch?v=1lCgh834nSM&feature=share,0,1666739215.0,,2022-10-25 19:06:55
How much do you have to edit an AI generated piece of artwork before it becomes copyrightable to you?,2,ydiahj,https://www.reddit.com/r/StableDiffusion/comments/ydiahj/how_much_do_you_have_to_edit_an_ai_generated/,4,1666738659.0,Reply with a percentage number only. LOL,2022-10-25 18:57:39
can I merge 3 different models using weighted sum?,2,ydi5gq,https://www.reddit.com/r/StableDiffusion/comments/ydi5gq/can_i_merge_3_different_models_using_weighted_sum/,2,1666738277.0,If I use .5 SD_1.5  + trinart + yiffy will the new merged model be .25 trinart + .25 yiffy?,2022-10-25 18:51:17
Villains for the Spooky Season,4,ydhtws,https://www.reddit.com/gallery/ydhtws,0,1666737394.0,,2022-10-25 18:36:34
red lightning,1,ydhtlk,https://www.reddit.com/r/StableDiffusion/comments/ydhtlk/red_lightning/,1,1666737372.0,"can anyone tell me who that red-headed character is that shows up when searching ""red lightning?""  pretty consistant",2022-10-25 18:36:12
Bioluminescent fungi,34,ydhmw0,https://www.reddit.com/gallery/ydhmw0,3,1666736875.0,,2022-10-25 18:27:55
Made with Outpainting using Stablediffusion-Infinity,3,ydhkgb,https://i.redd.it/bx5ts8o421w91.png,1,1666736687.0,,2022-10-25 18:24:47
Several Men Look Forward To The Future Bright Happy High Tech Mansion,1,ydh9oe,https://www.youtube.com/watch?v=MIzbZyEIvDg,0,1666735870.0,,2022-10-25 18:11:10
Made a little SD chrome extension that lets you highlight & generate any text you see!,8,ydh519,https://i.redd.it/364541jqy0w91.gif,1,1666735536.0,,2022-10-25 18:05:36
Seems normal... im2img batch,25,ydh4h6,https://v.redd.it/hvunt1ady0w91,8,1666735497.0,,2022-10-25 18:04:57
Why are models redownloaded after some updates?,3,ydgzx6,https://www.reddit.com/r/StableDiffusion/comments/ydgzx6/why_are_models_redownloaded_after_some_updates/,4,1666735169.0,"After doing git pulls on the huggingface diffusers or on automatic1111 - often the next run will redownload all of the models.  I'm fairly certain the models are exactly the same, so what is triggering the rather wasteful and pointless redownload?",2022-10-25 17:59:29
"Stable diffusion for 3D immersive scenes, viewable in WebVR",1,ydgyih,https://www.reddit.com/r/StableDiffusion/comments/ydgyih/stable_diffusion_for_3d_immersive_scenes_viewable/,0,1666735059.0,"## ""A CYBERPUNK NINJA RIDING AN OSTRICH THROUGH THE STREET OF TOKYO"" IN 3D/WEBVR

[https://holovolo.tv/v/962583](https://holovolo.tv/v/962583)

Today Lifecast unveils text-to-full 3D immersive environments that can be viewed in VR (e.g., Quest 2) or on 2D screens. We are doing this with a combination of Stable Diffusion and several other neural nets to make it 3D, combined with Lifecast's format for 6DOF VR photos and video. It's free to try and we do the processing in the cloud. Check it out and tell us what you think! This is version 1.0 and we are iterating quickly, so expect improvements in the future.

Try it here:  [https://holovolo.tv/landing](https://holovolo.tv/landing)",2022-10-25 17:57:39
got this out of a a.i. it's a version of my fursona from a d&d campaign. On the right is my drawing.,3,ydgy4o,https://www.reddit.com/gallery/ydgy4o,0,1666735029.0,,2022-10-25 17:57:09
input was a picture of the dog which face looks exactly like on the picture. stable diffusion gave him the superman shirt and changed the background.,3,ydgv47,https://i.redd.it/ausutfxae2w91.png,0,1666734805.0,,2022-10-25 17:53:25
Can the new 1.5 inpainting model from Runway be used to train a dreambooth model?,2,ydgoj0,https://www.reddit.com/r/StableDiffusion/comments/ydgoj0/can_the_new_15_inpainting_model_from_runway_be/,1,1666734319.0,,2022-10-25 17:45:19
"From a users pov, how does Dreambooth work?",2,ydgn8i,https://www.reddit.com/r/StableDiffusion/comments/ydgn8i/from_a_users_pov_how_does_dreambooth_work/,5,1666734220.0,"I'm trying to figure out how Dreambooth works from the pov of a user who doesn't understand how the underlying tech works. (ie, me).  


Please let me know if I understand this correctly:  


My understanding is that Dreambooth can be understood to be a kind of blackbox: you feed it a set of images and it gives you back a model with a novel element: the ability to use a certain image when you trigger that ability by using a certain keyphrase. Maybe the keyphrase is ""myUglyMug"" or something.  


So then the model would be a variant of, say, the huggingface 1.5 model, but altered to be able to insert my face.  


If so, then is the model a checkpoint file?   


If that's right, and I'm using the automatic1111 webui, can I then simply swap out the huggingface 1.5 chkpt file for the file that encapsulates the model that I've trained?",2022-10-25 17:43:40
Stable Diffusion Performance Data - The NVIDIA 5090 is the new champ!,0,ydgl61,https://www.reddit.com/r/StableDiffusion/comments/ydgl61/stable_diffusion_performance_data_the_nvidia_5090/,8,1666734075.0,"The [N](https://datastudio.google.com/s/swbCFzCO9jM)[VIDIA 5090 is the Stable Diffusion Champ](https://datastudio.google.com/s/swbCFzCO9jM)!  This $5000 card processes images so quickly that I had to switch to a log scale.

&#x200B;

[SD Performance Data](https://preview.redd.it/t5hf8lukq0w91.png?width=1190&format=png&auto=webp&s=181501c2c1c24c2ed01097c28e1b7a5d85051594)

What was discovered.   Different Stable Diffusion implementations report performance differently, some display s/it and others it/s.  I am assuming it should be it/s (iterations per second) but believe that metric is equivalent.

XFORMERS and Overclocking have an effect on performance, if you want to look at the [RAW DATA](https://docs.google.com/spreadsheets/d/1_a8P6XBoOoWkUfqFY-8IbMX9kj7Eeej-evMP-1_1OZA/edit?usp=sharing) to see what others wrote in the notes, feel free to take a look.  That being said the data may not be objective, 100% apples-to-apples benchmarks but gives us a reasonable performance comparison.

Further, even low end \~$250 NVIDIA cards drastically outperform the M1 Mac Pro and AMD Cards using ROCM.   To generate images quickly (generate an 20 step image in under 1 second) it will take a \~$1000-$1500 NVIDIA video card.

In further reading on the topic it appears that NVIDIA is so far out ahead in development that AMD has no chance of catching up or being relevant in the AI space.  With Apple Silicon using the GPU and the Neural Engine there is room for performance improvement but NVIDIA CUDA cores are king for real-world work and fast image generation.  Additionally, creative companies like Adobe are looking to quickly integrate this new technology into their cloud based tools.  The reaction from the art-world is mixed.  Some see this new capability as a fast way to iterate designs and a design accelerators while others artists take a much dimmer view of this technology.",2022-10-25 17:41:15
Alternate install drive folder and running off pop_os live usb stick!,1,ydgjaj,https://www.reddit.com/r/StableDiffusion/comments/ydgjaj/alternate_install_drive_folder_and_running_off/,0,1666733947.0,"I wanted to try this instead of having to dual boot. I thought the automatic webgui was supposed to be reasonably portable but im having no luck running from both an existing installed folder or doing a fresh install.

Im trying with pop_os because it has nvidia drivers preinstalled and says on the page development toolkits work flawlessly...

I thought to make things easier i would create a stable-diffusion-webui folder symlink to an external ssd.

    ln -s /media/pop-os/256GBUSB/stable-diffusion-webui /home/pop-os

    sudo apt install wget git python3 python3-venv

    bash stable-diffusion-webui/webui.sh

Doing a fresh install on the copied github i get an error about cuda...

Installing torch and torchvision... etc, main bit....

    UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.) return torch._C._cuda_getDeviceCount() > 0 Traceback (most recent call last): File ""<string>"", line 1, in <module> AssertionError: Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check

Just to note i had no problems running from linux mint before by simply following the basic cmds below...

    Debian-based:

    sudo apt install wget git python3 python3-venv

    bash <(wget -qO- https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh)

Any ideas as i never did anything special on linux mint except install nvidia drivers and these are built in and working on pop_os by default?",2022-10-25 17:39:07
Stable Diffusion integrated into a metaverse avatar editor! Pretty fun to apply SD art as patterns to different garments. It enables scaling and positioning and then you can also jump into the Stageverse world to see how the patterns look live!,1,ydg7fg,https://v.redd.it/v23323n8r0w91,1,1666733088.0,,2022-10-25 17:24:48
I made a Princess Zelda Hypernetwork! (link in comments),104,ydg4d9,https://i.redd.it/45zqwiwxq0w91.png,14,1666732875.0,,2022-10-25 17:21:15
I do not understand this issue with NSFW Disabled: NOP's Stable Diffusion Colab v0.54 (1.4 Weights),1,ydfzyf,https://www.reddit.com/r/StableDiffusion/comments/ydfzyf/i_do_not_understand_this_issue_with_nsfw_disabled/,0,1666732562.0," **NSFW Disabled: NOP's Stable Diffusion Colab v0.54 (1.4 Weights)** used to work perfectly (at least the legacy version), but know nothing work, and it only gives this stupid error and I don't understand what it means since I'm not a programmer.

https://preview.redd.it/doocjdv1q0w91.jpg?width=772&format=pjpg&auto=webp&s=8db33eed7bb1876fac20bdbeda56931a0f216a66",2022-10-25 17:16:02
Cool cat - the coolest,28,ydfzml,https://i.redd.it/tv70r1szp0w91.png,3,1666732538.0,,2022-10-25 17:15:38
Is there a way to stop something like this from happening?,3,ydfz25,https://i.redd.it/y0w98wkwp0w91.jpg,8,1666732497.0,,2022-10-25 17:14:57
img2img video game sprite walking animation,12,ydfwz3,https://i.redd.it/tn5g6h7dp0w91.gif,0,1666732346.0,,2022-10-25 17:12:26
Twin Peaks Poster Art Portrait Of David Bowie Stands Before The Labyrinth,1,ydfujl,https://www.youtube.com/watch?v=ugdo7AitMwQ,0,1666732170.0,,2022-10-25 17:09:30
Training a Dreambooth model on a humanoid/robot,10,ydfuhv,https://i.redd.it/f6n1qiivo0w91.png,4,1666732167.0,,2022-10-25 17:09:27
Darth Vadar as a duck,23,ydfssz,https://i.redd.it/1walt6njo0w91.jpg,0,1666732045.0,,2022-10-25 17:07:25
No SD not a cat WITH a dslr,7,ydfoi8,https://i.redd.it/jd4luukcn0w91.png,1,1666731745.0,,2022-10-25 17:02:25
From the Lovecraftian Depths,12,ydfo31,https://www.reddit.com/gallery/ydfo31,1,1666731720.0,,2022-10-25 17:02:00
Do you need 150 steps? Or is that overkill?,1,ydf774,https://www.reddit.com/r/StableDiffusion/comments/ydf774/do_you_need_150_steps_or_is_that_overkill/,5,1666730554.0,I tend to max out my steps to 150. But is it what is really needed? Does it make a difference? It seems most people do somewhere between 2-50. I just assumed a higher number meant more accuracy.,2022-10-25 16:42:34
5 good sites for AI prompts,0,ydezj3,https://www.reddit.com/r/StableDiffusion/comments/ydezj3/5_good_sites_for_ai_prompts/,2,1666730032.0,any suggestions ?,2022-10-25 16:33:52
Female Kratos,25,ydewth,https://www.reddit.com/gallery/ydewth,0,1666729837.0,,2022-10-25 16:30:37
The AND feature is actually pretty cool when you understand it's quirks!,8,yderim,https://imgur.com/a/rk1RXR8,5,1666729467.0,,2022-10-25 16:24:27
Mirror - music video by AI,1,ydee01,https://youtube.com/watch?v=uoPC2YzOSOs&feature=share,0,1666728541.0,,2022-10-25 16:09:01
Join me as we craft the perfect prompt for this weeks SD Discord Pick of the week Challenge!,1,yde8yr,https://www.reddit.com/r/StableDiffusion/comments/yde8yr/join_me_as_we_craft_the_perfect_prompt_for_this/,1,1666728185.0,"Hey y’all! Brand new to streaming and also SD but trying to combine the two and have some fun with the community! I’ll be streaming tonight from 6pm-11pm EST and we’ll be creating an imagine in the theme of “Dark Diffusions presents Movie Night Fright” 

https://twitch.tv/glinskiart/schedule?seriesID=eyJzZWdtZW50SUQiOiJjZGQyODY2NC1jNDFiLTQ4NzAtYmZkMS1kZGFmYTNiOWYwM2YiLCJpc29ZZWFyIjoyMDIyLCJpc29XZWVrIjo0M30=",2022-10-25 16:03:05
Colab and Google Drive Security,2,yde8wi,https://www.reddit.com/r/StableDiffusion/comments/yde8wi/colab_and_google_drive_security/,7,1666728180.0,"SD related colabs usually request access to Google Drive. Something like:

    from google.colab import drive 
drive.mount('/content/gdrive')

With these permissions, the Colab can read and delete anything that you have stored on Google Drive.  As I haven't looked at the Colab code, that makes me a bit nervous. Worse, often the Colab code is pulled directly from Git, so if the authors Git account is hacked the attacker would get access to all of our Google Drives.

Has anyone found an easy way to restrict access to a specific folder? Right now I am using a separate Google Account, but that's far from ideal.",2022-10-25 16:03:00
Latte Art in the spirit of autumn,1,yde5ws,https://www.reddit.com/r/StableDiffusion/comments/yde5ws/latte_art_in_the_spirit_of_autumn/,0,1666727986.0,"I like the bits in the background giving the latte piece a bit more context and environment.

Prompt help by [https://aitextpromptgenerator.com](https://aitextpromptgenerator.com) Pro.  Currently offering a discounted lifetime subscription!

&#x200B;

[Jackolatte](https://preview.redd.it/yyzmw4q1c0w91.png?width=512&format=png&auto=webp&s=0ec425abeb6c2d840cc5ec8f0cc22e836ffb932c)

[ Na na na na na na na na na na na na na na na na... BATMAN!](https://preview.redd.it/oc3gdeq1c0w91.png?width=512&format=png&auto=webp&s=f82735ac266706cc4db628d4e97c1e3f05ddb901)

[Matcha Tree](https://preview.redd.it/lav8ceq1c0w91.png?width=512&format=png&auto=webp&s=248d4b5532dd5fd26fd53b14b7fba7619b590d6d)

[Planetary Latte](https://preview.redd.it/tj0gueq1c0w91.png?width=512&format=png&auto=webp&s=bad08587af8512dc4d110059e90f97a31cd5b777)",2022-10-25 15:59:46
Shakira,0,yde4sv,https://www.youtube.com/watch?v=VfQKAlnafkQ,0,1666727906.0,,2022-10-25 15:58:26
Anyone here running Stable Diffusion on a home PC? What hardware specs are minimum?,0,yddyhv,https://www.reddit.com/r/StableDiffusion/comments/yddyhv/anyone_here_running_stable_diffusion_on_a_home_pc/,11,1666727471.0,"I would love to run SD from a home workstation for photo editing but wonder if even latest generation CPU and GPU would be sufficient.

AMD Ryzen 7950X and 4080 GTI: enough to have a fast workflow?

Anything less expensive and power hungry than that that would work?

Edited: for clarity",2022-10-25 15:51:11
Comment,1,ittkte1,,0,1666761574.0,If we only want one subject trained then use the old method?,2022-10-26 01:19:34
Comment,1,ittkt5k,,0,1666761570.0,"Yeah, what a wasted 2 credit points i got on this specific subjet.",2022-10-26 01:19:30
Comment,1,ittkn84,,0,1666761455.0,"2 and a half hours to train sounds right, for 1 retail gpu. 
From the repo readme, ""I train the model use two A6000 GPUs and it takes ~15 mins.""",2022-10-26 01:17:35
Comment,1,ittkm4y,,0,1666761434.0,Never knew I needed this awesomeness in my life till now.,2022-10-26 01:17:14
Comment,1,ittkcue,,0,1666761255.0,You should get an invite soon,2022-10-26 01:14:15
Comment,1,ittk98k,,0,1666761186.0,"So a question--this is trained on 1.5. What happens if you use another file, anything from novel AI to some of the custom files out there. Does it break anything?",2022-10-26 01:13:06
Comment,1,ittk4i4,,0,1666761095.0,And the fingers of Cthulhu,2022-10-26 01:11:35
Comment,1,ittk48f,,0,1666761090.0,that's really great : ) I love the final product there.,2022-10-26 01:11:30
Comment,1,ittk3zz,,0,1666761085.0,"I will open up the doors tomorrow, make sure to sign up",2022-10-26 01:11:25
Comment,1,ittk3a1,,0,1666761071.0,"Thanks for explanation. I've already started to think that something is wrong with me (or USA). Of course we were always free to create fake photos. I played with this too. Problems arise from using them as real.

Anyway, I think that while fakes, photo art, and digital art will circulate freely (I don't believe they will be able to stifle free flow of AI art) there will be separate market with photos authenticated either by authors or by dedicated camera software (which could be trickier).

I already adjusted myself a bit and I think you too. When watching images from Ukraine war I don't believe them blindly. I believe however when respected journalist takes them.",2022-10-26 01:11:11
Comment,1,ittjz9c,,0,1666760995.0,Yet they plan to sell AI generated stuff themselves? https://www.theverge.com/2022/10/25/23422359/shutterstock-ai-generated-art-openai-dall-e-partnership-contributors-fund-reimbursement,2022-10-26 01:09:55
Comment,1,ittju8h,,0,1666760901.0,"I think the biggest help was from using the fastest upscaler as a prototyper (Lanzcos) to see what would happen when I would change tiles sizes, tile overlap, denoise level, the mask blur (it's in the inpaint tab), same seed, random seed, different algo, different cfg, different steps, etc.  After getting something that wasn't clearly fucked up, I would try it on the different upscalers one at a time and would flip back and forth between the pictures in the output folder to see what changed and if that was something I wanted.

[Here the link to the wiki describing the feature.]
(https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#stable-diffusion-upscale)

For me what ended up working best was 640x640 tiles, .2 denoising  with a random seed (then rerendering if I didn't like the result), and a higher step on a different algo than what I used for the base image.  I did not touch the prompt I used for the base image.",2022-10-26 01:08:21
Comment,1,ittjpg3,,0,1666760810.0,You should clarify this to point out that the images being copy protected does not necessarily mean the user who promoted the computer to generate the art would be the copyright holder.,2022-10-26 01:06:50
Comment,1,ittjp4u,,0,1666760804.0,"Wow thanks! I've been asking about this forever. So basically with this we no longer need WLS or linux on Windows and we can train a previous custom model, convert it to diffusers, and retrain it? I feel like retraining a custom model may provide better results than just merging the models in Automatic1111, but have yet to test it out because I couldn't figure it out.",2022-10-26 01:06:44
Comment,1,ittjlpm,,0,1666760740.0,Try reinstalling Python. Then try installing torch manually using pip.,2022-10-26 01:05:40
Comment,1,ittjjse,,0,1666760703.0,"Prompt: Cat looking at its reflection, mirror in view, atmospheric, soft shading, fluffy fur, cute face, cinematic lighting, centered, symmetrical, highly detailed, digital painting, concept art, smooth, sharp focus,  
illustration, volumetric lighting, epic composition, 8k, art by akihiko yoshida and greg rutkowski and craig mullins, oil painting, (trending on ArtStation:1.3), trending on CGSociety, volumetric lighting, dramatic lighting, (refraction)

  
Negative prompt: Disfigured, bad art, amateur, poorly drawn, ugly, flat, deformed, poorly drawn, extra limbs, close up, b&w, weird colors, lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry

  
Steps: 40, Sampler: Euler a, CFG scale: 12.5, Seed: 1258564860, Size: 512x512, Model hash: a2a802b2, Batch size: 8, Batch pos: 0

Based on u/Adkit's prompt",2022-10-26 01:05:03
Comment,1,ittjgd1,,0,1666760638.0,"Working prototype will be done in like a week or 2, I need to buy springs",2022-10-26 01:03:58
Comment,1,ittjfyh,,0,1666760631.0,"AI is trying so hard to ruin the hands, it can't handle normal non-deformed hands.",2022-10-26 01:03:51
Comment,1,ittjefz,,0,1666760602.0,Why buy stock images when I can generate myself with AI?,2022-10-26 01:03:22
Comment,1,ittizo3,,0,1666760323.0,I don’t really understand any of this pollution stuff yet but it seems like something I need to try to comprehend. Can’t quite wrap my head around these new technical words. But I’m learning. As a Mac user I cannot really jump on the texture inversion wave quite yet so I’m still on Dreambooth. Which is fine really but I would love to have a bit more style control. The lack of negative prompts is probably the greatest frustration with the way I do things now. Thank you for answering my question!,2022-10-26 00:58:43
Comment,3,ittisyq,,0,1666760199.0,"This is great, I’ve thought the same before. It’ll become a reality soon that we will need a test for AI in all categories.",2022-10-26 00:56:39
Comment,2,ittimpi,,0,1666760083.0,"I see a zeldaBOTW.pt but not a zeldaBOTW.ckpt, what's the difference?",2022-10-26 00:54:43
Comment,5,ittil7g,,0,1666760056.0,"Yes, I still checked the hands. Thank you for this funny meme, because you got a chuckle out of me.",2022-10-26 00:54:16
Comment,1,ittiiz9,,0,1666760015.0,I only have a loopback script in my a1111 gui - am I out of date? Would love to hear your method for this!,2022-10-26 00:53:35
Comment,1,ittigch,,0,1666759968.0,the 1.5 model if that's what you're asking.  The UI I used was Automatic1111's webui fork.,2022-10-26 00:52:48
Comment,1,itti8te,,0,1666759833.0,No prompt? No problem! I respect the art either way and think it's really cool!,2022-10-26 00:50:33
Comment,1,itthrtv,,0,1666759529.0,"Seems like someone was going to come out with this sooner or later. As for me, I'm probably going to get back into using Poser because I need a big variety of fairly naturalistic people for my AI work. But this isn't any different from using pose books or stock photo for pose inspiration to avoid being accused of ""pose theft.""",2022-10-26 00:45:29
Comment,1,itthl1u,,0,1666759407.0,Your post/comment was removed because it contains hateful content intended to antagonize.,2022-10-26 00:43:27
Comment,1,ittgvgo,,0,1666758957.0,"sorry the text is all messed up. reddit copy pasting is cancer. ill fix it tommorow after work.

&#x200B;

Here's the workflow for these wallpapers. It might not be exact for each one since they all have different prompts from random experimentation. It's not much different from the old carne-vall style i've been using so far. I find it's more difficult to get good lighting and detail using the SD 1.5 model, even with the ""vae"" file. 1.5 seems to be more prone to getting washed out results than 1.4.

Anyways starting off I used a prompt posted by Kaduc21 since it works fine so far and haven't felt the need to ""re-invent the wheel"". plus any change in orderering can have a massive impact on the final picture

 A handpainted artwork by Alfons Mucha and Aaron Miller of the face andthe chest of a pretty woman in a futuristic body suitarmor, she iscentered in the picture, intricate, trending on artstation,highlydetailed, oil painting

Since the strength of each word depends on how close it is to the start of the prompt, we'll keep Griffiths at the back of the prompt. 

   A handpainted artwork by Alfons Mucha and Aaron Miller of the face and the chest of a pretty woman in a futuristic body suitarmor, she is centered in the picture, intricate, trending on artstation, highlydetailed, oil painting. In the style of Carne Griffiths.Now to make sense of the random paint splotches I recommend keeping artists that often uses flowers, plants, and geometric patterns in their work. The prompt already had Alfons Mucha, and he happens to be a perfect fit for Griffiths. Bella Kotaki or Edward Robert Hughes are also decent picks. You can choose to keep the artists you like, but keep them at the front. Have your main artists and Carne Griffith sandwich the rest of your prompt.    A putArtstyleOrMediumHere by putMainAtistsHere of the putSubjectHere, putBackgroundOrSettingHere, putDetailsHere. In the style of Carne Griffiths.    A \[handpainted artwork:cinematic photo:0.5\] by Jeremy Mann and John William Waterhouse of the portrait a brooding Nordic Man wearing a black suit, he is centered in the detailed picture set in nighttime city, intricate, trending on artstation, highly detailed, \[oil painting:Hyper realism:0.5\]. In the style of Carne Griffiths and Alfons Mucha.Also take note of art-style and medium to keep things from becoming too random, especially when you experiment and swap between artists who use different styles and medium. Stuff like realism, impressionism, and anime would be art styles. And stuff like oil painting or dry acrylic would be mediums.For negative prompts.     body deformities, inhuman hands. (washed out:1.23). fused heads. overlapping heads. fused characters. overlapping characters. fused bodies. overlapping bodies. caricatures. surrealism. \[drawing, cartoon, painting, handpainted, oil painting.:0.5\]. foreground characters, background characters. legs, waist. armor.",2022-10-26 00:35:57
Comment,1,ittgrmw,,0,1666758890.0,"I've read your other post too and you're full of anger, lashing out at a very broad sweep of any AI Image Generator and users of such tech, painting them all with the same broad hateful stroke.

Just because people use these AI does not make them all evil uncaring people.  This tech is literally brand new, everyone using them are still at the experimental stage, everyone excited at the power available to them at their fingertips.  There hasn't been enough time for the whole ecosystem to address all the issues of fair-use, fair-compensation, attributions, delineation of AI art vs non-AI art, etc...

There are many conversations to be had, many topics have not even crossed people's mind yet.  Screaming and ranting, and name-calling people will just put up barriers and create divides; there are more ways to express your concerns than that.

Here's an example of a constructive criticism of current AI image generators.  I may not agree with all his opinions, but I respected his view enough to watch the whole thing and didn't walk away angry or feeling defensive.  [https://www.youtube.com/watch?v=tjSxFAGP9Ss](https://www.youtube.com/watch?v=tjSxFAGP9Ss)

Btw, I have been an artist for decades (non-pro), and have also been a paid photographer, paid photo compositor, and paid photo retoucher for just about as long so these new tools do effect what I do but I've chosen to explore them in full to see how they can help or hurt my work in the long run.  For me, the jury is still out on the final outcome, but so far, I've seen more good than bad in them.",2022-10-26 00:34:50
Comment,3,ittgnrk,,0,1666758823.0,A brief history of the Voight-Kampff test.,2022-10-26 00:33:43
Comment,1,ittgilw,,0,1666758731.0,We are missing the 4th step where he says 'a working prototype' and shoots the camera,2022-10-26 00:32:11
Comment,1,ittgfde,,0,1666758675.0,"Very good, I like it.",2022-10-26 00:31:15
Comment,1,ittg8tm,,0,1666758564.0,I have the same idea!,2022-10-26 00:29:24
Comment,1,ittftfm,,0,1666758301.0,"I don't understand the obsession with disproportionately large breasts, it just looks ugly.. 

Not op, but in general, they'll have the most prettiest looking girl and next thing they do, slap Godzilla breasts on them. Why? It's like they have no sense of what beauty is.",2022-10-26 00:25:01
Comment,1,ittfm0c,,0,1666758174.0,"Using a Mac M1 - Been trying to install Automatic1111 for almost a month now following this: [https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Installation-on-Apple-Silicon](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Installation-on-Apple-Silicon)

Here are the Errors in order starting from the 2nd screenshot to the last screenshot:

\- *Building wheel for basics (setup.py)... errorerror: subprocess-exited-with-errorx python setup.py bdist wheel did not run successfully.*

\- *note: This error originates from a subprocess,and is likely not a problem with pip.ERROR: Failed building wheel for basicsrRunning setup.py clean for basicsrerror: subprocess-exited-with-errorx python setup.py clean did not run successfullv.exit code: ...*

*DeprecationWarning:setuptools.installer is deprecated. Requirements should besatisfied bya PEP 517 installerwarnings.warn(*

\- *OSError: \[Errno 66\] Directory not empty:""...*

*note: This error originates from a subprocess, and is likely not a problem with pip.ERROR: Failed cleaning build dir for basicsr*

\- *Failed to build basicsrDEPRECATION: basicsr was installed using the legacy'setup.py install' method, because a wheel could not be built forit.*

*Apossiblereplacement is to fix the wheel build issue reported above.Discussion can be found at* [*https://github.com/pypa/pip/issues/8368*](https://github.com/pypa/pip/issues/8368)

\- *webui.py: error: argument --use-cpu: invalid choice:'bsrgan' (choose from'all'Isdi'interrogate''gfpgan''swinir!""esrgan'' scunet'codeformer')*

&#x200B;

And to clarify where I'm at with the installation I ran these 4 commands:

**-$ cd \~/Documents/-$ curl** [**https://raw.githubusercontent.com/dylancl/stable-diffusion-webui-mps/master/setup\_mac.sh**](https://raw.githubusercontent.com/dylancl/stable-diffusion-webui-mps/master/setup_mac.sh) **-o setup\_mac.sh-$ chmod +x setup\_mac.sh-$ ./setup\_mac.sh**

This is the farthest I've gotten in the installation and I can give specs if needed",2022-10-26 00:22:54
Comment,1,ittfg0l,,0,1666758075.0,">nousr robot hyper realistic cyborg fluid close up ornate details doe female eyes volumetric lighting  subtle glows, 4k

Impressive!",2022-10-26 00:21:15
Comment,2,itteftx,,0,1666757471.0,"Shutterstock has days to pivot or die.

They chose death it seems.",2022-10-26 00:11:11
Comment,1,itte7ga,,0,1666757334.0,"You may need to rename stuff but yeah that might work. Like if the 1.4 model is model.ckpt then rename that to 1.4.ckpt and upload the 1.5 and rename it to model.ckpt. unless your UI supports switching, then renaming probably wont be needed.",2022-10-26 00:08:54
Comment,1,itte5df,,0,1666757300.0,"brilliant.  I just want to make a simple chesspiece and its just giving me gobbelty gook.

directional prompts?  dude i would love to pick your brain, I've been fascinated with dreamfusion but I can't quite get what I want, I would be fully satisfied with results like this.

i need to read up on negative prompts.  

&#x200B;

I was thinking if I could feed a starting image or seed to dreamfusion it would renderwhat I want it to, better.  but I'm not sure how seeds work really, I'm hacking my way into all this as just a dude with basic coding skills.

any chance you available to help me run through this stuff?  I could pay you a little in crypto for your time",2022-10-26 00:08:20
Comment,1,itte4nh,,0,1666757288.0,"Hello OP, I dare to ask if you could do a video of this tutorial please, I find the dreambooth colab quite not so easy to use (compared with any other colabs that I've used), so I've been messing up plenty of times without getting a single training well-made.   


Thanks for this how-to! It was still enlightening!",2022-10-26 00:08:08
Comment,1,itte35u,,0,1666757263.0,"Does it support prompt weighting and negative prompts? I tried using \[negative\] and it seemed to hang, eventually returned an error about API tokens when I tried to clear it and generate another without the square brackets.

What's the intended purpose of the palette colours below the image? They make me want to edit the palette to modify the image.

The idea of selling prompts is kind of baffling to me, it's a bit like getting a car for free, but paying the last guy who washed it, if you get what I mean? That said, I would be interested in accepting (or paying) tips as tokens for shared prompts, as opposed to cash.",2022-10-26 00:07:43
Comment,1,ittdy3n,,0,1666757181.0,It came out fantastic! Any suggestions to help save others time in understanding the SD upscale script? I did not have much luck with it.,2022-10-26 00:06:21
Comment,1,ittdwey,,0,1666757154.0,"So i'll just upload the model into that location of g-drive, then make the colab load that model with an already existing colab?",2022-10-26 00:05:54
Comment,1,ittdtk9,,0,1666757108.0,Sometimes I go to 600 steps just to see what I get.,2022-10-26 00:05:08
Comment,1,ittdplu,,0,1666757044.0,"No not yet. (AFAIK, maybe something came out in the last three hours.)",2022-10-26 00:04:04
Comment,1,ittdnor,,0,1666757013.0,"You're right, I should be drawing, but the existence of this tech has basically killed off my motivation. By the time I get any good at art, no jobs in art will exist anymore. The world will be so oversaturated with it that I'm confident not a single soul would ever see it.

I'm basically working towards what will essentially be a self-pat on the back. But maybe you find it selfish to feel that way, because you can't really stop technological advancements for your own desires.

Guess I will just focus on Plan B, which is save most of my income and retire early.",2022-10-26 00:03:33
Comment,1,ittdng9,,0,1666757010.0,Cool Cat loves you!,2022-10-26 00:03:30
Comment,1,ittdi5o,,0,1666756924.0,"so just to make it clear, if I say have three instances, anna, tom, and joe, what id' do would prepare Anna 1-30, joe 1-30, and tom 1-30, put them all in the same file directory, and this method would train for all three characters?",2022-10-26 00:02:04
Comment,1,ittdds1,,0,1666756853.0,"Depends what you are trying to do. Generally speaking you want the first pass dimensions to be as close to 512x512 with only one being a little bigger if you want non-square images. I like to double the first pass, so 512x768 first pass becomes  1024x1536 hires, then I upscale. 

If the image gets destroyed in the second pass you might need to lower the denoise setting.",2022-10-26 00:00:53
Comment,1,ittczxd,,0,1666756629.0,"I dont know. I dont use a colab, for AUTOMATIC1111 on my computer it goes in ""stable-diffusion-webui\models\Stable-diffusion"". You will need to check the documentation for yours, or guess. Worst case you can rename the 1.4 and place the 1.5 in that location.",2022-10-25 23:57:09
Comment,1,ittcrot,,0,1666756501.0,"This time, I pruned ckpt from Fast db and uploaded it to Google Drive again to test it. No problem this time. If pruned ckpt is the problem, what is the reason for this?",2022-10-25 23:55:01
Comment,1,ittcmn7,,0,1666756422.0,"So my issue then becomes:

> pytorch_lightning.utilities.exceptions.MisconfigurationException: You requested GPUs: [20]
>  But your machine only has: [0]

Which is weird. I am rocking an RTX 3090, so I don't know whats going on. If i do it with just the o gpu then it takes 2 and a half hours.

I think I am just lost here lol.",2022-10-25 23:53:42
Comment,1,ittcjq6,,0,1666756377.0,"Because Getty and shutterstock will immediately sue the second you get any traction due to the training data having their copyrighted images, and it’ll quickly get pushed up the courts and kill any non-well funded business.",2022-10-25 23:52:57
Comment,1,ittccz4,,0,1666756271.0,"What does it mean by ""Pruned"" ?? is it inferior to what they use on their private site?",2022-10-25 23:51:11
Comment,1,ittc9da,,0,1666756215.0,My goodness that shoulder fuzz is legit!,2022-10-25 23:50:15
Comment,1,ittc7n4,,0,1666756188.0,"I don't have the hardware to test parallelization, unfortunately. But I can confirm that Accelerate and 8bit adam are running fine, and I presume there's a way to get xformers to work too, considering it works in A1111's repo.",2022-10-25 23:49:48
Comment,1,ittc5yq,,0,1666756163.0,Which is why I had to use Linux back in 2020 for Deepfakes.  That extra 500 begs to 1 gig of vram mattered.  W10 just eats vram.,2022-10-25 23:49:23
Comment,1,ittc55u,,0,1666756150.0,Could you make a guts (berserk) hyper network next?,2022-10-25 23:49:10
Comment,1,ittc1fw,,0,1666756091.0,"I have 1.5 model downloaded, but how exactly do i get the colab to run it?",2022-10-25 23:48:11
Comment,1,ittbzf3,,0,1666756060.0,"Oh yeah - you'll either need to download a vae of your choosing and place it in ./vae or simply remove the --pretrained\_vae\_name\_or\_path flag from trainer\_example.bat.

Here's the SD 1.5 vae I'm using: [https://huggingface.co/stabilityai/sd-vae-ft-mse/tree/main](https://huggingface.co/stabilityai/sd-vae-ft-mse/tree/main)

Added this to OP as well.",2022-10-25 23:47:40
Comment,1,ittbxkk,,0,1666756031.0,Anything that can use 1.4 can use 1.5 (I think. As its just more steps trained). Just download the model and put it in the right place for your UI of choice. AUTOMATIC1111 has hot swappable checkpoints so you can have 1.4 and 1.5 to swap as needed,2022-10-25 23:47:11
Comment,1,ittbxhk,,0,1666756030.0,">But there is always bleeding, this is how the model is built

That sounds like something the Terminator would say !",2022-10-25 23:47:10
Comment,1,ittbx6v,,0,1666756026.0,Yup. I tried more I tried less. Same results. The old way led to better results. At least for me.,2022-10-25 23:47:06
Comment,1,ittbw5s,,0,1666756009.0,The timing on your cuts are excellent. Creepy as hell!,2022-10-25 23:46:49
Comment,1,ittbryr,,0,1666755943.0,"And if they get sued, they can turn around and sue you. Hope you're registered as a corporation to at least protect some of your assets. 

And shutterstock wouldn't have to sue you only if they lost a case--they could sue you to recover any legal costs arisi8ng from your refusal to abide by the TOS that you agreed to.",2022-10-25 23:45:43
Comment,1,ittblh9,,0,1666755840.0,Really good results. Thank you for this. Took me a lot longer to crop 30 photos than it did for the model to train.,2022-10-25 23:44:00
Comment,1,ittbiu5,,0,1666755800.0,"Uh huh. You're a librarian according to all your other posts, bro.

>You, on the other hand, are talking right out of your ass.
  


Ironically, I also have a BFA. That's why I know what an artist is, and why asking a computer to create images for you doesn't qualify you as one.",2022-10-25 23:43:20
Comment,1,ittbiqq,,0,1666755798.0,"if you want to run them together you need to do a checkpoint merger which is one of the tabs.  pick first model, pick second model then use the slider to determine how strongly each will influence the end result.   hit go and out comes a new model which you just made...  there is a check box where you can just straight up combine the two but I've never tried that to see how it works.",2022-10-25 23:43:18
Comment,1,ittbg6b,,0,1666755758.0,What was the original artist for the picture?,2022-10-25 23:42:38
Comment,1,ittb4la,,0,1666755585.0,Copyrighting billionaire companies is literally murder.,2022-10-25 23:39:45
Comment,1,ittb433,,0,1666755578.0,"Thats not how it works. Because your logic fails the moment I change the ""pocketed it"" to ""put it in his pocket"" and suddenly it no longer is the same text and there for not copyrighted.",2022-10-25 23:39:38
Comment,1,ittapqa,,0,1666755365.0,So you think it is justifiable to fake images for news articles or other media content that might try to influence people because they couldn't be told apart from real ones? This is the kind of stuff that EU is drafting regulations for AI for - to avoid spreading of misinformation generated by ai.,2022-10-25 23:36:05
Comment,1,ittalz0,,0,1666755309.0,T🤡,2022-10-25 23:35:09
Comment,1,ittaiwd,,0,1666755263.0,That is awesome. Well if you decide to detail your specific models anywhere please let me know. I would love to use a model like that! Thank you again for everything!,2022-10-25 23:34:23
Comment,1,ittagda,,0,1666755224.0,What's the trick to keeping the exact same image like that and just changing the season specifically?,2022-10-25 23:33:44
Comment,2,ittacm5,,0,1666755168.0,the garrison trained a detachment of ducks and equipped them https://www.reddit.com/r/StableDiffusion/comments/ydnomm/war\_ducks\_portraits/,2022-10-25 23:32:48
Comment,2,ittab0b,,0,1666755144.0,Interesting! I'll try that with Design Doll. In that program you can paint directly onto the doll. In the past I used that feature to draw landmarks for hand drawn illustrations.,2022-10-25 23:32:24
Comment,1,itta3f4,,0,1666755031.0,"Prompt 🤗 

8k, hd, 8d|Bob Ross's  hyper realistic renditional of beautiful ""Autumn Twilight"", a beautiful deer buck standing near a lake, perfect anatomically correct full deer buck body profile/portrait, in focus, super highly detailed, full landscape, sharpen features|beautiful sunset reflecting down| photosharp, dop, dof, Pieter Wagemans, Thomas Kinkade, David Lloyd Glover, Michelle Courier, Sushant S. Rane, Michael Simpson, by Bob Ross",2022-10-25 23:30:31
Comment,1,itta019,,0,1666754980.0,I just saw the formula and thats what I did,2022-10-25 23:29:40
Comment,1,itt9yno,,0,1666754958.0,This looks like it could be art on a magic card! Bravo!,2022-10-25 23:29:18
Comment,1,itt9y4a,,0,1666754950.0,"This is kind of pile of sand paradox. If you press a button on a camera makes you an artist, why not passing a prompt not make you? I agree there needs to be a conscious use of skill to create something aesthetically pleasing to be passed as an artist, but just as the analog of photograph, the skill does not need to be manual stroke of brush or something like that.

Leveraging technologies also needs skills to master it. Would you call anyone that takes a photograph an artist? no, obviously, only those who master the photography skillset (composition, color balance, angle, lighting, anything else here... I'm not a photographer) could be called so.

I agree just like when camera widely available in public cheaply, anyone possessing it, and taking pictures randomly and calling them selves an artist is indeed irritating. The AI generative field is still young now, and the skills needed to generate a piece of artwork from just another random generation is still vague. Everyone just copies others prompt that looks good. In times, there will be a well defined skill sets need for AI generative tools to be considered as necessity for someone could be called an AI artist, maybe this will includes prompt engineering, inpainting tricks, outpainting tricks, img2img refinement, prompt switching, negative prompts, seed and variation finding, and others...

Just as almost all the picture in photograph is created by machine, It needed humans to operate it to be regarded as an art (like cctv picture or random traffic camera is not an art), in analog, AI generated picture also need human operator to be regarded as an art.

Another takes on art is a form of communication, to communicate a means from the creator to the appreciator. Using AI to produce this for me does not diminish, as long as you (as a creator) could convey what you means using it. This, currently, is still very hard to do using AI as its struggles to produce detail, so some form of manipulation skills is needed if you stay true to your means.

My takes is, please stop generalizing people, like all people that held a camera isn't an artist vs portrait painter... True, some of camera holder isn't an artist, but not all...",2022-10-25 23:29:10
Comment,2,itt9y01,,0,1666754948.0,"Stabe Diffusion is an algorithm. Nothing that can be installed. Just something that can be read and understood. Like the recpie how to make a cake or mix a cocktail.

There are models, implenting the Stable Diffusion algorithm. Also, nothing that can be installed.

And there are UIs makeing the model accessible through an interface.",2022-10-25 23:29:08
Comment,1,itt9sns,,0,1666754868.0,"That's not good for people who have a business of creating stock art, but it's not bad at all for artists who work directly with any other type of purchaser. It would actually make AI-generated artwork more valuable if all stock art companies had this rule.",2022-10-25 23:27:48
Comment,1,itt9r5m,,0,1666754844.0,"inspired by this post: [https://www.reddit.com/r/StableDiffusion/comments/xidjwg/war\_ducks/](https://www.reddit.com/r/StableDiffusion/comments/xidjwg/war_ducks/)

first, we managed to generate the picture that is the last in the feed, using such a prompt:

evil monster duck wearing armor, war scene, medieval textbook, intricate detail, detailed line shading, high quality scan, 2400 dpi, visible paper structure, serious mood, epic, dynamic
  


next, using imgtoimg and such a prompt:

portrait evil monster duck wearing armor. war scene, medieval textbook, intricate detail, detailed line shading, high quality scan, 2400 dpi, visible paper structure, serious mood, epic, dynamic. by Wayne Barlowe
  


generated a bunch of these.

I am ready to pay more taxes to be protected by such an army. there are plans to create armies from other animals :)",2022-10-25 23:27:24
Comment,1,itt9o66,,0,1666754799.0,"you know what I find funny? Human artists also struggle a lot with hands. They're just complicated, man",2022-10-25 23:26:39
Comment,1,itt9m4g,,0,1666754768.0,What version of SD are you using?,2022-10-25 23:26:08
Comment,1,itt9k7w,,0,1666754740.0,"What do you mean by ""good images""?  and have you tried some that made only ""bad images""?",2022-10-25 23:25:40
Comment,1,itt9h08,,0,1666754691.0,"You seem to have a lot of free time, too bad it's not being used for something more productive or constructive.",2022-10-25 23:24:51
Comment,1,itt9c4g,,0,1666754618.0,"You're probably not charging enough. If the payments you are accepting are too small, that's potentially wrong. These creation videos are excellent pieces of motion art that purchasers can use in their ads, social media posts, etc, too, so if you offer creation videos to your purchasers, you should accept additional payment for those, too.",2022-10-25 23:23:38
Comment,2,itt97ml,,0,1666754552.0,Just saw this posted in this sub earlier: https://www.youtube.com/watch?v=iPsX7z5imVY,2022-10-25 23:22:32
Comment,1,itt96lp,,0,1666754538.0,is it a file you downloaded from GitHub to fix this error?,2022-10-25 23:22:18
Comment,1,itt9266,,0,1666754472.0,Link no longer works?,2022-10-25 23:21:12
Comment,1,itt8ziq,,0,1666754432.0,"Keep in mind that the ""art market"" is largely a money laundering mechanism.  Specifics don't matter.  Consensus determination of which art is ""good"" is a matter of luck & timing, having almost nothing to do with the ""art"" itself.  It's a heck of a thing.",2022-10-25 23:20:32
Comment,1,itt8xzb,,0,1666754408.0,I don't do much img2img but can see how useful this is for generating that perfect pose since manually prompting a pose is a pain.  This might even help to reduce (eliminate?) the problem of head/feet being cut off too.,2022-10-25 23:20:08
Comment,2,itt8pik,,0,1666754282.0,I'd love to try this out,2022-10-25 23:18:02
Comment,1,itt8kej,,0,1666754204.0,"Who is the ""they"" you're talking about?  


And just to be clear, ""manekin"" and ""posable"" are spelled correctly.",2022-10-25 23:16:44
Comment,1,itt8iny,,0,1666754178.0,I'm excited for this.,2022-10-25 23:16:18
Comment,1,itt8iht,,0,1666754176.0,"So you’re training a model on an existing set of NFTs to make…… a forked set of NFTs? 

I dig it",2022-10-25 23:16:16
Comment,1,itt83lo,,0,1666753951.0,"What did you use to do this? A bit confused.

Especially the automatic colorization",2022-10-25 23:12:31
Comment,1,itt7uuc,,0,1666753820.0,Already use AI models in my ads for products lol,2022-10-25 23:10:20
Comment,2,itt7trf,,0,1666753804.0,W the arm of a kindergartner,2022-10-25 23:10:04
Comment,1,itt7s6g,,0,1666753780.0,just use the snipping tool from microsoft store if you're not using a mac.,2022-10-25 23:09:40
Comment,1,itt7nap,,0,1666753709.0,"Is art the medium or the intent? If it's the intent, I think there's an argument to be made that the AI medium still allows for the creation of actual art. If art is just the medium, the literal paint sitting on a canvas, then that's pretty fuckin' depressing and leads to a lot of gatekeeping beyond just AI tools.",2022-10-25 23:08:29
Comment,2,itt766l,,0,1666753460.0,It would be under extras. If you put it in the folder models\ESRGAN on AUTOMATIC1111 and assuming it’s the same ultra sharp that I’m running.,2022-10-25 23:04:20
Comment,1,itt6s7s,,0,1666753256.0,"just to be clear, they have no problem with copying other artists by including them in their prompts, but they don't want other people using their art to create their own?

I guess that's about what one should expect from someone who can't spell 'posable' or 'manekin'. (in the vid)",2022-10-25 23:00:56
Comment,1,itt6eob,,0,1666753068.0,Awesome!,2022-10-25 22:57:48
Comment,1,itt6ef3,,0,1666753064.0,Excellent! I use 3ds Max and sometimes Blender in a pinch. But when I normally illustrate I usually just use Design Doll. It's simple and runs on a Cintiq nicely. I've made paper doll outfits when I just couldn't find any other reference. I was hoping that SD was a grand solution for generating specific reference photos. I don't think it's quite there yet.,2022-10-25 22:57:44
Comment,1,itt6bec,,0,1666753021.0,Do you have a ckpt file for Joe Mad? Or CMgirl?,2022-10-25 22:57:01
Comment,1,itt5vfi,,0,1666752794.0,Awesome! That style is really cool.,2022-10-25 22:53:14
Comment,2,itt5mjg,,0,1666752668.0,"It was a happy discovery on my part when I sorted this out.  Was trying to create this dead adventurer in one of my scenes, like he had just been stabbed in battle and was slumped on the ground bleeding out.

I was like ""SD does not do people laying on their sides well does it?""  Then I checked the data and found out why.  So I thought why not just stand old dude upright, prompt as if he's leaning back on a wall instead and voila after one or two tries he finally looked normal.  Then I rotated him back and called it a day.

Works with everything I've tried.  Reason being not too much good data on objects laying prone I've found, it's all standing/sitting mostly so the orientation needs to be sorted out the right way for SD to not blow a fuse.",2022-10-25 22:51:08
Comment,1,itt5lpi,,0,1666752657.0,"It'll barely fit in a 3090 Ti with batch size 1, probably won't with batch size 2.

I don't know how fast it'll be, don't have one to test with.",2022-10-25 22:50:57
Comment,2,itt5i4s,,0,1666752607.0,Yes,2022-10-25 22:50:07
Comment,3,itt5ghn,,0,1666752584.0,"Its alright boys i got the prompt leaked : 

Hello nice TITS milky milky milky baby thirsty mommy baby want milk suck suck suck suck hahahaha give me those big udders tits tit titty me your caveman me use big titty for big bitty honk honk honk mommy honk honk milky baby want more now honk honk honk pitter patter on those big mommy milkies hee hee hee haha haaaa haaaa can't stop the milk truck coming through honk honk all aboard the titty train hee hee woop wooooooo honk honk honk!!!",2022-10-25 22:49:44
Comment,1,itt5903,,0,1666752478.0,what is this width height?,2022-10-25 22:47:58
Comment,1,itt56aq,,0,1666752439.0,Flatting! Of course! I wonder if adding noise in Photoshop would help things along. I tried white noise with a photo a few days ago and it worked well. Flatting and noise. Hmm...,2022-10-25 22:47:19
Comment,1,itt53yx,,0,1666752406.0,"Very cool! You can weight the individual tokens in your prompts to sort of ""move through"" the intensity of something like ""winter"" or ""spring"". You might find that helps a bit with what you're trying to achieve. I find it quite useful. YMWV.",2022-10-25 22:46:46
Comment,1,itt52on,,0,1666752387.0,How much difference does fp16 make in the quality? I have the gdrive space but just left it checked anyways sknce it was thd default,2022-10-25 22:46:27
Comment,2,itt4xhg,,0,1666752314.0,"Art reference of figure anatomy posing is a good start.  Plenty of people posting those for free everywhere or if you want you can buy whole packs of thousands of fullbody turnaround poses for illustrators in various themes.  Action poses, artistic poses, casual poses it's all on artstation and deviantart and places like that.

Avoids the issue of the grey flat lighting on using dummies.  

All those others in this thread who said to either draw in the rough shape of the outfit or use a ""paper doll"" technique to composite the clothes on top are spot on.  This works.   In essence you have to give img2img something to chew on.  Once you do it knows where to go.

I saw this today as well if you at all are willing to learn free 3d called Blender: https://www.reddit.com/r/StableDiffusion/comments/ydl985/stable\_diffusion\_posable\_dollmannequin\_by\_royal/",2022-10-25 22:45:14
Comment,1,itt4wqz,,0,1666752304.0,"[https://github.com/ShivamShrirao/diffusers/tree/main/examples/dreambooth](https://github.com/ShivamShrirao/diffusers/tree/main/examples/dreambooth)

Run with cuda enabled wsl.",2022-10-25 22:45:04
Comment,1,itt4uu2,,0,1666752277.0,"I'm trying it again, and I'm getting the following error in the last step:

Traceback (most recent call last):  
  File ""/content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py"", line 7, in <module>  
from fastapi import FastAPI  
  File ""/usr/local/lib/python3.7/dist-packages/fastapi/\_\_init\_\_.py"", line 5, in <module>  
from starlette import status as status  
ImportError: cannot import name 'status' from 'starlette' (unknown location)

I've tried every combination between the three checkboxes here: https://cln.sh/78CoU8EucSzKr8E9P97B",2022-10-25 22:44:37
Comment,1,itt4qwk,,0,1666752222.0,"It got all the way to the end of training, then says “something went wrong”.",2022-10-25 22:43:42
Comment,1,itt4l1c,,0,1666752138.0,Wow! I didn't expect a plug-in so soon. I'll try it tomorrow. Perhaps I'll follow his recommendation and run SD on my workstation while I use Photoshop on my Cintiq. When he implements inpainting for the plug-in I will be very happy.,2022-10-25 22:42:18
Comment,1,itt3zlf,,0,1666751840.0,Good stuff!,2022-10-25 22:37:20
Comment,1,itt3v28,,0,1666751778.0,I usually 10 in Huen. Seems fine.,2022-10-25 22:36:18
Comment,1,itt3udf,,0,1666751769.0,"Actually not a lot, just for the faces. I will post my workflow soon, I have adding detail down to a T",2022-10-25 22:36:09
Comment,6,itt3rj5,,0,1666751729.0,"If you want to see more cool prompts, visit my site [publicprompts.art](https://publicprompts.art)

Prompt:

>tiny cute ""ninja"" toy, standing character, soft smooth lighting, soft pastel colors, skottie young, 3d blender render, polycount, modular constructivism, pop surrealism, physically based rendering, square image

_____________________
If you have any suggestions please comment

and consider supporting the project on [BuyMeACoffee](https://www.buymeacoffee.com/PublicPrompts/) :)
__________________
Discord link: https://discord.com/invite/jvQJFFFx26",2022-10-25 22:35:29
Comment,1,itt3e9f,,0,1666751546.0,"I just leverage the image editor abilities that exist to nudge the img2img process in  the direction I want.

You can take your wine glass in your example and light it using this free AI called Relight however you want to match the scene.  SD understands lighting and shading well enough if given the right guidance.  I'm usually pretty well impressed at least.

For shadows I drop in a quick drop shade in photoshop in the general direction and color I need.  Using your wine glass again, I'd give it a drop shadow after lighting it.  (the original image of the glass would either be generated by SD or hand drawn by me or rendered in 3d or something or course, I don't use anyone else's photos or art for img2img stuff just my own creations either natively created or produced by AI via prompting.  You could just take an image of a wine glass and crop it out though if you're not concerned with that stuff.  Even a photo of one of your own taken with your phone.)

At that point, two steps, I've got what I need to nudge img2img to deliver the goods.  Took me longer to type it.  Part of my standard workflow.  This stuff is all flat image based so I find leveraging the power of flat 2d img tools that already exist works hand in had to deliver good output with very little struggle.

SD img2img is extremely capable of blending images together.  I would use it just for that purpose in image compositing even if that was all it was capable of, because it's kind of magical in the way it can render out the right shading and highlighting of composited objects in a scene and make them all fit together.

As for your logo on the headphones issue, with text I've found I just quickly type it in again using an image editor or drawing it in simply using my tablet and stylus .  Img2img does a good job recreating the text as long as the letters are simple forms and legible.  I experimented with that heavily and found it does indeed work.   If the logo had text.  If it was a text free logo I'd just draw in the shape instead, rudimentary and run img2img until I got the right logo randomly which might take a few images.

I just image composite all this stuff taking pieces here and there from good images and combining them into one solid final image that I then run a low strength img2img pass on to tie it all together before enlarging it.  You did say you welcome any input!  It's just how I use SD.  I use it generate single images that I then cannibalize for good parts and composite all together outside SD, then finalize using img2img.  Img2img is a part of that process of having SD create the images for compositing.   I don't waste time or struggle doing it this way, it's all fast and efficient work.",2022-10-25 22:32:26
Comment,1,itt3e1r,,0,1666751543.0,You touched on something.  I bet they'll be working with open AI to create a proprietary model based on their massive stock.  The tagging and quality of their images is  much higher quality likely then what current models were trained on.  I can see their model being better at generating images that look more like stock photos.  That might be worth something to someone.,2022-10-25 22:32:23
Comment,2,itt3e1h,,0,1666751543.0,Communion,2022-10-25 22:32:23
Comment,2,itt31iq,,0,1666751373.0,"Shading is a key. If you want to make a painting style - use a flat comic like shading to on render, otherwise realistic lighting and materials.",2022-10-25 22:29:33
Comment,1,itt30ql,,0,1666751362.0,"I received another error saying   
`OSError: We couldn't connect to 'https://huggingface.co' to load this model, couldn't find it in the cached files and it looks like ./vae is not the path to a directory containing a file named diffusion_pytorch_model.bin`   


Any idea?",2022-10-25 22:29:22
Comment,1,itt2t4j,,0,1666751259.0,Excellent. Model?,2022-10-25 22:27:39
Comment,1,itt2p23,,0,1666751202.0,"No problem, glad to hear it!

TPSM is pretty amazing, but I've found that it does have a lot of glitches if the framing isn't exactly what it expects -- so, it's limiting.

> Regarding the additional optical flow method, do you see an special-case application for that? Maybe videos with more movement, etc?

I'm just speculating, but I suspect it can help when there's not a lot of heterogeneity in the materials and lots of fast motion, like you say. I tried it with my own surface materials and had pretty underwhelming results.

This is a FSPBT model trained on noise+normals:

https://www.youtube.com/watch?v=tpJIpRMnJaA

And this is with gaussians and optical flow on top:

https://www.youtube.com/watch?v=adcA8HWYkvE

The face rig is shit, but I'm sure you get the idea.

Maybe it's my inexperience here, but rendering out the gaussians was also a pain for me. Not only did it take ages, but I think I broke two conda environments in the process and had to do some pretty extensive debugging only to find out there were some problems with the scripts. The end result was, in my opinion, a little worse -- slower to converge and didn't look any better. Your mileage may vary.",2022-10-25 22:26:42
Comment,2,itt2j89,,0,1666751124.0,Gouda lord,2022-10-25 22:25:24
Comment,2,itt2gwh,,0,1666751093.0,"Art is a shit show, just good for Tax Evasion.",2022-10-25 22:24:53
Comment,1,itt288t,,0,1666750974.0,Your post/comment was removed because it contains hateful content.,2022-10-25 22:22:54
Comment,1,itt200j,,0,1666750865.0,"That sounds great! So the input images will be more than just ""a photo of sks man"" but rather a photo with both subjects could be ""a photo of sks man and sks woman"" and every photo has a more indepth explanation? 

Is there an example directory of such labelled images?",2022-10-25 22:21:05
Comment,1,itt1yb0,,0,1666750842.0,"I just had some good results from this free colab for DB:

[https://www.reddit.com/r/StableDiffusion/comments/yd9oks/new\_simple\_dreambooth\_method\_is\_out\_train\_under/](https://www.reddit.com/r/StableDiffusion/comments/yd9oks/new_simple_dreambooth_method_is_out_train_under/)

trained at 3000 steps

Fell free to try that so you won't have to worry about your local vram.",2022-10-25 22:20:42
Comment,2,itt1v2d,,0,1666750800.0,is it sacrelige to want to eat the robe of cheesus,2022-10-25 22:20:00
Comment,2,itt1m0m,,0,1666750679.0,How did you get the eyes so perfect?,2022-10-25 22:17:59
Comment,0,itt1l0k,,0,1666750665.0,">Chill out. You're not an artist by any metric.

I have a Bachelor's of Fine Arts, and have been a practicing artist for over 20 years. Long before AI art was even a thing.

You, on the other hand, are talking right out of your ass.",2022-10-25 22:17:45
Comment,1,itt1k1j,,0,1666750651.0,"prompt: a clearing in a forest grove with a tiny sci fi city skyline on the horizon, peaceful, majestic, 8k, volumetric, spring time, intricate detail, Environment concept art, Sci-Fi digital painting, trending on ArtStation

seed:  4205758118",2022-10-25 22:17:31
Comment,3,itt1j6j,,0,1666750641.0,[Try this plugin.](https://christiancantrell.com/#ai-ml),2022-10-25 22:17:21
Comment,2,itt0xp6,,0,1666750352.0,*cheesus,2022-10-25 22:12:32
Comment,1,itt0x1g,,0,1666750343.0,It's because you need that token to connect to HuggingFace in order to download the model,2022-10-25 22:12:23
Comment,2,itt0v38,,0,1666750316.0,Is his robe made of provolone? Is it sacrelige to want eat the robes of jesus,2022-10-25 22:11:56
Comment,1,itt0tjp,,0,1666750297.0,It basically says it cannot download the model. Do you have a firewall prevent that?,2022-10-25 22:11:37
Comment,1,itt0pzw,,0,1666750250.0,That face the person in your lucid dream gives you,2022-10-25 22:10:50
Comment,1,itt0of6,,0,1666750229.0,"Prompt: Scott Steiner teaching math to Kindergarteners, 8k",2022-10-25 22:10:29
Comment,1,itt0o9w,,0,1666750227.0,"how to use that script, since I don't see a download link anywhere, I guess I'll try it",2022-10-25 22:10:27
Comment,1,itt0gig,,0,1666750123.0,ah okay. thank you friend! I stepped out to grab some good Ill try it the second I get home!,2022-10-25 22:08:43
Comment,1,itt0dy5,,0,1666750088.0,Just imagine realtime automatically generated targeted ads based on each user's ad profile.,2022-10-25 22:08:08
Comment,0,itt0do4,,0,1666750084.0,">In the case of AI art, all of the artistic direction comes from one person, the creator. Even though I'm not hand painting an image, necessarily, I can still put hours and hours and hours into getting the AI to generate the image I have in my head, making sure that the details and composition and everything else are to the standards I've set.

Chill out. You're not an artist by *any* metric. You type words into an algorithm and an image appears. All this hand-wringing and begging people to see you as an artist is really cringey. Just use the tech for waifus and don't get big ideas about yourself.",2022-10-25 22:08:04
Comment,1,itt0878,,0,1666750010.0,you can merge 2 than merge the new merged on with a third,2022-10-25 22:06:50
Comment,1,itt0027,,0,1666749901.0,"ok, tryed everything. i'm getting this error at last steps

`File ""/opt/conda/lib/python3.7/site-packages/huggingface_hub/utils/_errors.py"", line 213, in hf_raise_for_status`

`response.raise_for_status()`

`File ""/opt/conda/lib/python3.7/site-packages/requests/models.py"", line 960, in raise_for_status`

`raise HTTPError(http_error_msg, response=self)`

`requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://huggingface.co/CompVis/stable-diffusion-v1-4/resolve/main/model_index.json`

`The above exception was the direct cause of the following exception:`

`Traceback (most recent call last):`

`File ""/opt/conda/lib/python3.7/site-packages/diffusers/configuration_utils.py"", line 234, in get_config_dict`

`revision=revision,`

`File ""/opt/conda/lib/python3.7/site-packages/huggingface_hub/file_download.py"", line 1057, in hf_hub_download`

`timeout=etag_timeout,`

`File ""/opt/conda/lib/python3.7/site-packages/huggingface_hub/file_download.py"", line 1359, in get_hf_file_metadata`

`hf_raise_for_status(r)`

`File ""/opt/conda/lib/python3.7/site-packages/huggingface_hub/utils/_errors.py"", line 254, in hf_raise_for_status`

`raise HfHubHTTPError(str(HTTPError), response=response) from e`

`huggingface_hub.utils._errors.HfHubHTTPError: <class 'requests.exceptions.HTTPError'> (Request ID: ZxbLCBkIsHiRABDL6RZya)`

`During handling of the above exception, another exception occurred:`

`Traceback (most recent call last):`

`File ""/train_dreambooth.py"", line 695, in <module>`

`main()`

`File ""/train_dreambooth.py"", line 376, in main`

`args.pretrained_model_name_or_path, torch_dtype=torch_dtype, use_auth_token=True`

`File ""/opt/conda/lib/python3.7/site-packages/diffusers/pipeline_utils.py"", line 373, in from_pretrained`

`revision=revision,`

`File ""/opt/conda/lib/python3.7/site-packages/diffusers/configuration_utils.py"", line 256, in get_config_dict`

`""There was a specific connection error when trying to load""`

`OSError: There was a specific connection error when trying to load CompVis/stable-diffusion-v1-4:`

`<class 'requests.exceptions.HTTPError'> (Request ID: ZxbLC**********)`",2022-10-25 22:05:01
Comment,1,itszxr0,,0,1666749870.0,Damn how do u do that ?,2022-10-25 22:04:30
Comment,1,itszmpa,,0,1666749724.0,Maybe you can try something like Gyazo its super easy and free or sharex its free and open source,2022-10-25 22:02:04
Comment,2,itszlpk,,0,1666749711.0,"> site like shutterstock, for JUST AI generated images, they will do good work in putting shutterstock out of buisness, and will clean up in the mean time.

Couldn't a person just grab a photo on this given site, put on their stable diffusion, tell it to generate a slightly variant of that image for free without having to pay anything, just taking advantage from the composition already made and img2img the whole thing? I mean, what I'm trying to say here is that the whole concept of stock photography, pardon my french, seems fucked in the ass :\",2022-10-25 22:01:51
Comment,2,itszl1k,,0,1666749703.0,0,2022-10-25 22:01:43
Comment,1,itszkmq,,0,1666749697.0,That is awesome.,2022-10-25 22:01:37
Comment,1,itszh92,,0,1666749653.0,"worked much better this time. Thank you.

I can't seem to find the created ckpt file to download and use locally though.

I even did a search in my google drive for ckpt and it showed each version that was saved up until the 2500 step one. But the final one isn't shown. I'm so confused by this.",2022-10-25 22:00:53
Comment,1,itsz7px,,0,1666749529.0,Looks pretty cool!,2022-10-25 21:58:49
Comment,1,itsyzo8,,0,1666749425.0,"Probably you could find a way to control for variables. For example, an identical workflow, reference GPU or CPU depending what you were testing, etc.",2022-10-25 21:57:05
Comment,1,itsyvho,,0,1666749371.0,Interesting.,2022-10-25 21:56:11
Comment,1,itsyth9,,0,1666749345.0,Very nice!,2022-10-25 21:55:45
Comment,1,itsyox3,,0,1666749287.0,"\*control panel

This: https://i.imgur.com/f5Y8COh.png",2022-10-25 21:54:47
Comment,1,itsyh3v,,0,1666749188.0,thanks. For some reason I kept getting [https://huggingface.co/CompVis/stable-diffusion-v1-4/tree/main](https://huggingface.co/CompVis/stable-diffusion-v1-4/tree/main),2022-10-25 21:53:08
Comment,0,itsygry,,0,1666749184.0,I dont think I have a configuration panel,2022-10-25 21:53:04
Comment,2,itsyeip,,0,1666749154.0,I had a similar experience. Instructions (even training for longer) do not yield good results compared to the classic JoePenna dreambooth model I trained on the same dataset.,2022-10-25 21:52:34
Comment,1,itsy8qg,,0,1666749082.0,Right so you'll need to uninstall miniconda too. It should appear in the list of installed software you can uninstall in your configuration panel.,2022-10-25 21:51:22
Comment,3,itsy47y,,0,1666749026.0,"True. It is art, but we are not artists.",2022-10-25 21:50:26
Comment,1,itsy30c,,0,1666749009.0,Yep. The beta just let me keep playing without buying credits since I didn’t download anything. 😃,2022-10-25 21:50:09
Comment,0,itsy1wx,,0,1666748996.0,https://www.howtogeek.com/830179/how-to-run-stable-diffusion-on-your-pc-to-generate-ai-images/,2022-10-25 21:49:56
Comment,1,itsy0d3,,0,1666748976.0,How,2022-10-25 21:49:36
Comment,3,itsxxh8,,0,1666748939.0,If you don't make your own paint from you ass and use your fingers as a paintbrush you ain't no artist.,2022-10-25 21:48:59
Comment,1,itsxxc8,,0,1666748937.0,lol did you really make pictures of ur monitor haha,2022-10-25 21:48:57
Comment,1,itsxx22,,0,1666748933.0,Do you know how can i add this [arcane](https://huggingface.co/nitrosocke/Arcane-Diffusion) model to the notebook?,2022-10-25 21:48:53
Comment,1,itsxknx,,0,1666748770.0,"i wonder how is the training when using a merged sd+vae   
(if is even possible acttualy i'm not sure but i think i have read somewere, maybe on a colab, that is possible to merge sd+vae togheter...)",2022-10-25 21:46:10
Comment,1,itsxk4p,,0,1666748763.0,"We will have SD artists. But just because you can direct a tool, does not make you an artist. We had a similar argument with Photoshop for years. But there are true artists that use it as a tool for their creations. The same will happen with SD. I'm looking forward to their creations.",2022-10-25 21:46:03
Comment,1,itsxjsz,,0,1666748759.0,Noice. This is amazing,2022-10-25 21:45:59
Comment,1,itsxjbd,,0,1666748753.0,"Using NMKD I'm getting 1020 X 1080 images, and the look okay as long as I use image2image, only slightly following the initialization picture.  Automatic1111 won't go that high.  I think the browser interface is using too much of the 1080 Ti's VRAM.  NMKD has its own tidy little interface, no browser needed.",2022-10-25 21:45:53
Comment,2,itsxiac,,0,1666748739.0,"Looks like it is here?

https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/tree/main

Uploaded 2 months ago.",2022-10-25 21:45:39
Comment,2,itsxgj8,,0,1666748716.0,Not too hard when most of the prompt is in the bottom of the screen. 😀,2022-10-25 21:45:16
Comment,2,itsxejf,,0,1666748690.0,Looks stunning,2022-10-25 21:44:50
Comment,1,itsx7c0,,0,1666748597.0,i dont get why i must put the token? i thought this was completly offline,2022-10-25 21:43:17
Comment,2,itsx29h,,0,1666748532.0,Which version did you install? Following which instructions?,2022-10-25 21:42:12
Comment,1,itswxwf,,0,1666748477.0,"It looks pretty strange, but I have to give it to you for the effort. You are very creative, and I look forward to what you come up in the future. :)",2022-10-25 21:41:17
Comment,2,itswts6,,0,1666748425.0,"> can do all that

Do what? Struggle with guns just as much as it struggles with hands? Or merge clothes into other objects?

You just notice the hands more because that's how the human brain works. Lots of features are just as scuffed in almost every image, we simply don't have the same reaction.",2022-10-25 21:40:25
Comment,1,itswfux,,0,1666748247.0,it's not a massive download ;),2022-10-25 21:37:27
Comment,1,itsw878,,0,1666748149.0,"So, should I give a porcentaje of my earning to my college professor?. For teach me the stuff I use as a daily basis in my job. Or maybe to the authors of the books I read in college.",2022-10-25 21:35:49
Comment,1,itsw67u,,0,1666748124.0,"2, all are good tho!",2022-10-25 21:35:24
Comment,2,itsvybu,,0,1666748021.0,"I'm curious what consequences this would have for local SD users down the road. I'm far from against creators who's work was used to train a model getting paid some amount for it's use, but if it becomes the norm to use a spotify-ish payment model, what would that mean for people still using those same artist's names locally and not paying, would there be some kind of retroactive legal enforcement if enough companies went down the same road? Maybe some kind of asterisk that nothing made with the local versions can be used commercially if they include those artists names?",2022-10-25 21:33:41
Comment,1,itsvrcz,,0,1666747930.0,"testing it out now, just a heads up if your token/images name includes a number like the one I use ""rob3d"" it automatically removes the number.  So it trains each step as ""robd"" I'm guessing this is because of the numbering system your using. anyway around that other than changing the token itself.",2022-10-25 21:32:10
Comment,1,itsvqyx,,0,1666747925.0,"so from that repo you linked

https://github.com/XavierXiao/Dreambooth-Stable-Diffusion/blob/main/configs/stable-diffusion/v1-finetune_unfrozen.yaml#L80

line 80 of that yaml config has a reference to num_workers, and is defaulted to 8. Maybe try playing with that first, instead of hardcoding.",2022-10-25 21:32:05
Comment,1,itsvq0l,,0,1666747912.0,"Thank you, this is great!

I have a question though... why does it seem impossible--in contrast with say ArtBreeder's portrait mode--to get genuinely smooth transitions that do not have sudden jumps?

Is it technologically impossible due to the way StableDiffusion works and/or was trained?  Or it's just not how your script does things, but theoretically it could be done?",2022-10-25 21:31:52
Comment,1,itsvncm,,0,1666747878.0,"Edit: I got the model and repos to go thru! I got more errors but man I'm happy AF rn :DD https://www.reddit.com/r/StableDiffusion/comments/ydomgy/thought\_i\_finally\_successfully\_installed\_sdbut\_i/

~~Wow so I just saw right now the model file I had to manually move to the folder disappeared  was not in the model folder beside the ""Put Check  Points Here"".~~

~~reran the set up using those 4 cmd with same error.~~

~~I think since I downloaded Python3 from their website instead of thru Homebrew it causing the error because of the weights/repositories possibly~~",2022-10-25 21:31:18
Comment,1,itsvgm0,,0,1666747791.0,"The very easiest way is to use a service that does all the setup for you. That does usually cost a little money, but it will give you a taste for it quickly. If you want to delve deeper there are more options. If you have powerful enough graphics card, you can run Stable Diffusion on your own PC, or on a remote computer if you don't.",2022-10-25 21:29:51
Comment,1,itsv2wo,,0,1666747610.0,Thanks!,2022-10-25 21:26:50
Comment,2,itsv1gi,,0,1666747591.0,All I did was use the difference merge option in AUTOMATIC1111's repo. SD 1.5 + (dreambooth model-SD 1.4) 10 times with different dreamboith models.,2022-10-25 21:26:31
Comment,2,itsuwr0,,0,1666747529.0,🗿,2022-10-25 21:25:29
Comment,1,itsupzd,,0,1666747439.0,Can anyone else still download SDv1.4 I couldn't find it on huggingface anymore. Maybe I am just blind,2022-10-25 21:23:59
Comment,1,itsuo2z,,0,1666747414.0,"Haha glad not worked! But yes it's Throwing Snow, we licensed that track from him ❤️",2022-10-25 21:23:34
Comment,2,itsunop,,0,1666747408.0,Maybe they'll use AI to know,2022-10-25 21:23:28
Comment,1,itsul5n,,0,1666747376.0,"hmmm yes I was just talking about this yesterday and got downvoted. Big companies won't be sleeping on this new technology. Everyone here who dreams of a future as a ""prompt writer"" is just that, dreaming. Soon we will have AI image creation comparable to the ease of using Google image search. Every normie can do it then and no complicated prompt writing will be necessary.",2022-10-25 21:22:56
Comment,1,itsud4t,,0,1666747271.0,"That's one of them, yes.
https://stablehorde.net/",2022-10-25 21:21:11
Comment,2,itsu7tz,,0,1666747204.0,"Did you just made the AI try to recreate the original, without any modification?",2022-10-25 21:20:04
Comment,1,itsu5y9,,0,1666747179.0,"With such a specific number in your title, I thought you were offering.",2022-10-25 21:19:39
Comment,1,itsu5xd,,0,1666747179.0,Wonderful!,2022-10-25 21:19:39
Comment,1,itsu5k7,,0,1666747174.0,"Gammagec Dreambooth-SD-optimized - https://github.com/gammagec/Dreambooth-SD-optimized

I am using this:
https://www.reddit.com/r/StableDiffusion/comments/xqkyoc/installing_dreambooth_stable_diffusion_for/

and okay I will try that real quick.  Thanks Ill let you know how it goes!",2022-10-25 21:19:34
Comment,1,itstz17,,0,1666747089.0,So just to be clear - are you training models on Colab and then using them locally?,2022-10-25 21:18:09
Comment,2,itsty3n,,0,1666747077.0,Our grate lord,2022-10-25 21:17:57
Comment,7,itstemq,,0,1666746824.0,Day-old account.,2022-10-25 21:13:44
Comment,1,itstcyq,,0,1666746803.0,"Well, within their walled garden, at least. No sellable AI art via Shutterstock unless you use their tool on their site, for a monthly fee. And since there aren't really other sites offering the ability to safely sell AI art, they do have a pretty solid monopoly overall. At least until Adobe copies the idea :)",2022-10-25 21:13:23
Comment,1,itstbmd,,0,1666746785.0,"Thoughtful post, looking forward to seeing this grow.",2022-10-25 21:13:05
Comment,1,itsta47,,0,1666746766.0,"I'm not sure, but there are 5 jurisdictions worldwide including the UK that copyright protect computer-generated works by statutory law. More info in [this post](https://www.reddit.com/r/bigsleep/comments/uevfch/article_ai_authorship_by_a_law_professor_2020/).",2022-10-25 21:12:46
Comment,1,itst9qj,,0,1666746761.0,It's like the ai doesn't know whether to generate tubes or fingers,2022-10-25 21:12:41
Comment,2,itst9op,,0,1666746760.0,Kinda looks like Bulma from DBZ,2022-10-25 21:12:40
Comment,1,itst930,,0,1666746752.0,Np 😀,2022-10-25 21:12:32
Comment,3,itst6dv,,0,1666746718.0,"It sounds like it should be ""./diffuser\_model""",2022-10-25 21:11:58
Comment,1,itst4xy,,0,1666746700.0,Just a joke.,2022-10-25 21:11:40
Comment,1,itst474,,0,1666746690.0,"We just deployed a fix for this. When custom is off, the seed is randomised within the API request so you won’t see it change until the run is complete. Let me know how you go.",2022-10-25 21:11:30
Comment,1,itst3h0,,0,1666746680.0,">who are in despair not primarily because they are losing money- but because a skill they found to be worth developing and which lent their lives meaning and purpose has been- as they see it- rendered futile.

I imagine this has been the case for a wide range of crafts displaced by technology. Anyone using personalized processes to produce things which become parts of other peoples lives would experience that feeling of futility when their efforts are functionally replaced by automatic manufacture. But I think it's an important detail that this is not a removal of relations between people, just a rearrangement. A piece of music played in a recording studio lacks the back and forth of a life performance, and a printed book lacks what is present in a story told in person, but it is still communication. Even a mass produced product was designed by someone, and even if that person used an entirely formulaic strategy for the design, it was still influenced by the needs and interests of people.

I think of AI assisted art as another rearrangement. Everything they produce is ultimately a reflection of something someone once imagined, even if the provenance of that expression is hard to trace. Much of what is created with them is the product of new creative input; active guiding towards a particular goal or hybrid traditional/AI works. It can be argued that it isn't really the case that you would be alone in that way when spending time with a work that AI was used to produce. I am hopeful that worries of creative alienation will be short lived.",2022-10-25 21:11:20
Comment,1,itst3a7,,0,1666746678.0,Is my face bro 🤨,2022-10-25 21:11:18
Comment,1,itssu2l,,0,1666746560.0,I can't believe you put Robert Downey Jr in the face of iron man.,2022-10-25 21:09:20
Comment,1,itsssas,,0,1666746536.0,"Sorry, but I'm just not getting results as good with this as with standard Dreambooth training in the same amount of time. Needs more work, IMO.",2022-10-25 21:08:56
Comment,1,itssqy6,,0,1666746519.0,"They are granting themselves a monopoly on AI art? What?

This sub is crazy town",2022-10-25 21:08:39
Comment,1,itssqt0,,0,1666746517.0,This should be fixed now 👍,2022-10-25 21:08:37
Comment,1,itsspsh,,0,1666746504.0,"Hadn't seen the new versions till now. Now the format would look something like this - set zoom to 2 at beginning, morph prompts for 10 seconds, set zoom to 1 at 10 sec mark (if that's what you want):

    0   | transform | 2 | 0 | 0 | 0
    0   | prompt | (Waterfall):1    AND (Water droplet):0
    2.5 | prompt | (Waterfall):0.75 AND (Water droplet):0.25
    5   | prompt | (Waterfall):0.5  AND (Water droplet):0.5
    7.5 | prompt | (Waterfall):0.25 AND (Water droplet):0.75
    10  | prompt | (Waterfall):0    AND (Water droplet):1
    10   | transform | 1 | 0 | 0 | 0

As to the [prompt morph](https://github.com/feffy380/prompt-morph) script you can find it in the [Auto repo's wiki](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Custom-Scripts)",2022-10-25 21:08:24
Comment,1,itsspmb,,0,1666746502.0,"[October 24, 2022](https://www.reddit.com/user/Wiskkey/comments/ydkzv9/stable_diffusion_links_from_around_october_24/).",2022-10-25 21:08:22
Comment,1,itsskuy,,0,1666746441.0,Surely OP will deliver,2022-10-25 21:07:21
Comment,2,itssjr8,,0,1666746427.0,"You could collage and do it all at once, or do them separately, then collage and run them again.",2022-10-25 21:07:07
Comment,2,itssh5j,,0,1666746393.0,How do they even know if it was generated by AI in the first place???,2022-10-25 21:06:33
Comment,3,itssdks,,0,1666746346.0,Someone likes NFT’s ;),2022-10-25 21:05:46
Comment,1,itssc2f,,0,1666746327.0,"That prompt is absolute fire mate, we wanted to show it off :)",2022-10-25 21:05:27
Comment,1,itssbtl,,0,1666746324.0,"[October 7, 2022](https://www.reddit.com/user/Wiskkey/comments/ydkxq2/stable_diffusion_links_from_around_october_7_2022/).",2022-10-25 21:05:24
Comment,4,itssb02,,0,1666746313.0,This is just a PR move by OpenAI to target their corporate and open source completion.,2022-10-25 21:05:13
Comment,1,itss8xk,,0,1666746287.0,"That's a great negative prompt, I'll have to try it with some of my images",2022-10-25 21:04:47
Comment,2,itss7y7,,0,1666746274.0,I'm going to try a crude collage and paper doll technique in Photoshop to get the general clothing and textures in place. Then see what happens in Auto1111 and inpaint. I got my work cut out for me tomorrow.,2022-10-25 21:04:34
Comment,5,itss7x5,,0,1666746274.0,"Does dat cat look like it's ""struggling to survive""? Na, its Pokerface looks like it owns the currents 😂",2022-10-25 21:04:34
Comment,1,itsrppq,,0,1666746044.0,"I had a lot of fun with this one, basically taking some pop album covers and running them into Diffusion.

I like the plastic toy flair to them, a bit like legos. Let me know what you think! :)

More of my work here: https://www.instagram.com/lightcatai/",2022-10-25 21:00:44
Comment,2,itsrm6e,,0,1666746001.0,"These are fantastic, I tend to do a lot of these too.",2022-10-25 21:00:01
Comment,1,itsrlrv,,0,1666745996.0,"looks like a blend between brie, and wong & xing ji ping lmao",2022-10-25 20:59:56
Comment,2,itsrhil,,0,1666745941.0,I just happened to make some too. [https://imgur.com/a/2ZSZnGF](https://imgur.com/a/2ZSZnGF),2022-10-25 20:59:01
Comment,1,itsrg6n,,0,1666745924.0,"agree with this, i'm loosing more time to try keep track of every new features and updates, across 100 platforms.. then the actual time spending on enjoying the AI itself",2022-10-25 20:58:44
Comment,2,itsrfv0,,0,1666745920.0,"Thanks, regarding the path for the model, if my model folder is on the root (beside train\_example.bat) called ""diffuser\_model"" what would be the path here?  
  `--pretrained_model_name_or_path=""./models/sd15"" ^`",2022-10-25 20:58:40
Comment,2,itsrbxk,,0,1666745870.0,Find a photo online of someone in the pose you want and cut out the background. Use that for img2img.,2022-10-25 20:57:50
Comment,1,itsrb6w,,0,1666745860.0,"""We are all in the gutter, but some of us are looking at the stars"" 🌟",2022-10-25 20:57:40
Comment,1,itsqrew,,0,1666745613.0,"what repo are you using? my data_loading.py is only 63 lines. The error is referring to some function at line 132 instancing a DataLoader object from torch.utils.data..so you could hardcode the num_workers argument in that instance call to 20, but shouldn't be needing to if it is being called properly.",2022-10-25 20:53:33
Comment,2,itsqmd5,,0,1666745550.0,"Because there's a ton of artists out there that can afford to file drawn out frivolous lawsuits just to make a point.

This is a legit concern that I'll bet will be picked up pro bono by a smart team of copyright lawyers soon. Just need the right case.",2022-10-25 20:52:30
Comment,1,itsqfg4,,0,1666745463.0,"Not a perfect solution is a complete understatement. I've already circumvented your suggestion in the past three days without even having seen it. I've been training artist style embeddings on SD Textual Inversion the past week just because I wanted stronger style associations, and SD's open source nature means that I can remove any prompt limitations if I want. In fact the first thing I did was remove the invisible watermark SD generates on images. I can also assure you the first thing people would do with a list of opt outers is download a history of their work and train their own embeddings to have them available for themselves. It'd be a nice way for Stability to wash their hands of the situation though.",2022-10-25 20:51:03
Comment,1,itsqchk,,0,1666745425.0,All these sources of malicious code such as packages and models could read/write to your Google drive.,2022-10-25 20:50:25
Comment,1,itsq5xn,,0,1666745343.0,"From what I've learned so far, all the illustrations I've seen others do actually start from either a photo or a randomly generated image as a starting point. SD can be a powerful tool for traditional illustrators. I'm trying develop a workflow.",2022-10-25 20:49:03
Comment,2,itsq4fc,,0,1666745324.0,Will do,2022-10-25 20:48:44
Comment,1,itsq23f,,0,1666745296.0,[It isn't WSL.](https://i.imgur.com/yvpUU71.png),2022-10-25 20:48:16
Comment,2,itspz3c,,0,1666745259.0,"Yeah, the doll approach would probably do it. Back whe I was full-on composing images (oh, the good old days of last week!), I would sketch some stuff, paste in certain details, resize etc in Photoshop, and then run it through img2img and see what happened. Ideally, you wouldn't have to spend TOO much time compositing in Photoshop, but yeah, it helps limit frustration and rework :)",2022-10-25 20:47:39
Comment,3,itspyvq,,0,1666745256.0,Now do other major religious figures,2022-10-25 20:47:36
Comment,1,itspyte,,0,1666745255.0,Yeah sorry but this method looks no better than Textual Inversion but with extra steps,2022-10-25 20:47:35
Comment,5,itspxo5,,0,1666745242.0,"How did you call people who throw paint on canvas? You called them artists. 

How did you call people who put excrements in tin cans? You called them artists.

How did you call people who tape bananas to walls? You called them artists. 

How did you call people who mash up couple of stock photos in Photoshop? You called them artists. 

How do you call people who spent hours working, wrighting and experimenting to get an image? You call them low-effort nothings.",2022-10-25 20:47:22
Comment,1,itspsh4,,0,1666745177.0,"\[celebrity x, celebrity y\]. That's it. Whatever comes up will be consistent. And if you pick the right names then you can have characters that are consistent and don't look like either celebrity",2022-10-25 20:46:17
Comment,1,itspr3z,,0,1666745160.0,"Yeah I agree, even his cherry picked examples look considerably worse then what can be achieved using Shivam or even Joe's repo.",2022-10-25 20:46:00
Comment,1,itsppvx,,0,1666745145.0,"I don't quite understand the instructions to skip two cells below start dreambooth, isn't that all that's left in that section?",2022-10-25 20:45:45
Comment,1,itspl20,,0,1666745086.0,Omg is this specifically stable diffusion 1.5 without the inpainting?,2022-10-25 20:44:46
Comment,2,itspfvy,,0,1666745022.0,On the todo list,2022-10-25 20:43:42
Comment,7,itspfgt,,0,1666745018.0,"Who needs stock photography when the AI can generate anything from scratch?  And no, the training data is not a ""copy"" of anything.  It's an abstraction.  If I study Haydn and Tchaikofsky, and develop a set of rules by which I write my own string quartets...neither my quartets nor the rules I derived are anyone's intellectual property but my own.  If Getty wants to write their own AI, they can have at it, but the algorithm derived from a training set neither contains the training set, nor can it generally reproduce the training set.  It is merely an abstraction of the mathematical relationships between different gradients contained within small subregions of every image of that dataset, averaged and formalised into a series of simple transformations, which makes this algorithm a purely mathematical phenomena, no more copyrightable than the number 4 or the concept of compound interest.",2022-10-25 20:43:38
Comment,1,itspd5c,,0,1666744990.0,"I've only trained Hypernetworks successfully. The one embedding I tried didn't work, though that was probably user error, and despite having 12GB of VRAM running dreambooth via WSL hasn't worked out for me yet.",2022-10-25 20:43:10
Comment,2,itsp9em,,0,1666744943.0,"How about collaborator, or curator?

As to your main point, sure, there are certainly many people who just type ""pretty girl"" and click go.  I see these people the same was as I do people who take vanilla photos of common subjects in common ways.  They're both just types of amateurs.

But a great deal of work *can* go into finding the right prompt, modifying the training data, issuing infill, &c.  And it takes a trained eye to recognize something really special out of hundreds of good-but-not-amazing images, just as with photography.  Or when running an art gallery, which is why curator came to mind.",2022-10-25 20:42:23
Comment,2,itsp8jw,,0,1666744932.0,"My process (and desired results) are maybe a bit sideways of what others prefer, but for me, training on humans that are meant to be used in variable costumes/hairstyles etc, I find that between 3-5k steps, you get something that matches the subject and is pretty flexible. At 5-9k you get something very crisp, but you maybe lose the ability to shift styles (can't get a rendering as a painting or a pencil sketch). I accidentally did one today at 13k and it refused to let me change the clothes at all. Past 13k, I don't even know. It stops being useful for me when I can't adapt the base character. If you're trying to train a character in extreme detail, that might be the right approach, but I've never tried.

(I usually train at 0.0005 learning rate, BTW)",2022-10-25 20:42:12
Comment,4,itsp1zu,,0,1666744850.0,"Oh wow! I'll have to check this out when I get back to my computer.  I went as far as dual-booting Ubuntu to get DreamBooth running with all the memory optimizations and whatnot.  If Accelerate, 8-bit-Adam and Xformers is working on Windows now, that's big!

Any idea about parallelizing? I know the gloo backend for Pytorch is crap for multi-gpu. (Another reason I went Ubuntu)  but will Hugging face accelerate work properly under Windows now?",2022-10-25 20:40:50
Comment,1,itsoyu3,,0,1666744811.0,"DIMM and LMS are possible, but there's a bug in the diffusers right now and you can only use PNDM. There's a work around (future guide update)",2022-10-25 20:40:11
Comment,2,itsowmg,,0,1666744783.0,nice job,2022-10-25 20:39:43
Comment,1,itsovyr,,0,1666744775.0,You can do this with automatic1111. Not sure for what you use.,2022-10-25 20:39:35
Comment,0,itsovgg,,0,1666744769.0,"It being ""fraud"" or not is not the discussion here dude.",2022-10-25 20:39:29
Comment,7,itsouyx,,0,1666744763.0,"[Ok](https://i.imgur.com/1lplxSt.png)

>!a meme of a guy in a group of men and women giving another guy a huge thumbs up
Steps: 20, Sampler: Euler a, CFG scale: 11, Seed: 552397896, Size: 512x512, Model hash: 81761151!<",2022-10-25 20:39:23
Comment,3,itsouqm,,0,1666744760.0,Awesome 👌  and thanks for sharing !,2022-10-25 20:39:20
Comment,1,itsosxs,,0,1666744737.0,"This may be a dumb question but if i set my stable diffusion to always update when i start, is this included?",2022-10-25 20:38:57
Comment,1,itsomqj,,0,1666744659.0,A true hero!,2022-10-25 20:37:39
Comment,1,itsom1m,,0,1666744650.0,"doesn't work 100% though. and some people don't like to use highres. fix. I don't understand why, but that is the case for some people.",2022-10-25 20:37:30
Comment,1,itsol0j,,0,1666744636.0,damn what graphics card do you have,2022-10-25 20:37:16
Comment,1,itsojrw,,0,1666744621.0,"Yes, thank you. I knew where the python was installed at, but it was something else. I have no clue what the issue was. I just yeeted windows and reinstalled and everything is working.   


I haven't tested the hypernetwork training yet but I'm glad I got it up and running again. 

&#x200B;

Also my GPU isnt making any noise anymore, so I have no idea what was wrong. Before it was loud.",2022-10-25 20:37:01
Comment,1,itsoj2i,,0,1666744612.0,"https://reddit.com/r/StableDiffusion/comments/yaq3hu/_/itcia2f/?context=3

https://reddit.com/r/StableDiffusion/comments/y5d0u3/_/iskdfuz/?context=3

Not my computer to type more but here's some examples I made for img2Img.",2022-10-25 20:36:52
Comment,1,itsogr4,,0,1666744582.0,"so the webuser bat file runs, and you do get a message: Running on local URL:  http://127.0.0.1:7860  ?",2022-10-25 20:36:22
Comment,1,itsoeio,,0,1666744554.0,"https://imgur.com/a/kicg24Y

I downloaded the taming-transformers folder and it put in with the other repos and I just re ran the script using:

cd \~/Documents/  


curl https://raw.githubusercontent.com/dylancl/stable-diffusion-webui-mps/master/setup\_mac.sh -o setup\_mac.sh  


chmod +x setup\_mac.sh  


./setup\_mac.sh

&#x200B;

and it still saying ERROR that the repos and model failed",2022-10-25 20:35:54
Comment,2,itsodgb,,0,1666744540.0,But how are they gonna know its AI generated?,2022-10-25 20:35:40
Comment,3,itsoa5i,,0,1666744498.0,"Thanks for buying my oni mask prompt, I thought I recognized the pics you were generating",2022-10-25 20:34:58
Comment,1,itso6s9,,0,1666744456.0,"If you look at the data, they are running Windows 12 on Intel i9-14900K 6.1Ghz

So definitely from the future or being trolled by NVIDIA in their test kitchen.

Also, I figured out the iteration discrepancy. 

If you have a slooow GPU it is seconds per iteration, if you have a fast video card it is iterations per second.   Stable Diffusion changes the reporting based on system speed (clever programmers).  I will scrub the data later now that I know how to report it.

Thus, the 5090 it is 500 Iterations per Second.",2022-10-25 20:34:16
Comment,2,itsny2f,,0,1666744345.0,"I will be following your adventure here with great interest.  I don't know of any tool or workflow out there for what you're asking, but conceptually it sounds promising.  

You're standing on the cutting edge my friend.  Godspeed and keep us posted.",2022-10-25 20:32:25
Comment,2,itsnuio,,0,1666744300.0,"1.6.0 came out like a week ago, and I'm working on the next version already.",2022-10-25 20:31:40
Comment,3,itsnmwv,,0,1666744206.0,"Yeah, well just wait until they decide that some images are more impactful than others.  It'll create a perverse incentive for artists to craft images that get over-utilised by the AI, monetising overtraining on a small subset of images and making Greg Rukowski (whoever the heck that is) a multi-trillionaire.  Like pictures of treehouses with purple and pink leaves?  Good.  Because that's all your gonna get, once they start weighting the payments by utilisation.",2022-10-25 20:30:06
Comment,1,itsnm9c,,0,1666744198.0,"Ars Technica: Shutterstock partners with OpenAI to sell AI-generated artwork, compensate artists.

https://arstechnica.com/information-technology/2022/10/shutterstock-partners-with-openai-to-sell-ai-generated-artwork-compensate-artists/",2022-10-25 20:29:58
Comment,2,itsnm4a,,0,1666744196.0,"Indeed, create a story from a single picture, any picture, wow!...",2022-10-25 20:29:56
Comment,1,itsnl0g,,0,1666744182.0,"I feel you there and it’s most likely not a specific problem of art, but modern era in general. Since the globalization of easy perceiving technologies such as tv and internet, people got to much information to filter. Nowadays only a truly passionate person can become an expert at really specific subject, which is also applies to art. There are good creators, who are deserved to be called an artists, but mostly it’s just a Demi-intelligent social mass trying to keep itself in meaningless trends, that comes and goes away just a day. Of course, this thinking is controversial and probably won’t find many listeners there, but I think it’s a serious ungoing problem that can lead to the fatal humanity condition in near future. The likely upcoming stage for a thoughtful art and creativity is surrealism again, since it requires an intellectual thinking on idea both from author and spectator.",2022-10-25 20:29:42
Comment,4,itsnhvr,,0,1666744142.0,"I'm fine with giving it a different term. And honestly, people who are only using ML to augment their artworks are fine to be called artists. This is just about the people who use it as a 1 button generator. Calling them commissioners or directors is more suitable.",2022-10-25 20:29:02
Comment,1,itsndol,,0,1666744090.0,This is a combination of multiple MJ renders some stable diffusion in painting and then composition in photoshop.,2022-10-25 20:28:10
Comment,1,itsnbgc,,0,1666744061.0,Could you link Stable hoard? is it this one? https://aqualxx.github.io/stable-ui/,2022-10-25 20:27:41
Comment,1,itsn7ia,,0,1666744012.0,The XKCD comic on the proliferation of dozens of would-be-all-encompassing tech standards is exactly what I thought of 🙃,2022-10-25 20:26:52
Comment,4,itsn5rq,,0,1666743990.0,"Perhaps cut and paste pieces of what you want on top of the doll? Sort of like a paper doll? In Photoshop, of course. I _really_ want Stable Diffusion in Photoshop. Going back and forth between it and the web gui is tedious.",2022-10-25 20:26:30
Comment,1,itsn4a3,,0,1666743971.0,"it needs a lot of vram >16GB unless you can run it on Linex, but that could be changed soon.",2022-10-25 20:26:11
Comment,1,itsn05e,,0,1666743918.0,"Lol you, me, and a third of the whole internet!

I'll be honest, although I've heard of people running SD on graphics cards as small as 4GB VRAM, I don't actually know how they do it.  (I'm guessing from your error message that you're on a single 6GB graphics card?) What graphics card are you using? If it's fairly old (GTX 900 or older) then many of the memory-optimizations that have been added to SD won't work.  (Or rather, they just won't actually save memory)",2022-10-25 20:25:18
Comment,1,itsmwqr,,0,1666743876.0,"Prompt:

""hand drawn cute one bumble-bee-gnome face in autumn disguise holding pumpkin, detailed closeup face, concept art, low angle, high detail, warm lighting, volumetric, godrays, vivid, beautiful, trending on artstation, by jordan grimmer, huge scene, grass, art greg rutkowski, photo, realistic, high quality, professionally""


This was the prompt but the picture bearly resembles what I wanted.  Sometimes the results are so random.",2022-10-25 20:24:36
Comment,1,itsmwnd,,0,1666743875.0,It's cool. Great that you have it working. I'd like to see for sure,2022-10-25 20:24:35
Comment,2,itsmr7k,,0,1666743807.0,THIS,2022-10-25 20:23:27
Comment,1,itsmoyo,,0,1666743778.0,"I'm bummed out because you and I later argued, and I hadn't realized you were the person who tried to help me.

At any rate, I have this working now, and I'll share it with you if you want.",2022-10-25 20:22:58
Comment,1,itsml2j,,0,1666743729.0,Can I have an invite? I have a really cool idea and this would be awesome,2022-10-25 20:22:09
Comment,1,itsmkph,,0,1666743724.0,"I would always do my edits at full resolution. In fact, sometimes, I upscale, edit, and then downscale, if there are tricky areas where my edits just don't look good.",2022-10-25 20:22:04
Comment,0,itsmjsp,,0,1666743713.0,So do you think people who use ML to generate and/or augment their art should have their own term?  Or are you saying it's not an art form?,2022-10-25 20:21:53
Comment,1,itsmfh4,,0,1666743659.0,Probably a lack of quality pictures in dataset and it’s perfectly understandable.,2022-10-25 20:20:59
Comment,3,itsm61z,,0,1666743542.0,"I tried this a month or two ago, with limited success. The greyscale of the models definitely messes with the process, because the only way I could get it to do something more vibrant was to crank up the CFG scale and denoising practically to maximum, which runs the risk of it drawing something really weird in place of jacket etc.

The only solution that I could find that was relatively effective was to take the model and draw a somewhat messy version of the clothing on top (it doesn't need to be good, just broad-strokes shapes etc). Then inpaint that with denoising in a kinda middle range.

The bigger challenge, strangely, was the background. Getting it to let go of the empty background was sheer torture.

That all said, there were a few poses I did where the results were just WOW right out of the gate, so it's actually a good strategy. I just couldn't crack it to my satisfaction :)",2022-10-25 20:19:02
Comment,1,itsm3y2,,0,1666743515.0,Thanks a lot,2022-10-25 20:18:35
Comment,1,itsm0wt,,0,1666743477.0,"I tried textual inversion training on Auto1111 today, and got a ""UnicodeDecodeError""... Don't know what went wrong, and after searching around I filed a bug report issue. There are 1000 such issues now on the repo. I'm worried.",2022-10-25 20:17:57
Comment,1,itsm06o,,0,1666743468.0,Their approach is about as reasonable and level headed as is possible given the legal and ethical landscape of ai art generation,2022-10-25 20:17:48
Comment,1,itslzcf,,0,1666743457.0,"How did you able to mask the lines at sec 10?  
And I didn't understand the last part, did you feed the output to the input multiple time or did you just keep generating till you get a better result?",2022-10-25 20:17:37
Comment,-5,itslpo8,,0,1666743334.0,"Well, usually we call people who take photographs ""photographers"". I also think that is an artform, but it is so distinctly different that we gave it another term.",2022-10-25 20:15:34
Comment,1,itslim6,,0,1666743247.0,"Put them in the ERSGAN folder with the other .pth files and restart the web ui, then they should show up.",2022-10-25 20:14:07
Comment,1,itslhmj,,0,1666743235.0,would someone give a current link to this discord?,2022-10-25 20:13:55
Comment,7,itslhf5,,0,1666743232.0,"I prefer the term ""executive director"" anyway.",2022-10-25 20:13:52
Comment,1,itslcp0,,0,1666743173.0,"Problem is, most of the digital painters out there shouldn’t use the word artist too, since it’s mostly being a non-original style or idea, purely commercial work or just a fan art. All those things are misinterpreted as art. It’s just a unfortunate thing of English language, which doesn’t operate another word for this kind of processes.",2022-10-25 20:12:53
Comment,1,itsl937,,0,1666743128.0,it's a colab notebook but it can be converted to any platform with a little work,2022-10-25 20:12:08
Comment,1,itsl8l5,,0,1666743121.0,"Did you try multiple subjects using the same input images in Shivam?

The major difference between the two right now is that Ben haven't implemented class images per subject. 

And he's been making some wild claims about training steps and results he subjectively considers good.",2022-10-25 20:12:01
Comment,1,itskx9z,,0,1666742982.0,"I have always been a) mostly a landscape photographer or abstract artists, and b) really bad at doing touchups beyond Lightroom, so maybe this is a silly question. But are there ever parts of your workflow where it would be *simpler* to do the edits in low res and then upscale? Or would you be concerned that upscaling would skew your edits enough that you have to go back and fix them anyway?",2022-10-25 20:09:42
Comment,1,itskw0w,,0,1666742966.0,Are you planning on releasing further updates to your GUI?  It’s great for shmoes like me that need things to be simple!,2022-10-25 20:09:26
Comment,5,itskq3t,,0,1666742892.0,"Prompt: ""An alchemist's laboratory, cluttered workbench, bookshelves, tinkering supplies, beautiful uhd fantasy art, masterpiece matte painting, perfect composition, soft lighting, extremely detailed"" (768x512)",2022-10-25 20:08:12
Comment,2,itskggf,,0,1666742770.0,"Sure:
1. Turn off pc
2. Get the degree in fine arts 

(*Just kidding*)",2022-10-25 20:06:10
Comment,1,itskg71,,0,1666742767.0,Is it possible to change sampler to Euler/A or DDIM?,2022-10-25 20:06:07
Comment,2,itskg6q,,0,1666742767.0,"Sure.

[https://rentry.org/voldy](https://rentry.org/voldy)

In this page you'll find everything you need to perform the test. It will give you the exact settings. There's also a section called ""Troubleshooting Incorrect Asukas"" where you'll find everything you need to know if your test goes wrong. 

My test did go wrong at first and I was able to fix it. In the end, I got the exact same Asuka image. And now, my models are WAAAAAAY better.",2022-10-25 20:06:07
Comment,1,itsked5,,0,1666742744.0,That is what I am doing. But it's really not ideal as I essentially need a different account for each experimental setup that I want to keep sandboxed.,2022-10-25 20:05:44
Comment,2,itske5u,,0,1666742741.0,It would be interesting if we could get a csv file to graph on your colab as well. It would help to see about training issue,2022-10-25 20:05:41
Comment,2,itskcpc,,0,1666742723.0,"Experimented with using FlowFrames XVFI Interpolation with the frames generated using A1111 Deforum Extension to produce more smooth flowy animations to mimic waves and underwater feel.

&#x200B;

Steps: 50  
cfg\_scale\_schedule : 0: (4)  


Prompt:

a hyper - detailed 3 d render like a oil painting of aquatic animals cresting and crashing tidal waves, surrealism!!!!! surreal concept art, lifelike, photorealistic, digital painting, aesthetic, smooth, sharp focus, artstation hd, by greg rutkowski, bruce pennington, valentina remenar and asher duran

Animation Maths:

""translation\_x"": ""0:(0)"",

""translation\_y"": ""0:(0)"",

""translation\_z"": ""0: (4\*sin(2\*3.141\*t/100)+2)"",

""rotation\_3d\_x"": ""0: (0.5\*sin(2\*3.141\*t/200)), ""

""rotation\_3d\_y"": ""0: (0.5\*sin(2\*3.141\*t/200)), ""

""rotation\_3d\_z"": ""0: (0.5\*sin(2\*3.141\*t/200)), ""

""noise\_schedule"": ""0: (0.07\*(cos(3.141\*t/15)\*\*1000)+0.02)"",

""strength\_schedule"": ""0: (-0.15\*(cos(3.141\*t/50)\*\*1000)+0.65)""",2022-10-25 20:05:23
Comment,1,itskagx,,0,1666742695.0,"Yes and no. I am fine with the Colab itself being untrusted and potentially compromised. Someone could run compute (e.g. mine crypto) on my credits, but damage would be limited. 

The real risk IMHO is access to other data.",2022-10-25 20:04:55
Comment,1,itsk5sf,,0,1666742635.0,"Yes, as I wrote that is what I am doing right now.",2022-10-25 20:03:55
Comment,2,itsjn5w,,0,1666742400.0,"37 is okay, uncheck the fp16 if you want, but that will half the speed of training",2022-10-25 20:00:00
Comment,1,itsjm0f,,0,1666742386.0,super sick,2022-10-25 19:59:46
Comment,1,itsjfdd,,0,1666742302.0,"Yooo I really like your work! I gave you a follow on IG, @gerdegotit, send me a dm on there and I’d be more then happy to answer any questions I can! Resources are a bit limited right now for this, but a friend of mine and I have been really starting to figure some stuff out. So I can for sure give you some pointers that really helped me!",2022-10-25 19:58:22
Comment,1,itsjecl,,0,1666742288.0,"Your understanding is both correct and incorrect.  Only unnecessary data was removed, yes.  But because of how the system works, *any* change to the data will change the results, which makes 1:1 comparisons between the models in this manner functionally impossible.

Even between 1.4 and 1.5, the differences are actually quite minor, but because the model changes, you may see wildly different results, and so people are using these outputs to make claims like ""1.4 is better than 1.5"" because if you run the same prompt and seed, you get a different result, and some people find the 1.4 result more aesthetically pleasing than the 1.5 result, whereas in reality, the comparison is similar to comparing two different seeds (with the caveat that the seed still determines some fundamental portions of the composition).

The main difference between 1.4 and 1.5 is that 1.5 should be better at understanding your prompts, which is why these comparisons are kind of nonsense, because if you had a prompt that 1.4 understood perfectly fine, you shouldn't really expect an improvement out of 1.5.",2022-10-25 19:58:08
Comment,1,itsjdid,,0,1666742278.0,"Never heard of those commands at all, at least for running InvokeAI. Where did you install InvokeAI by the way?",2022-10-25 19:57:58
Comment,2,itsjcst,,0,1666742269.0,They're all great but my favourite is the clown one.,2022-10-25 19:57:49
Comment,1,itsjc79,,0,1666742261.0,I run on runpod.io. This is like this every time I try it on fresh new instances.,2022-10-25 19:57:41
Comment,1,itsjc1q,,0,1666742259.0,"I'll give it a look, thanks",2022-10-25 19:57:39
Comment,2,itsj70f,,0,1666742193.0,holy crab. yet another great leap. i want one 🙈,2022-10-25 19:56:33
Comment,2,itsj4k9,,0,1666742161.0,"No way it will be able to cover all the cost and still be cheap.  
I wouldn't be surprised if they remove the free edition after a few days since it will make them broke in no time.",2022-10-25 19:56:01
Comment,1,itsj42p,,0,1666742155.0,nice bait,2022-10-25 19:55:55
Comment,1,itsizez,,0,1666742097.0,"Hi again! I got past the cudatoolkit issue thanks to someone else’s help and I am able to run the webserver again, however even though I haven’t checked yet I’m not sure if it would fix the “Could not generate image” errors I got every time I entered a prompt last time I had the webserver running. Just in case before I ran the webserver I’ve been trying to look through all the README.md files in the InvokeAI folder and going through them and following their instructions to see if this fixes that issue if it comes up but I’m not sure if that’s necessary, so do you know a solution for the “Could not generate image” error?

I was reading one of the README.md files in the InvokeAI folder to make sure I didn’t miss anything and it stated to try installing yarn optionally. Not wanting to miss anything and making sure InvokeAI works properly this time I tried following the instructions and put “corepack enable” in the terminal, however I got the error “Error: EACCESS: permission denied, symlink ‘..Lib/node_modules/corepack/dist/pnpm.js’ -> ‘/usr/local/bin/pnpm’. I’m trying to figure out how to solve the permission denied errors I’ve been getting since it could be causing issues regarding InvokeAI, but I’m not sure if this is necessary or not and if it would fix the “Could not generate image” issue.

I also ran into “no file or directory” errors for “chmod: -r:” “chmod: 755” and “chmod: npm” after typing in the terminal “sudo chmod u+x -R 775 ~/. npm” and “sudo chown $USER -R ~/. npm”. Are those commands necessary for InvokeAI to run? I also got a  “sudo: in: command not found” error when trying to run “sudo in -snf /bin/env /usr/bin/env” after typing “echo $PATH” and “export PATH=""/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin” Do you know if installing yarn and following all the README.md files are necessary for InvokeAI to generate images or is there a different solution to the “Could not generate image” error for InvokeAI?",2022-10-25 19:54:57
Comment,1,itsiv5c,,0,1666742042.0,Keep it up. I think it is almost obviously best for humanity if artists get to keep ip ownership over their work when it becomes part of an AI. The existence of these models has proven that the data training them is more valuable than ever. Why on earth would we then want to remove the IP incentive to keep making data? It would only help people trying to make a quick buck off first generation ai tools.,2022-10-25 19:54:02
Comment,1,itsitps,,0,1666742024.0,How do we run this through runpod/vast.ai? This seems specifically made for Google Colab.,2022-10-25 19:53:44
Comment,2,itsiru3,,0,1666742000.0,"I think the disincentive issue is actually deeper than  financial. I see a fair number of posts from artists who are in despair not primarily because they are losing money- but because a skill they found to be worth developing and which lent their lives meaning and purpose has been- as they see it- rendered futile.

I actually disagree with this view- I think the capabilites of AI art have been overstated- but there is a non trivial question raised here- what happens when-if- AI really does start to outperform humans at virtually all intellectual and creative tasks?

What impact would this have on the psyche of millions of people? A handful of people will be made rich by AI- many more will have the meaning and purpose stripped from their lives as the skills and abilites upon which they constructed their sense of self worth and purpose are rendered valueless, both financially and socially.

The real threat from AI may not be the hostile sentient singularity we hear so much about- it may be the widespread dissolution of the social fabric of meaning and purpose that holds our societies together.

The unchecked propagation of AI technology may in the end provoke a backlash of surprising ferocity which is perhaps already being forshadowed in the current backlash against AI Art in many online communites- there is something about the ability of machines to duplicate human creativity and intellect that stirs an irrational hostility.

The thing I keep coming back to when thinking about this issue is that word 'futility'.

Soon- I am assured- AIs will be creating all manner of things- they will create art, write novels, compose music, write code, drive cars etc. But this does raise questions;

For example- would you go to watch two robots play tennis? Or teams of robots play soccer? Or any other sports for that matter? The answer is probably no. You might go once, out of curiosity, but would you go again? I don't think so. Why? Because it would be futile- pointless.

So what about a Novel written by an AI? Would you invest the hours required to read that book? This is less clear to me- but here again I think there would be a strange sense of futility in reading the work of a machine that had no real investment in the thing it had made.

Perhaps the odd truth about creativity is that it's not the singular individual act we tend to think it is- it's more of a collaboration between the creator and those who respond to their creation. This is clear in the case of a live music performance where the audience is as integral to the event as the musicians- but perhaps a similar dynamic also applies to such things as the Novel, or even the painting- perhaps it matters more than we realise that the culture we consume is the product of other humans, that what these things actually are is a shared enterprise. 

The first thought I had when someone asked me if I would read a book written by an AI was 'why would I do that?- I would be alone'. It's an odd thought, given the fact that reading is by nature a solitary act. The reader is always alone- but then again is that really the case? To read a novel is to participate in a collaboration with the author in a shared experience. If that author is a machine there is no shared experience- and for some reason that matters more than it rationally should.",2022-10-25 19:53:20
Comment,1,itsiotc,,0,1666741961.0,"Why the negativity my dude/dudette? I'm glad you have seen plenty of this, but I personally have not, nor have I made my own blended models because I'm a beginner. I thought what OP made was cool and I was curious if he would share to help my own journey with SD. What I view as creative clearly isn't the same as yours and that's ok too because everyone's journey is different. Take care and have a good day.",2022-10-25 19:52:41
Comment,1,itsiiwf,,0,1666741886.0,It really does,2022-10-25 19:51:26
Comment,7,itsifg2,,0,1666741841.0,Which model are you using for this?,2022-10-25 19:50:41
Comment,1,itsiekr,,0,1666741830.0,"Depends on what exactly is going wrong in your case. My first guess would be to check if you're using the correct type of slashes for the OS, Windows and Linux use the opposite slashes for file paths.",2022-10-25 19:50:30
Comment,2,itsiejo,,0,1666741830.0,Really cool results! Would you care to share your prompt?,2022-10-25 19:50:30
Comment,1,itsibq7,,0,1666741794.0,Ou la la,2022-10-25 19:49:54
Comment,1,itsi9er,,0,1666741766.0,Oh man this sub is perfect. Or better yet rpg ai art. Probably 90 percent of my generations are potential art for my homebrew rpgs. So fun feeling like I can create images that actually evoke the feeling I'm aiming for.,2022-10-25 19:49:26
Comment,1,itsi5qr,,0,1666741720.0,"Perfect, what script did you use?",2022-10-25 19:48:40
Comment,2,itsi3x3,,0,1666741697.0,"Oh, I actually didn't realize that was possible! Thanks, I'll give it a try.",2022-10-25 19:48:17
Comment,1,itsi0e4,,0,1666741652.0,Not sure offhand but maybe there is something in this list: https://www.reddit.com/r/StableDiffusion/comments/xjqy5y/list_of_stable_diffusion_systems_part_2/ .,2022-10-25 19:47:32
Comment,4,itsi04p,,0,1666741649.0,"I can textually invert on automatic1111 with 6 gig vram, just have to set the image size to 448 x448, instead of 512x512 in the training tab.",2022-10-25 19:47:29
Comment,14,itshyk7,,0,1666741629.0,The same arguments could be made for photography; is that not art?,2022-10-25 19:47:09
Comment,1,itshwg7,,0,1666741602.0,Is there a way to start with a custom ckpt instead of going through huggingface?,2022-10-25 19:46:42
Comment,1,itshtwj,,0,1666741569.0,"Honestly I think they are late to the party, others will catch on, people will start making and combining their own models, effectively creating very precise ways of creating anything imaginable.
For now things are still fresh even though this thing is here for over a year as a concept, but now anyone can run it such just drastically changed the rules of the game.
There is effectively no objectively right or wrong as long as people are aware of the consequences.",2022-10-25 19:46:09
Comment,2,itshpl2,,0,1666741514.0,"soo cute, the lighting is beautiful!",2022-10-25 19:45:14
Comment,1,itshp6r,,0,1666741509.0,"This is a good news, these greedy companies need to die, and new sites should raise something like Ai-stock, with better royalty cuts for both artist and the consumer.",2022-10-25 19:45:09
Comment,3,itshho9,,0,1666741414.0,"I know, but this community got no chill, downvoted by defending someone sharing his content.",2022-10-25 19:43:34
Comment,1,itsh5o6,,0,1666741261.0,Is there a way to run locally?,2022-10-25 19:41:01
Comment,2,itsh4xu,,0,1666741251.0,"I didn't have to do anything special. My models are in this same directory, and they appear properly in the merge dropdowns for me. Something is wrong with your instance of sd - maybe check the logs?",2022-10-25 19:40:51
Comment,1,itsh314,,0,1666741227.0,">I don't claim to be anything but amateur at ML

Could have fooled me

>I understand exactly how it works. I've implemented plenty of ML myself and so I know it's all about the quality of the training data (in this case image-description pairs). I've only ever worked with tiny tensors but the concept is exactly the same. What's your expertise, other than attacking without adding any evidence?",2022-10-25 19:40:27
Comment,1,itsgvap,,0,1666741130.0,u/YacBen Did you see about it here?,2022-10-25 19:38:50
Comment,1,itsgryo,,0,1666741088.0,"I got Ultrasharp and idk how to use it. It's all PTH files and people keep saying to just put it in the folder.

Which folder? Only ckpt files show up in the models folder.",2022-10-25 19:38:08
Comment,1,itsgpat,,0,1666741055.0,Thank you! 🍺🍺🍺,2022-10-25 19:37:35
Comment,1,itsgn4r,,0,1666741028.0,Thank you!,2022-10-25 19:37:08
Comment,1,itsgn16,,0,1666741027.0,Life imitates art.,2022-10-25 19:37:07
Comment,1,itsglfp,,0,1666741007.0,"You sure could start that way, and I probably scaled this up to around 4k before I started breaking it down and adding elements. It's quite relaxing and been my way of chilling for years. With AI the sketching, the beginning part is really helpful and cuts a lot of time off of the the planning phase.",2022-10-25 19:36:47
Comment,4,itsgipn,,0,1666740974.0,"If we're starting to apply that standard to reddit, 95% if it would be gone.",2022-10-25 19:36:14
Comment,1,itsghtz,,0,1666740963.0,https://dilbert.com/strip/2001-10-25,2022-10-25 19:36:03
Comment,1,itsgayh,,0,1666740878.0,"here is the prompt and config I used for final version. I first did it in text2img then multiple times in img2img : 

Twas brillig, and the slithy toves  
Did gyre and gimble in the wabe;  
All mimsy were the borogoves,  
And the mome raths outgrabe.  
(((scary character)))  
Steps: 54, Sampler: DPM2 a Karras, CFG scale: 9, Seed: 3417119912, Size:  
 1152x768, Model hash: 41fef4bd, Denoising strength: 0.8, Mask blur: 4",2022-10-25 19:34:38
Comment,1,itsg32v,,0,1666740779.0,Natively doesn't mean using WSL. Every guide I see for that starts by telling you to install WSL.,2022-10-25 19:32:59
Comment,1,itsg0hl,,0,1666740745.0,"Shutterstock says “don’t upload artwork created by AI.” If you upload artwork that was created by AI, you are lying to them.",2022-10-25 19:32:25
Comment,1,itsfzc8,,0,1666740730.0,That would be absolutely awesome. Assuming most people with a gaming graphics card have around 8GB of Vram,2022-10-25 19:32:10
Comment,1,itsfysh,,0,1666740724.0,code only work w t4 p100 v100,2022-10-25 19:32:04
Comment,1,itsftio,,0,1666740656.0,I had bad results on NovelAI compared to other methods (2 subjects on 1000 and 8000 steps) but this is the only one where I could make 2 characters appear at the same time (even if they don't even have the right hair colors it's not very useful),2022-10-25 19:30:56
Comment,1,itsfqv0,,0,1666740624.0,Great job! Nice of you to share as well. Have you trained Dreambooth and Embeddings yet? I'm trying to figure out what are the best use cases for each.,2022-10-25 19:30:24
Comment,2,itsfnt1,,0,1666740586.0,Firefox,2022-10-25 19:29:46
Comment,1,itsflam,,0,1666740555.0,"Hey u/kabachuha, I'm unable to get a mask working for either the video mask or the image mask - every time I try I get the error of AttributeError: shape.

Does the mask work for you? I was getting this error with the addon as well as this extension.",2022-10-25 19:29:15
Comment,1,itsfka6,,0,1666740542.0,It is not lying . It is my work. Only  use a new tool that is unrecognized to creepy mega photoshot profile platform .,2022-10-25 19:29:02
Comment,1,itsfjzl,,0,1666740539.0,">5090

are you from the future

also 500 secs for 1 iteration?!

that slow as fuck!

op can't math",2022-10-25 19:28:59
Comment,2,itsfi1n,,0,1666740514.0,How are they trying to stop the future????,2022-10-25 19:28:34
Comment,1,itsffuq,,0,1666740486.0,"I did name them correctly. I'll try it again with 3000 steps. Should I turn off the fp16?

I am using 37 instance images. Should I not include 7 of them? I thought a few more would help or at least not hurt.",2022-10-25 19:28:06
Comment,2,itsfdb9,,0,1666740455.0,Definitely not. In 5 years you can expect photorealistic long form txt2video at the current pace.,2022-10-25 19:27:35
Comment,1,itsfcu6,,0,1666740449.0,"I think you're right in that we're misunderstanding each other, and this gives me a good example to work with.

In the case that you suggest, if I generated images of Donald Trump kicking a dog and went to the paper to pitch a story about him, there would be crimes being committed in that. 

I'm not a lawyer, but I suspect in that scenario, Trump could try to sue the paper for libel or defamation, and the paper could press charges on me.. most likely for fraud. It might be a different charge if I gave them the photo and story instead of selling it to them, I'm not sure on the line there.

But, in that case, it would be my attempt to play the image off as legitimate that would be the crime, not the making of the image. It's the story, not the picture.

If I made the exact same picture, but just for fun, and posted it onto some image site so I could show a friend, or just because I thought it was funny, then I would be legally protected. Even if the paper picked up the image on their own, and ran a story using it as the basis, they'd be opening themselves up to legal trouble, but I wouldn't be in legal trouble since I never intended to portray it as an actual photo. 

So, like Deepfakes, AI art generation is a tool that -could- be used for crimes, sure. But the same can be said of a hammer. It's in how you use it. 

There's nothing wrong with using it to make art to hang on your wall or use as your phone's lock screen, or whatever.",2022-10-25 19:27:29
Comment,1,itsfbap,,0,1666740430.0,"I think you and I are coming to the key point of disagreement, since basically all of that aligns for me, except AI versus human generated. The law allows human artists to use their brains however they see fit, because that's good for humanity. I don't see it as necessarily good for humanity to give the same rights to machines and people who control those machines (type in text and press a button). We have stumbled, almost to our own surprise, on algorithms that when applied at sufficient scale, seem to behave just like human brains in a narrow domain.

Instead of thinking how to share the wealth of such algorithms with all humanity (and in particular the original artists), every time this comes up I see people in this community laughing at those artists as doomed dinosaurs. Which is why I've started this conversation multiple times now, and learnt more every time (in amongst the snide comments and mostly silent downvotes). The discussion can be just as mindless in the artist forums, though I haven't tried joining in there just yet.",2022-10-25 19:27:10
Comment,1,itsf81r,,0,1666740390.0,See also this post: https://www.reddit.com/r/StableDiffusion/comments/ycezd8/how_can_i_train_a_sd_model_to_the_pictures_i_have/ .,2022-10-25 19:26:30
Comment,2,itsf6yf,,0,1666740377.0,\^ this. Their faces look like they're 12 years old. I find it highly disturbing and I don't think images like these belongs in this subreddit.,2022-10-25 19:26:17
Comment,1,itsf32c,,0,1666740330.0,"I can't stand all the BS around dealing with social media, so I totally understand.

Not sure why the link didn't work though. It works when I click on it. No worries. I'll keep an eye out for more of your posts here.",2022-10-25 19:25:30
Comment,2,itsezo6,,0,1666740288.0,"Congratulations, my friend. You have a multi-million dollar company on your hands.",2022-10-25 19:24:48
Comment,1,itseyqk,,0,1666740277.0,i have only heard of one example where someone said they got 2 or 3 it/s on Win10 and like 18it/s on linux. i find it hard to believe and tbh i wasn't listening properly it was probably for something specific,2022-10-25 19:24:37
Comment,3,itseuqa,,0,1666740228.0,"Lol, ai has been in photoshop for ages by now. Just not *this* ai.",2022-10-25 19:23:48
Comment,3,itsept1,,0,1666740167.0,"I merely commented on the current legal status of doing so, as a style cannot be copyrighted. And you didn't specify whether or not the images used to train the model were copyrighted ;)

I do think the scenario is a bit unethical. Training a model on a single artist is kind of scummy if the artist did not agree to their artwork being included in the training data.

However, an artist can replicate another artist's style and sell the resulting piece as their own, so that's where this all starts to get a little muddled.

I am no lawyer and all this is currently being debated across the internet (and in courtrooms?). I won't speak on most of it, because I'm not entirely sure what direction it's even headed.",2022-10-25 19:22:47
Comment,1,itsemic,,0,1666740126.0,"I'm not sure now noob friendly these are, but at least perhaps I can point you in the right direction: see the DreamBooth and Textual Inversion list items on this list: https://www.reddit.com/r/StableDiffusion/comments/xjr19j/list_of_stable_diffusion_systems_part_4/ .",2022-10-25 19:22:06
Comment,1,itsekwx,,0,1666740106.0,"yes absolutely, also the diversity of the input images, they need to be from different lighting setups and perspectives and colors and so on",2022-10-25 19:21:46
Comment,1,itseh3s,,0,1666740058.0,"I like the earrings and the shirt, well done!",2022-10-25 19:20:58
Comment,1,itsegjj,,0,1666740051.0,Just make a new Google account to do it.,2022-10-25 19:20:51
Comment,2,itseg06,,0,1666740044.0,"the important thing is the filenames make sure they are correct, and try this negative prompt :

((((ugly)))), (((duplicate))), ((morbid)), ((mutilated)), \[out of frame\], extra fingers, mutated hands, ((poorly drawn hands)), ((poorly drawn face)), (((mutation))), (((deformed))), ((ugly)), blurry, ((bad anatomy)), (((bad proportions))), ((extra limbs)), cloned face, (((disfigured))), out of frame, ugly, extra limbs, (bad anatomy), gross proportions, (malformed limbs), ((missing arms)), ((missing legs)), (((extra arms))), (((extra legs))), mutated hands, (fused fingers), (too many fingers), (((long neck)))",2022-10-25 19:20:44
Comment,1,itseela,,0,1666740027.0,"Pretty much, that's what he's doing. I mean, he largely sees it as the natural evolution--it was, after all, things like photoshop and the internet that gave us this ability to make money selling illustrations and such. Now the market has changed, and you have to change with them. 

hell, he's already got his own SD set up, and when he's thinking about doing some art that say needs someone running, he'll toss in a few prompts, generate a hundred examples, and see if any one gets his creative ideas flowing.",2022-10-25 19:20:27
Comment,6,itsed2l,,0,1666740009.0,"[The portage home.](https://i.imgur.com/QTgADcH.png)

I used almost all of your settings, same seed. I still couldn't get a red kayak though.

Prompt: A cute white Ragdoll cat kitten dragging a kayak attached to a leash in a forest, action scene, low angle, detailed, high detail, dynamic lighting, warm lighting, volumetric, godrays, vivid, beautiful, huge scene, trending on artstation, by jordan grimmer, art greg rutkowski",2022-10-25 19:20:09
Comment,2,itsec0i,,0,1666739996.0,This is both amazing and creepy,2022-10-25 19:19:56
Comment,1,itse90q,,0,1666739958.0,Having spent many hours on this I've found Dreambooth to simply produce better results.,2022-10-25 19:19:18
Comment,6,itse24k,,0,1666739873.0,"    a [cat dressed as a bumble bee:cat:0.50] pollinating a beautiful flower, court scene, low angle, detailed, high detail, dynamic lighting, warm lighting, volumetric, godrays, vivid, beautiful, huge scene, trending on artstation, by jordan grimmer, art greg rutkowski    
    Negative prompt: Disfigured, bad art, deformed, poorly drawn, extra limbs, close up, b&w, weird colors, lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry    
    Steps: 55, Sampler: DDIM, CFG scale: 13.5, Seed: 1467826830, Face restoration: GFPGAN, Size: 512x512, Model hash: 81761151


This prompt was my starting point. I then moved to inpaint to make some improvements (faces- the usual suspect), sent it through to img2img and used the SD upscale script , sent to inpainting for a minor fix, and then did a small additional upscale at the end.  I spent several hours using the SD upscale script trying to figure out how to use it and what all the dials and knobs would do. Then spent a  lesser amount of time on inpainting, thankfully.",2022-10-25 19:17:53
Comment,2,itsdwro,,0,1666739807.0,"""We have decided to prohibit the sale of AI-generated art by our contributors.

In unrelated news, customers will soon be able to buy AI-generated art from us.""",2022-10-25 19:16:47
Comment,2,itsdwni,,0,1666739805.0,"I mean it's a smart way to do it, and their reasoning does make sense legally for why they might not want to touch raw AI images. I wonder how they're going to determine whether your art was used for training.

I actually think this is a pretty cool step forward for AI. And no, I don't care about them charging for the service, you can always spin up a local install and this just makes it more accessible to people without the time to go through that. I'm actually pretty excited to see this show up in their plugins, being able to generate assets right in InDesign will be pretty neat.",2022-10-25 19:16:45
Comment,1,itsdsmz,,0,1666739755.0,"I have implemented a fix for A100 GPUs, use the latest Colab (from the link above) and let me know",2022-10-25 19:15:55
Comment,6,itsdq3d,,0,1666739723.0,"Who is the target audience? Because I don't think many women are going to find those interesting or relatable. Ridiculously proportioned female characters should be kept to horny time unless the target audience wants objectified protags. There's an audience for that, for sure, but it means turning off a large portion of potential readers just for the sake of a few extra cup sizes.",2022-10-25 19:15:23
Comment,1,itsdpmx,,0,1666739717.0,"    a [cat dressed as a bumble bee:cat:0.50] pollinating a beautiful flower, court scene, low angle, detailed, high detail, dynamic lighting, warm lighting, volumetric, godrays, vivid, beautiful, huge scene, trending on artstation, by jordan grimmer, art greg rutkowski
    Negative prompt: Disfigured, bad art, deformed, poorly drawn, extra limbs, close up, b&w, weird colors, lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry    
    Steps: 55, Sampler: DDIM, CFG scale: 13.5, Seed: 1467826830, Face restoration: GFPGAN, Size: 512x512, Model hash: 81761151


This prompt was my starting point. I then moved to inpaint to make some improvements (faces- the usual suspect), sent it through to img2img and used the SD upscale script , sent to inpainting for a minor fix, and then did a small additional upscale at the end.  I spent several hours using the SD upscale script-trying to figure out how to use it and what all the dials and knobs would do, and a lesser amount of time on inpainting, thankfully.",2022-10-25 19:15:17
Comment,1,itsdp1x,,0,1666739710.0,">set COMMANDLINE\_ARGS= --precision full --no-half

Very good. Thanks",2022-10-25 19:15:10
Comment,1,itsdon4,,0,1666739705.0,"Can't remember the exact settings I'm afraid, but I do know the prompt was:

""A jumping man with a red cap and dungarees, eyes and a dark bushy moustache""

Using the jumping sprite as a basis for img2img, it took a couple of generations and playing around with the settings to get a result I liked.",2022-10-25 19:15:05
Comment,1,itsdkho,,0,1666739652.0,Do not run any models other than the authorized ones locally,2022-10-25 19:14:12
Comment,1,itsdk3x,,0,1666739647.0,"This may be why some people are getting poor results, if a person hasn't taken care to ensure their input images have the subject centered and it's center cropped, that may explain poor results?",2022-10-25 19:14:07
Comment,1,itsdj1s,,0,1666739634.0,yes,2022-10-25 19:13:54
Comment,1,itsdg83,,0,1666739598.0,"I'm pretty sure people say whatever comes first to mind when typing online comments. I don't claim to be anything but amateur at ML - not that it's particularly hard to understand, most innovation beyond what I've learnt is in scale. And hey, I use array and list interchangeably, depending on context. But I understand ML and copyright law well enough to know that we're building ourselves a huge minefield here. You seem to think an intricate knowledge of how photocopiers work is required. I've gotten some great input, even amongst the weird gotcha attempts like yours.

Happy to hear more, if you have anything to contribute beyond ""you're wrong, and say weird grammatical structures"".",2022-10-25 19:13:18
Comment,2,itsdfpz,,0,1666739591.0,Thank you! That helps me a lot. It's wonderful how some simple tweaks/ideas can produce really fun results. God bless. 😃,2022-10-25 19:13:11
Comment,1,itsdcil,,0,1666739551.0,"For anyone that wants the image or the model they can be found here: [https://www.thingiverse.com/thing:5587239](https://www.thingiverse.com/thing:5587239)

The model was ""hand made"" by me in Fusion 360 with only that single image as a reference.

Sadly i dont have the prompt, but it was something like ""futuristic, electronic, gun, rifle, alien, sci fi, 3d model, blender"" with a seed of 8824679, 30 steps, and a guidance of 7.5",2022-10-25 19:12:31
Comment,1,itsd67a,,0,1666739472.0,"Wasn't it already possible? I remember people posting that the limit was now 8gv weeks ago.
Too bad anyway fir me, stuck at 6gb",2022-10-25 19:11:12
Comment,1,itsd5sb,,0,1666739467.0,"i did yeah, i tried running 4000 steps and the results seem to be a bit better than what I was getting with the previous repo!",2022-10-25 19:11:07
Comment,5,itsd3oy,,0,1666739442.0,"Good job! How to do it?

![gif](giphy|kQOxxwjjuTB7O)",2022-10-25 19:10:42
Comment,1,itsd2wj,,0,1666739431.0,"Haha you're welcome. Glad to hear you were able to get back to (base), were you able to fix it? I noticed on mine, at least for automatic1111 not invokeai, every day it's getting updated so I have to look up a solution because I always get an error after updating the repo. Don't really know if that's the issue you are having here but yeah",2022-10-25 19:10:31
Comment,1,itscw21,,0,1666739345.0,So you’re saying that if nobody’s likely to catch you then you’re fine with lying about your work?,2022-10-25 19:09:05
Comment,1,itscqwt,,0,1666739280.0,Guidance scale is liek CFG and Denoising steps are steps? or how do I change steps? Also why no fine tuning options for steps?,2022-10-25 19:08:00
Comment,2,itscq4r,,0,1666739271.0,These are photographs!! What is happening?? :),2022-10-25 19:07:51
Comment,1,itscnx2,,0,1666739243.0,This looks awesome. Can you send an invite?,2022-10-25 19:07:23
Comment,1,itsckdo,,0,1666739199.0,"Meanwhile, it could turn out to be an expensive headache for more than a few entities, and a boon to the legal profession.",2022-10-25 19:06:39
Comment,1,itscjlj,,0,1666739189.0,"Is this due to no xformers pre-built?  
If one was to build xformers with A100 (about 45 mins?) would this allow for A100 or is there another problem which prevents A100 being used?",2022-10-25 19:06:29
Comment,1,itscif1,,0,1666739175.0,"use 30 instance images and 3000 steps, make sure the names of the images is just one random name (jgireo) with a number.",2022-10-25 19:06:15
Comment,5,itschkt,,0,1666739164.0,The benefit is having options with the image variations to give you more creative control.,2022-10-25 19:06:04
Comment,6,itscfbj,,0,1666739136.0,"Yes, Auto. 20k steps. This guide helped me figure it out: https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/2670 , and there's good info in the comments. I used the annealing LR posted by the user Heathen there.

The Hypernetwork I shared is actually the second iteration, made with lessons I learned the first time.",2022-10-25 19:05:36
Comment,1,itsce4k,,0,1666739120.0,"Minimum 20 class photos. Gives good output for 1k - 3k steps. $2 for first 1000 steps, subsequent steps are 0.5 per 1000 steps.",2022-10-25 19:05:20
Comment,3,itscapj,,0,1666739077.0,"500 steps is a bit low when the input images aren't ""perfect"", so it's safer to use 1500+ steps",2022-10-25 19:04:37
Comment,1,itsc9nc,,0,1666739064.0,"Well I guess no 3D models are copyrighted, rip",2022-10-25 19:04:24
Comment,1,itsc9d9,,0,1666739061.0,Good human.,2022-10-25 19:04:21
Comment,1,itsc876,,0,1666739047.0,Very very good bot. Well done.,2022-10-25 19:04:07
Comment,1,itsc6q3,,0,1666739028.0,Yes that is correct it should work. I do it currently with Google Colab,2022-10-25 19:03:48
Comment,1,itsc5b9,,0,1666739011.0,Stop speaking out of your butt and literally making things up as you go,2022-10-25 19:03:31
Comment,1,itsc4oh,,0,1666739003.0,"It worked really great :)) 
thanks for the help. I used it together with SD generated imagds to deal with the artifacts of LIA and Thin-Plate Spline Motion methods and it really made a huge difference with just **ONE** frontal image... Incredible method.

Regarding the additional optical flow method, do you see an special-case application for that? Maybe videos with more movement, etc?

Anyway, thanks for the help!",2022-10-25 19:03:23
Comment,1,itsc3xr,,0,1666738994.0,"This is simply not true lol

I'm not sure how else to respond to such a basic falsehood.",2022-10-25 19:03:14
Comment,1,itsc1un,,0,1666738967.0,The deciding case will go to some higher court ( I expect supreme court ) where it will be a bench trial anyways.,2022-10-25 19:02:47
Comment,1,itsbxeq,,0,1666738911.0,the important thing is that the name used doesn't have much weight so that it will not interfere with the trained subject,2022-10-25 19:01:51
Comment,5,itsbs55,,0,1666738845.0,\> 0%,2022-10-25 19:00:45
Comment,2,itsbr0v,,0,1666738832.0,"That's a really good idea.   
You should create a landing page with more details. I think you'll get a lot of interest.   


What's the input required from the user? How many photos, any class photos?  


Isn't the recommended steps 5000? So $20 per model? I'd say you'll make some decent money.",2022-10-25 19:00:32
Comment,2,itsbnui,,0,1666738792.0,how? are you using the latest update? :O,2022-10-25 18:59:52
Comment,1,itsbmgt,,0,1666738775.0,"I think I get it, what do you think of using ""nameofcelebritythatlookslikeme""? that's what I've been doing with joe penna's dreambooth as when I didn't do it and chose some random term it was giving bad results",2022-10-25 18:59:35
Comment,1,itsbj4y,,0,1666738734.0,"I wrestled with googles 15GB limit for ages, then just went 'screw it' and bought the 1st tier upgrade and, omg, it's so, so, so much better and easier with far less fiddling around and much time saved. I highly recommend it.",2022-10-25 18:58:54
Comment,2,itsbimw,,0,1666738728.0,"they done fooled you, boy",2022-10-25 18:58:48
Comment,1,itsbclq,,0,1666738651.0,">Even a jpeg doesn't ""have access to"" the input art that was photographed. You're trying to contrive a distinction between a tensor and an image file.

This is not a fair comparison. A jpeg both intends to replicate the original art, and does to normal human understanding, albeit is encoded in a lossy format. Neural nets neither intend to nor successfully replicate the original data in many cases, including Stable Diffusion.

&#x200B;

>Storing less than the whole of an input, be it a jpeg wavelet transform or a tensor doesn't change it from being a derived work. Indeed, I think even those training models wouldn't argue that the tensor forms aren't copies. They would argue that since the tensors are only used to train the nn then discarded, they're not distributed and therefore fair use. The problem as I see it is that this is literally how wavelet compression works too, just that it's only ""trained"" on a single image until it's good enough to reproduce it sufficiently. That a diffusion model can't produce one input (except Starry Night) exactly doesn't change anything. If I just crudely Photoshop 10000 images into a 100x100 mosaic, it's a derived work of all those original images. Specific rulings of copyright law will allow me to do that (eg. if I scale it to a 200x200 pixel image then so much of the original is lost that I might get a ruling in my favour). This is the sliding scale which you think is so obviously in favour of diffusion models. I think it's not.

So, your example is precisely what I'm talking about. Past a certain point, the transformation is so destructive / reductive that no meaningful part of the original work remains. If I take 10,000 images and put them into a 100x100 **pixel** mosaic, that's not a derivative work in the ordinary, or even likely legal sense of the word (and if it did quality legally, the law is wrong and should be changed).

&#x200B;

The same would apply if I wrote a completely original story about my dog's first vet appointment only using words contained in the Harry Potter books. I could claim it was derivative as a gimmick, but if I was only using standard English words, and not duplicating sentence fragments or novel concepts or words (e.g. ""muggle""), it's not really derivative. If, on the other hand, I used the first paragraph of the book as a ""prompt,"" to write my own wizarding story exploring similar themes, that would be an actual derivative work.

&#x200B;

We can water the word down to mean nothing, but then all work is derivative. You (and I) don't have fully original ideas, you have ideas based on the sum of all of your exposures to the real world, human culture, human art, etc. You might extend beyond the limits of what has previously been explored, but outside of people raised by wolves, people's art, even if they have a unique and valuable voice, is still informed by changes to their brain that occurred as a result of exposure to prior art.",2022-10-25 18:57:31
Comment,1,itsb7lg,,0,1666738588.0,"Links to the streaming platforms:



• [**Brujita** by Throwing Snow](https://lis.tn/Brujita?t=171)

• [**Stars on the Red Carpet** by Arno Wagenhofer](https://lis.tn/StarsOnTheRedCarpet?t=33)

*I am a bot and this action was performed automatically* | [GitHub](https://github.com/AudDMusic/RedditBot) [^(new issue)](https://github.com/AudDMusic/RedditBot/issues/new) | [Donate](https://github.com/AudDMusic/RedditBot/wiki/Please-consider-donating) ^(Please consider supporting me on Patreon or giving a star on GitHub. Music recognition costs a lot)",2022-10-25 18:56:28
Comment,1,itsb7jr,,0,1666738588.0,"I got matches with these songs:

• **Brujita** by Throwing Snow (02:51; matched: `100%`)

Released on `2021-03-31` by `Houndstooth`.

• **Stars on the Red Carpet** by Arno Wagenhofer (00:33; matched: `87%`)

Album: `Hollywood Award Music, Vol. 2`. Released on `2021-03-19` by `Earmotion Audio Creation`.",2022-10-25 18:56:28
Comment,1,itsb6gp,,0,1666738575.0,E5 2680 Xeon with an Nvidia 1060 3GB.  It works.....   512x512 @ 50 steps is about 2 minutes each... but it runs.,2022-10-25 18:56:15
Comment,2,itsb6aj,,0,1666738573.0,Mind sharing what that music is? It's awesome.,2022-10-25 18:56:13
Comment,1,itsb26x,,0,1666738521.0,"Yes, but you don't use syntax like that during discussion. You don't say array instead of list. They aren't interchangeable, but doesn't make sense in the context of what you said.

Because conventions can't just be googled or learnt from a tutorial or an introductory college class. That's where people tend to screw up.",2022-10-25 18:55:21
Comment,1,itsb1ld,,0,1666738514.0,"Making an amazing and transformative collage with incredible artistic skill and content from thousands of works doesn't make one iota of difference. You can sell the collage, but you can't distribute copies of it, unless you want to make thousands of royalty payments.

I'm glad you raised collage. It's an illustrative comparison.",2022-10-25 18:55:14
Comment,14,itsaxhi,,0,1666738463.0,"'just an optimizer'  


It has been 'just the optimizers' that have moved SD from being a high memory system to a low-medium memory system that pretty much anyone with a modern video card can use at home without any need of third party cloud services, etc  


This is a major part of why the community has exploded with new tools, almost daily.  


So as humble as you are being, it's important to remember just how valuable good optmizations are (even small incremental ones add up!).  


So thank you.",2022-10-25 18:54:23
Comment,1,itsawey,,0,1666738450.0,Thanks for the M40 and Tesla data!!!,2022-10-25 18:54:10
Comment,1,itsav7t,,0,1666738435.0,"I used the same prompts with bad results with 500 steps but maybe the quality of the pictures weren't great. 
I'm very happy with I got. Thank you!!",2022-10-25 18:53:55
Comment,1,itsaqjc,,0,1666738377.0,"Thanks for making this. I gave it a shot as my first attempt using any version of dreambooth. I have trained some embeddings in A1111 previously using the same images.

My results so far are that the images look better with DB, but they don't look as much like me. They look like someone that has similar attributes such as a beard, etc, but otherwise, not nearly as recognizable as when I did the embeddings.

I used the default settings in the colab. Any suggestions for what I could do different to make it work better when I try training it again?

I was wearing my eyeglasses in some of the training images, but like I said they are the same images I used to train the embeddings and they worked fine, so I thought they'd be ok for this too.

Should I try doing more than 600 steps or without fp16 next time?",2022-10-25 18:52:57
Comment,1,itsaov0,,0,1666738356.0,Also checking the high Res fix box. SD is trained in square pictures so when you make a tall image you can end up with the totem effect because SD tries to fill each square with your content. Checking the high Res fix box takes care of this.,2022-10-25 18:52:36
Comment,1,itsanzc,,0,1666738345.0,"a bit more 12.7, knowing that windows uses around 1GB so with a 12gb card you got 11 free",2022-10-25 18:52:25
Comment,1,itsakqm,,0,1666738304.0,"It depends on the model you want to use, some are available in onnx format and some are not and need to be converted.

If you wanted to convert https://huggingface.co/nitrosocke/Arcane-Diffusion

Scripts to Convert Model into Onnx (2 step):

* https://github.com/huggingface/diffusers/blob/main/scripts/convert_original_stable_diffusion_to_diffusers.py
* https://github.com/huggingface/diffusers/blob/main/scripts/convert_stable_diffusion_checkpoint_to_onnx.py

Commands to run:

* python convert_original_stable_diffusion_to_diffusers.py --checkpoint_path=""./arcane-diffusion-v3.ckpt"" --dump_path=""./arcane_diffusion_v3_diffusers""
* python convert_stable_diffusion_checkpoint_to_onnx.py --model_path=""./arcane_diffusion_v3_diffusers"" --output_path=""./arcane_diffusion_v3_onnx""

The Example Txt2Img Script With More Features is all setup for using multiple models just have to edit the section near the top

    while model == """":
        model = input('Avalible Models\n1 (sd_1.5)\n2 (another_model)\nPlease Choose a Model#: (or q to quit): ')
        if model == ""q"":
            os.system('cls')
            sys.exit(""Quit Called, Script Ended"")
        elif model == ""1"":
            model = ""./stable_diffusion_onnx""
        elif model == ""2"":
            model = ""./another_model_dir""
        else:
            model = """"",2022-10-25 18:51:44
Comment,3,itsak9g,,0,1666738298.0,This is so cool...there are literally infinite options,2022-10-25 18:51:38
Comment,4,itsai1t,,0,1666738270.0,Did you train the hypernetwork on A1111? What were your settings? How many steps did you need to train it to? It's really hard to find a good and accessible description of how people trained successful hypernetworks like this.,2022-10-25 18:51:10
Comment,1,itsadmc,,0,1666738215.0,"Submitted data for my RTX 3070, Tesla P100, and Tesla M40.

I wasn't sure about s/it... The terminal output puts out it/s unless you're above 1 second per sampling step.  I put both. 

I also ran the old server cards at both full and half precision.  It was a wash on the M40, with marginal speed penalties for half-precision on the P100.",2022-10-25 18:50:15
Comment,2,itsad5r,,0,1666738209.0,I believe you can also share you’re merged model (if you wanted to of course) via hugging face. If you believed it to be of use,2022-10-25 18:50:09
Comment,1,itsabz0,,0,1666738194.0,"Is there actually a guide somewhere for prompt format, I tried looking and failed.I see \[ \], ()  and now (()) and have no idea how it influences things, especially as sometimes the terms within them are repeated outside.

Edit:  parenthesis ()  emphasize , and brackets \[\] de-emphasize terms, and multiples stack to further change it.",2022-10-25 18:49:54
Comment,0,itsaax4,,0,1666738180.0,"Thanks for the answer (first one!)

I don't agree it's that cut and dry though. Whether or not that output would be illegal/infringing has not yet been tested yet and I don't think that, *when* it's argued in court, it'll be argued on ""emulating a style"" either. I'm no lawyer so I have no clue what avenue they'd go down but it would seem prudent to point out that the output from this model *could not exist* without unauthorized use of works under copyright. Any profits made from that output would only be possible with that unauthorized use.

At the very least, do you agree this use would be unfair and/or unethical?",2022-10-25 18:49:40
Comment,1,itsa9wc,,0,1666738168.0,"Actually, if someone makes statement about things he is not able to catch, probably being laughed on the face would only be a healthy reminder to stay with feet on the ground.",2022-10-25 18:49:28
Comment,1,itsa5zm,,0,1666738119.0,"Nah, it kinda works now ;)",2022-10-25 18:48:39
Comment,1,itsa587,,0,1666738109.0,That makes sense according to what I've gathered too. Hypernetworks for styles and embeddings for objects/people.,2022-10-25 18:48:29
Comment,1,itsa413,,0,1666738094.0,Does dreambooth also run locally or only thru the collab?,2022-10-25 18:48:14
Comment,2,itsa3v8,,0,1666738092.0,"I have python blocked with a firewall and it always tries to  connect to some IP each time I launch the webui.aybe to check for those updated models? I don't know. but if you block the connection you wont waste bandwidth. sometimes it won't work without connecting, then I can deactivate the firewall for a moment and it updates gradio or something that is really needed. but in general tou don't need to download anything more once it is already working and all the models are downloaded.",2022-10-25 18:48:12
Comment,1,itsa2f3,,0,1666738074.0,Thank you :),2022-10-25 18:47:54
Comment,2,its9yuj,,0,1666738030.0,"Lol. 

I did some painting in photoshop myself, ""proof of process"" is bullshit.

I keep some of the passages while I work just in case I change my mind about something.

But when I'm done I delete all that stuff, because it just uses up my HDD and creates confusion.

Yet I total own copyright on my work.

And I totally will own copyright when I'll use AI generated art, it will be other people who will need to prove I don't.",2022-10-25 18:47:10
Comment,1,its9vah,,0,1666737985.0,"The training is all performed on their servers with the option to convert to ckpt for home webui use when complete and even sync the file with your google account for easy access and download 

From what I've learned so far, it seems an effectively trained model will take less of SD's resources to render a successful likeness, freeing up resources for compositing the other prompt elements during the image generation. Allowing us to further turn up the CFG scale for a more embedded and fully realised manifestation of our prompts. I plan to explore this further by taking all the training parameters considerably higher. To the point that great renders of the subject would be at almost no cost to SD",2022-10-25 18:46:25
Comment,2,its9tx9,,0,1666737968.0,But I think it's also okay to just manually put the images in the folder that was just added (by running that cell). So now I did that. It just didn't work to use the 'upload button'.,2022-10-25 18:46:08
Comment,6,its9n9f,,0,1666737884.0,"Negative prompts: *bad picture, no, why, SD messed up, not what I wanted, bonus limbs, Alabama*.

/s",2022-10-25 18:44:44
Comment,1,its9m66,,0,1666737871.0,"I'm not sure if we understand each other. Do you want to tell me that when I sell to newspaper fake photo of Donald Trump kicking a dog I don't risk any lawsuit - especially from newspaper? Because that's what I meant by ""display as real"". If that's safe in USA I'm very, very surprised.

I'm sorry that my post sounded like ""strong opinions"". I was in a hurry so I didn't add typical disclaimers like IMO and the like. I don't have many strong opinions - especially for the future. I just express what looks for me most possible. I should add IMO definitely. I'm fan of Socrates and his: ""I know that I know notthing.""",2022-10-25 18:44:31
Comment,1,its9ite,,0,1666737828.0,">`test .png(image/png) - 391017 bytes, last modified: n/a - 0% done`  
`---------------------------------------------------------------------------`  
`MessageError Traceback (most recent call last)`  
`<ipython-input-16-4dfc201c0807> in <module>`  
`48 INSTANCE_DIR=""/content/data/""+Session_Name`  
`49 get_ipython().system('mkdir -p ""$INSTANCE_DIR""')`  
`---> 50 uploaded = files.upload()`  
`51 for filename in uploaded.keys():`  
`52 shutil.move(filename, INSTANCE_DIR)`  
`3 frames`  
`/usr/local/lib/python3.7/dist-packages/google/colab/_message.py in read_reply_from_input(message_id, timeout_sec)`  
`100 reply.get('colab_msg_id') == message_id):`  
`101 if 'error' in reply:`  
`--> 102 raise MessageError(reply['error'])`  
`103 return reply.get('data', None)`  
`104`  
`MessageError: RangeError: Maximum call stack size exceeded.`",2022-10-25 18:43:48
Comment,1,its9ig4,,0,1666737823.0,How do linux users get this working?,2022-10-25 18:43:43
Comment,1,its9fs3,,0,1666737788.0,just replied to somebody else [here](https://www.reddit.com/r/StableDiffusion/comments/ycrjsg/was_testing_rotational_animations_and/its6iwk/) right as you asked =),2022-10-25 18:43:08
Comment,2,its9djg,,0,1666737760.0,Not sure if I have the patience for social media. Your link doesn't seem to work for me though.,2022-10-25 18:42:40
Comment,1,its9dec,,0,1666737758.0,It doesn't.,2022-10-25 18:42:38
Comment,0,its9ddt,,0,1666737758.0,"That would be up to a jury. 

We are in uncharted territory, when it comes to how the law will treat large scale AI vs human production.

There's a vast difference between one artist cribbing the style of another, (which is actually heavily frowned upon in the art world, but obviously not unknown), as opposed to a company worth billions deliberately automating production of art in a style some individual took decades to develop, and then selling that production ability to the general public, so that any newb with enough RAM can crank out stylistic ""deepfakes"" of their work on an industrial scale.

I could see a jury being sympathetic to the plight of the individual artist whose life's work was - lets be honest - used in less than good faith, especially if it was done without the artist's knowledge or consent.

Who knows?

But I sure wouldn't want to be in the defendant's shoes.

Time will tell.",2022-10-25 18:42:38
Comment,1,its964s,,0,1666737667.0,Good luck with that,2022-10-25 18:41:07
Comment,1,its91fj,,0,1666737609.0,"lol, their days are numbered. Dinosaurs need to adapt or die. Be birds not fossils.",2022-10-25 18:40:09
Comment,3,its90sp,,0,1666737601.0,"I mean, they can do similar things. The real difference is just hypernetworks are applied to every image and distort the model, whereas inversion embeddings add a token that is called by it. If I'm getting this right, of course. 

I'm pretty sure either will work. It's just a matter of easier/more efficient, I think.",2022-10-25 18:40:01
Comment,1,its9053,,0,1666737592.0,Interesting. I haven't thought to try them both on top of each other.,2022-10-25 18:39:52
Comment,1,its8zjp,,0,1666737585.0,"Quick note; if a human can do it, an AI can do it. AI absolutely can develop a style, and there’s no reason to imagine why it wouldn’t be able to. That’s what it means to say AI will outpace humanity; it will be able to do everything we can do, _EVERYTHING_, and more. That’s why it’s so unpredictable, and why AI absolutely can (or will soon be able to) develop a unique style on par with and exceeding that of those created by humans.",2022-10-25 18:39:45
Comment,1,its8xic,,0,1666737559.0,Because of ignorance. Someone made a video on how to do the hypernetwork method and it was the first one that I could run locally with my 10GB of Vram so I tried it. It kind of works but as mentioned further down here the training is then applied to all images as long as you have that network loaded. Tonight I was able to train a Dreambooth model so now I can call upon it with a single word. Much better results.,2022-10-25 18:39:19
Comment,1,its8sr2,,0,1666737500.0,This guy ? https://fanbuzz.com/college-football/acc/florida-state/red-lightning-fsu/,2022-10-25 18:38:20
Comment,3,its8qz5,,0,1666737478.0,"It's silly hey.  


Sure I can make some spectacular images with just stable diffusion, with a stack of mucking around and a lot of crap.  


However, an artist that can actually draw well (or whatever they do) will be able to outperform me easily with Img2Img, so really they are just whinging because they don't want to learn a new skill.. whatever, join the rest of humanity that failed to adapt to disruptive market advances.",2022-10-25 18:37:58
Comment,1,its8moh,,0,1666737425.0,"Huh? I say tensor because that's the term used in every software package for AI that I've used. And I said tensor rather than model because they're not directly interchangeable, even if a small tensor does tend to imply a small model. This is a weird tangent to be taking, but okay, I'll go this way too:

Why would you choose to say vector instead of tensor in the context of ML, and why would you use tensor/vector interchangeably with model?",2022-10-25 18:37:05
Comment,2,its8kx8,,0,1666737404.0,I didn't prune the file after training so its a little awkward to share easily atm. I will be taking the training further soon and I'll make sure to trim the model so I can share easily,2022-10-25 18:36:44
Comment,1,its8k2z,,0,1666737393.0,"Sorry I haven't tested it, so I can't confirm but I read somewhere it works.",2022-10-25 18:36:33
Comment,1,its8ivv,,0,1666737378.0,"And I'm saying it sounds like the work you put into finding a promising starting image is the work needed to find the final result with the other method.

Unless you're saying that you prefer only using, say, 30 steps or 40 steps some of the time, which then increases the work even further, and could have been used to just make a bigger batch.",2022-10-25 18:36:18
Comment,2,its8h6g,,0,1666737355.0,"**Defaulted to one day.**

I will be messaging you on [**2022-10-26 22:34:52 UTC**](http://www.wolframalpha.com/input/?i=2022-10-26%2022:34:52%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/StableDiffusion/comments/yd9oks/new_simple_dreambooth_method_is_out_train_under/its8c2t/?context=3)

[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FStableDiffusion%2Fcomments%2Fyd9oks%2Fnew_simple_dreambooth_method_is_out_train_under%2Fits8c2t%2F%5D%0A%0ARemindMe%21%202022-10-26%2022%3A34%3A52%20UTC) to send a PM to also be reminded and to reduce spam.

^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%20yd9oks)

*****

|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|
|-|-|-|-|",2022-10-25 18:35:55
Comment,1,its8fu9,,0,1666737339.0,"Thanks.  


So if I'm basically correct about all the above, then does that mean I can do the following:  


* Use something colab or runpod to train Dreambooth  

* Then download the trained model and use it locally  


I'm using a 3070ti with 10G of VRAM. It's fine for a lot of things, but not capable of training Dreambooth.   


I'm intrigued and excited about the possibility of being to create trained models on leased GPU's, and then run them locally.",2022-10-25 18:35:39
Comment,3,its8c2t,,0,1666737292.0, !RemindMe soon,2022-10-25 18:34:52
Comment,1,its8bv5,,0,1666737290.0,are split-height shoulders a thing in this brand of realism? And maybe her implants slipped upwards or something.,2022-10-25 18:34:50
Comment,1,its8bho,,0,1666737285.0,"Class images are supposed to compensate for the instance prompt that includes a subject type (man, woman), training with an instance prompt such as : a photo of man jkhnsmth redefines mainly the definition of photo and man, so the class images are used to re-redefine them.

But using an instance prompt as simple as jkhnsmth, puts so little weight on the terms man and person that you don't need class images, so the model will keep the definition of man, and photo, and only learns about jkhnsmth with a tiny weight on the class man.",2022-10-25 18:34:45
Comment,2,its890h,,0,1666737253.0,"Every Single Traditional Artist, learned by experience. They learned by looking at the art of others, they call it 'inspiration' or whatever.

&#x200B;

I fail to see how this is any different. Hypocrites.",2022-10-25 18:34:13
Comment,1,its88ok,,0,1666737249.0,You side with your own project because it has a nice Frontpage? Can't argue with that :D,2022-10-25 18:34:09
Comment,1,its8847,,0,1666737242.0,so the 3060 with 12gb is enough or do you need more than 12 gb?,2022-10-25 18:34:02
Comment,9,its877k,,0,1666737231.0,"now that the training is faster, it would be easier to implement it in the gradio interface, it's in the TODO list",2022-10-25 18:33:51
Comment,1,its8705,,0,1666737228.0,"Wow, ok for sure I completely understand! I appreciate the answer and look forward to the feature. 🙏",2022-10-25 18:33:48
Comment,2,its85b5,,0,1666737206.0,">What if I trained a model solely on one living artist's lifetime body of copyright protected work and used that model to generate ""new"" for-profit works? Would that be fair/ethical/legal?

Currently, a artist's style cannot be quantified and/or copyrighted. If you trained an AI solely on a single artist, it wouldn't currently be illegal to sell that work.",2022-10-25 18:33:26
Comment,1,its847r,,0,1666737193.0,"I used collage to make an understandable analogy. But I knew you're gonna go this way, which is why I made sure to add the next line about what the AI is doing is far more transformative than a collage.",2022-10-25 18:33:13
Comment,1,its82hz,,0,1666737171.0,Examples please,2022-10-25 18:32:51
Comment,3,its81t8,,0,1666737162.0,In what way is this creative? It’s the exact same shit everyone else does,2022-10-25 18:32:42
Comment,1,its7zzd,,0,1666737139.0,what's the full error message ?,2022-10-25 18:32:19
Comment,1,its7z6u,,0,1666737130.0,"With *Euler a* if I find a seed that gives a promising image, but the pose is a bit awkward, or the expression isn't what I'd like, I can use the same seed, increase the steps and get a variation on the original. I can vary the steps until I find an image I prefer.",2022-10-25 18:32:10
Comment,1,its7yp7,,0,1666737124.0,"I don't really understand that personal attack, and no, I don't say anything about human artists - for all I know about neurology, our brains could be doing *exactly* the same thing when memorising as is done when training a model and *exactly* the same thing when expressing art as when resolving noise into an image (it even *feels* that way, turning a vague image in the minds eye into an artwork in RL).

But we're not talking about human artists. Unless this has turned into an AI rights discussion.

Copyright law gives a *lot* of leeway to human creativity precisely because it prevents the stifling of human creativity. We're only at the very beginning of AI art and we don't know yet whether it will be good or bad for humanity. We're both welcome to have our hunches. Every argument against technological progress has proven wrong so far, but past performance is not a guarantee of future success. Will all balding action actors eventually be put out of work by deep faked Bruce Willis? Will deep-voiced men never get to play Darth Vader again? Probably not any time soon, but the 2D artists raising their pitchforks won't necessarily be stopped by calling them names, so I'll keep drilling down on the more interesting counters to my arguments.",2022-10-25 18:32:04
Comment,1,its7xur,,0,1666737114.0,hey! don’t you have face consistency problems while using img2img alt?,2022-10-25 18:31:54
Comment,2,its7wzo,,0,1666737103.0,"in the repo, use the A1111 colab, there is an option to use the trained model with a link or a path",2022-10-25 18:31:43
Comment,1,its7whp,,0,1666737096.0,"There's no minefield anywhere. If Github disagrees with hosting my project we will distribute it some other way.

The main sticking point is that stable-core has a more convincing promise on its front page, so I side with that project.",2022-10-25 18:31:36
Comment,2,its7t71,,0,1666737054.0,"This is the only one I have ever needed; [https://www.youtube.com/watch?v=0RLtHuu5jV4&t=317s](https://www.youtube.com/watch?v=0RLtHuu5jV4&t=317s)

The trick is to use it wisely; I try to pick logical keyframe points, and I also clean things up, after processing, with rotoscopes and masks.",2022-10-25 18:30:54
Comment,2,its7rse,,0,1666737036.0,Thank you for that so much ♥ :),2022-10-25 18:30:36
Comment,1,its7rrp,,0,1666737036.0,"as long as you use only one random identifier in the filenames (instead of a sentence), you will get great results",2022-10-25 18:30:36
Comment,1,its7qkr,,0,1666737021.0,"Wow thank you, I appreciate all of your insight it has been incredibly helpful!   Seems like dreambooth training really improves the quality of SD not just in terms of faces but in  realism if I understood correctly.

One last thing, so you are using the colab of dreambooth which runs SD on their servers? Or are you making models on dreambooth then importing it locally on SD webui?",2022-10-25 18:30:21
Comment,3,its7oe7,,0,1666736994.0,"looks like that is being worked on now.

https://github.com/microsoft/DeepSpeed/pull/2428",2022-10-25 18:29:54
Comment,1,its7hqm,,0,1666736910.0,"Very easy to use. It's been in beta for years, but the beta is free.",2022-10-25 18:28:30
Comment,1,its7gi8,,0,1666736895.0,">what do you think the input images are converted to to train the models

Technically vectors are tensors ofc, but who says tensor instead of vector in this case?

Also why would you say small tensor instead of small model?

Idk, there's something very off about the way you said it.",2022-10-25 18:28:15
Comment,2,its7fse,,0,1666736886.0,"I'm getting amazing results with 1500 steps. In the past, I tried with 2000 steps, but it looks much faster now. Just 20 minutes.",2022-10-25 18:28:06
Comment,3,its7fjt,,0,1666736883.0,"I don't have them saved, but a quick google search will show predictions and current trends.

  
Some examples I remember: Law-firms... the lawyers aren't in too much trouble but 1 really good paralegal armed with AI and a solid understanding of how to use the appropriate tools can replace a crew of paralegals.   This kind of thing is already happening. AI being used isn't always obvious either, data science uses a ton of predictive algorithms many of which are in the realm of AI.

  
Medical personnel are an interesting one.  I don't think we'll see anything shrink because demand is so high, but nurses and doctors are going to increasingly use AI to help them diagnose and screen patients much faster than previous.  
This also means more jobs in data science indefinitely.  AI isn't actually 'intelligent', broadly speaking AI is a category of tools and the user of those tools matters.. a lot.

  
Essentially, the more straightforward your job is, and how numerous your position is the more at risk you are of being 'condensed' into a smaller team.

  
a quick search in google scholar yielded lots of reviews on the subject... behind paywalls of course.... easy to get around.",2022-10-25 18:28:03
Comment,3,its7bji,,0,1666736834.0,"I get that. (I mean, some of it is, and you should still be allowed some say in who and how it is used commercially!) At the same time, this new development changes the implications of having put your life's work on public display.

I hope it doesn't lead to more artists fire-walling their work away from the rest of us. The cultural implications of that happening are... the opposite of progress.",2022-10-25 18:27:14
Comment,1,its7b3o,,0,1666736829.0,"Thanks, hope you enjoy!",2022-10-25 18:27:09
Comment,3,its7aze,,0,1666736827.0,"nah, they'll pay out tiny amounts, just as spotify and youtube pay out tiny amounts - the important thing is to avoid issues with photographers and designers, while also being able to hop on the bandwagon. - I mean, no one will be able to make a living from that, but they can't work without them, because that would mean there might be lawsuits waiting to happen (as long as this is all new and copyright is unclear)",2022-10-25 18:27:07
Comment,1,its79ug,,0,1666736814.0,Is EBsynth easy to use and does it cost anything?,2022-10-25 18:26:54
Comment,2,its79pl,,0,1666736812.0,"Largely down to luck, but I've had middling success with parentheses, hyphens and/or underscores. 

You may also wanna look into the AND function if you're using automatic's ui. Though I'm still not super sure how that works.",2022-10-25 18:26:52
Comment,1,its7980,,0,1666736806.0,"1 and 4, depending on if you want a city or nature.",2022-10-25 18:26:46
Comment,1,its78lw,,0,1666736798.0,"If you want to try it, here's a good tutorial to get it set up [https://www.youtube.com/watch?v=ZPEwPEBCY1c](https://www.youtube.com/watch?v=ZPEwPEBCY1c)

Here's the GitHub [https://github.com/lkwq007/stablediffusion-infinity](https://github.com/lkwq007/stablediffusion-infinity)",2022-10-25 18:26:38
Comment,1,its77bx,,0,1666736782.0,they never know. How they never know if the photo or picture up is your creation .You understand the problem ?,2022-10-25 18:26:22
Comment,3,its7707,,0,1666736779.0,To my knowledge everything you have said is correct. I have swapped out my regular 1.4 model for my dreambooth model to be able to use a phrase and generate my character.,2022-10-25 18:26:19
Comment,1,its6xr4,,0,1666736664.0,How do I use a trained model in SD running in collab?,2022-10-25 18:24:24
Comment,1,its6uco,,0,1666736623.0,"Either someone is lying, someone has a preproduction model, or the boys from NVIDIA are having some fun with us.  I did find some leaked photos of the 5090 and it as big as a Desktop computer.  I am assuming about 1000W peak power and $5000 street price.

https://www.reddit.com/r/pcmasterrace/comments/y1xooa/rtx\_5090\_3d\_design\_model\_leaked\_by\_nvidia\_staff/",2022-10-25 18:23:43
Comment,1,its6roh,,0,1666736590.0,"4! Specially the sky and water contrast, is amazing!",2022-10-25 18:23:10
Comment,2,its6qpp,,0,1666736578.0,"""Full-body shot"" tends to work consistently for me.",2022-10-25 18:22:58
Comment,1,its6pui,,0,1666736568.0,"Go to youtube and search ""DreamBooth tutorial""",2022-10-25 18:22:48
Comment,1,its6oz1,,0,1666736557.0,"6GB on Windows, that's the dream(booth).",2022-10-25 18:22:37
Comment,1,its6oid,,0,1666736551.0,"It doesn’t matter where they can tell or not. What matters is that they say you’re not allowed to. If you go ahead and upload an image that was generated with AI, you are violating the terms of service by claiming that it wasn’t. On the chance that there should be some dispute about it, you could forfeit whatever money you made on it and get kicked off the platform.",2022-10-25 18:22:31
Comment,1,its6l3h,,0,1666736508.0,"I have no idea how to get it working :(   
Every time I try to upload my files which are named: metest .jpg, metest (1).jpg, metest (2).png, etc. It gives me an error...

""`MessageError                              Traceback (most recent call last)`""",2022-10-25 18:21:48
Comment,2,its6iwk,,0,1666736482.0,"Prompt was Tom Cruise intensely enjoying a donut, the only other thing I did was set a rotation of 90 (so 1/4 turn per second) - as I said, I was just testing what rotation would do, so it wasn't anything fancy AT ALL... 10 seconds at 10 FPS (so 100 frames total) in auto1111, then made a gif at 30 fps (so 3.333 seconds in length) in ffmpeg. that's all I got.",2022-10-25 18:21:22
Comment,1,its6gzs,,0,1666736457.0,"what's odd is that it's working at all if you've done something wrong haha, but yeah it shouldn't massively change the result",2022-10-25 18:20:57
Comment,1,its6gmj,,0,1666736452.0,"This method is without prior preservation and without an instance prompt, it only uses the instance name taken from the images filenames.",2022-10-25 18:20:52
Comment,1,its6dqe,,0,1666736417.0,"Wow..great!

Must have been a lot of compositing and inpainting, right?",2022-10-25 18:20:17
Comment,1,its68ve,,0,1666736357.0,"I've been stuck on joe penna's notebook since the beginning, as it's been reliable and I had seen that the optimised methods weren't as accurate, has this changed ? How does this compare for one person ? How come we don't need categorisation images anymore and what did they really do ? So many questions !",2022-10-25 18:19:17
Comment,2,its68e6,,0,1666736351.0,its ok 7 lives,2022-10-25 18:19:11
Comment,2,its5zdh,,0,1666736239.0,Great comparison. Thanks.,2022-10-25 18:17:19
Comment,1,its5yyn,,0,1666736234.0,"Yep I trained 1.5 model on her for 6000 steps. I have a theory, and to experiment, I plan on taking all the training parameters much higher.",2022-10-25 18:17:14
Comment,2,its5yye,,0,1666736234.0,"Lol, these clowns again. Should rename themselves Laughingstock. :D",2022-10-25 18:17:14
Comment,1,its5vjc,,0,1666736192.0,"Awesome, thanks!",2022-10-25 18:16:32
Comment,1,its5v5q,,0,1666736187.0,oh god no,2022-10-25 18:16:27
Comment,1,its5u15,,0,1666736173.0,"It's odd that you choose collage as an example. Plenty of collage is considered a copyright infringement, and it varies between jurisdictions.

Collage has the advantage of traditional exception too. Try pasting 100 lines of someone else's code into your 1 million line program and asking it to be ""transformative not derivative"". Or music samples of litigious artists.",2022-10-25 18:16:13
Comment,1,its5s5d,,0,1666736149.0,https://www.reddit.com/r/StableDiffusion/wiki/index/#wiki\_tips,2022-10-25 18:15:49
Comment,1,its5q0t,,0,1666736124.0,Could you give a little more detail on your workflow and how this was done?,2022-10-25 18:15:24
Comment,1,its5nbj,,0,1666736092.0,"3,4,2,1",2022-10-25 18:14:52
Comment,1,its5j1j,,0,1666736040.0,"Can I just point out the repeated use of the word 'contributors'?

The use of that word is, in my opinion, belittling. Or at least it's highly reductive. Seriously, without artists, they would have nothing to sell. They're just a marketplace selling a product and calling their suppliers 'contributors' makes it sound like SS thinks they are part of the actual creation of the art. And they're downplaying how much they rely on the work of artists all while trying to tell them that they are protecting them.

It's corporate speak at its finest, and if I was an artist selling my work to Shutterstock, I would immediately be looking for alternatives.

Because damn, this company...",2022-10-25 18:14:00
Comment,1,its5gg2,,0,1666736008.0,no. shan't.,2022-10-25 18:13:28
Comment,-7,its5dkp,,0,1666735973.0,Literally nothing helpful came out of your comment,2022-10-25 18:12:53
Comment,1,its5c6i,,0,1666735955.0,"Not only could the code in git have malicious code, you also have to consider any packages that get installed and all their dependencies.  Plus models downloaded can have executable code as well.  It's basically a huge security nightmare waiting to happen.  If a user has their phone backing up to their Google drive there might be a way for malicious code to access that as well.  I haven't tried it yet to see if the token has permissions for the backups but it would not surprise me if it did.",2022-10-25 18:12:35
Comment,3,its57ks,,0,1666735900.0,Can you share some of those studies?,2022-10-25 18:11:40
Comment,1,its57f4,,0,1666735898.0,"I mean, they are stock images, so I don't really see a problem with that.

Stock images are supposed to be ""fake"" and just for illustrative purposes.",2022-10-25 18:11:38
Comment,1,its57ax,,0,1666735897.0,"Errr... what do you think the input images are converted to to train the models? I pointing out that my ML experience isn't anywhere near the scale of these models. Whereas you just keep asserting you're right because just because. I'm happy to keep discussing because it exercises my understanding, not to ""fool"" you. What are you trying to do, score points?",2022-10-25 18:11:37
Comment,1,its564a,,0,1666735882.0,"lol you sound like a sovereign citizen quoting a dictionary as law

&#x200B;

Your arguments are so broad and off base you could say that any artist that was inspired by another artist at any point after seeing their art and then went on to make anything even remotely resembling that original was in violation of copy-write law.",2022-10-25 18:11:22
Comment,1,its55jz,,0,1666735875.0,"That's what ""independent creation"" is all about. If the second guy isn't just copying and came to it by himself, you can't sue him.",2022-10-25 18:11:15
Comment,4,its55ch,,0,1666735873.0,"You could add the following to the negative:  
*ugly, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, ugly, blurry, bad anatomy, bad proportions, wrong proportions, extra limbs, cloned face, disfigured, out of frame, ugly, extra limbs, bad anatomy, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, mutated hands, fused fingers, too many fingers, long neck*",2022-10-25 18:11:13
Comment,1,its53gh,,0,1666735850.0,"It is questionable, but after further consideration I don't believe its much different to a 3D artist sourcing reference images to assist building a model. Or a graphic designer drawing inspiration from images to make a digital painting.",2022-10-25 18:10:50
Comment,1,its50b5,,0,1666735813.0,very very beautiful,2022-10-25 18:10:13
Comment,1,its4xqk,,0,1666735782.0,"You're getting the A100 GPU, and is not supported at the moment",2022-10-25 18:09:42
Comment,1,its4swe,,0,1666735724.0,"That sounds like getting to the same place with extra steps. Unless you're arguing that Euler A has a better final result, which I'm not sure I agree with, you're running the exact same process but only seeing half baked images, and then running a second process on top of that.",2022-10-25 18:08:44
Comment,1,its4pb2,,0,1666735681.0,"Try it out here: [https://chrome.google.com/webstore/detail/generate-with-sparkl/gcmlhmhehieamodojnccmnfhhahhnmdp?hl=en&authuser=0](https://chrome.google.com/webstore/detail/generate-with-sparkl/gcmlhmhehieamodojnccmnfhhahhnmdp?hl=en&authuser=0)

We're considering making it fully featured (ie: show the image in the extension instead of linking out), and possibly using the [Stability.ai](https://Stability.ai) API so you don't need to login to our website too etc.

But I think it's rather niche rn - let us know if this is something that you find interesting and we'll continue working on it! :)",2022-10-25 18:08:01
Comment,1,its4pah,,0,1666735680.0,"Use 3000 steps, 30 instance pics. and let me know

negative prompt : 

((((ugly)))), (((duplicate))), ((morbid)), ((mutilated)), \[out of frame\], extra fingers, mutated hands, ((poorly drawn hands)), ((poorly drawn face)), (((mutation))), (((deformed))), ((ugly)), blurry, ((bad anatomy)), (((bad proportions))), ((extra limbs)), cloned face, (((disfigured))), out of frame, ugly, extra limbs, (bad anatomy), gross proportions, (malformed limbs), ((missing arms)), ((missing legs)), (((extra arms))), (((extra legs))), mutated hands, (fused fingers), (too many fingers), (((long neck)))",2022-10-25 18:08:00
Comment,1,its4o1g,,0,1666735665.0,"I get an error when I upload the 30 pictures. It says:   
`test .png(image/png) - 391017 bytes, last modified: n/a - 0% done`  
 `---------------------------------------------------------------------------`  
`MessageError                              Traceback (most recent call last)`  
`<ipython-input-16-4dfc201c0807> in <module>`  
`48   INSTANCE_DIR=""/content/data/""+Session_Name`  
`49   get_ipython().system('mkdir -p ""$INSTANCE_DIR""')`  
`---> 50   uploaded = files.upload()`  
`51   for filename in uploaded.keys():`  
`52     shutil.move(filename, INSTANCE_DIR)`  
`3 frames`  
`/usr/local/lib/python3.7/dist-packages/google/colab/_message.py in read_reply_from_input(message_id, timeout_sec)`  
`100         reply.get('colab_msg_id') == message_id):`  
`101       if 'error' in reply:`  
`--> 102         raise MessageError(reply['error'])`  
`103       return reply.get('data', None)`  
`104`   
`MessageError: RangeError: Maximum call stack size exceeded.`  


  
What do I do wrong?",2022-10-25 18:07:45
Comment,1,its4myp,,0,1666735652.0,"I don't think the class images add to the style, their purpose is to embed the trained model into the class identifier without polluting the rest of the latent space. Also making it easier to evoke the subject. If you wanted to add a style to your renders, you would be better off learning textual inversion. These are fine tuned in the embedding space, not the model and can be evoked from the same single prompt as a trained object. I've not done textual inversion yet but it looks simpler and less resource heavy than dreambooth and can be completed locally on our machines. I plan on learning this feature sometime this week.",2022-10-25 18:07:32
Comment,0,its4iip,,0,1666735598.0,"Even a jpeg doesn't ""have access to"" the input art that was photographed. You're trying to contrive a distinction between a tensor and an image file.

Storing less than the whole of an input, be it a jpeg wavelet transform or a tensor doesn't change it from being a derived work. Indeed, I think even those training models wouldn't argue that the tensor forms aren't copies. They would argue that since the tensors are only used to train the nn then discarded, they're not distributed and therefore fair use. The problem as I see it is that this is literally how wavelet compression works too, just that it's only ""trained"" on a single image until it's good enough to reproduce it sufficiently. That a diffusion model can't produce one input (except Starry Night) exactly doesn't change anything. If I just crudely Photoshop 10000 images into a 100x100 mosaic, it's a derived work of all those original images. Specific rulings of copyright law will allow me to do that (eg. if I scale it to a 200x200 pixel image then so much of the original is lost that I might get a ruling in my favour). This is the sliding scale which you think is so obviously in favour of diffusion models. I think it's not.",2022-10-25 18:06:38
Comment,1,its4iaf,,0,1666735595.0,that site use a lot of photoshot retouching photos ... They can't diference ai or photoshot thing,2022-10-25 18:06:35
Comment,2,its4g6u,,0,1666735570.0,"Yeah, well the current generation in power definitely doesn't want to give up what it would take to do that, but I think the coming generations will warm to it pretty quick.

And I could see that being both the most fun, and the most dreaded part of being an unknown artist, depending on the gig and location.",2022-10-25 18:06:10
Comment,4,its4bk7,,0,1666735514.0,"Original video - [https://pixabay.com/videos/girl-heart-gesture-symbol-asian-129421/](https://pixabay.com/videos/girl-heart-gesture-symbol-asian-129421/)

SD1.5 inpainting model with img2img alt, 39 steps, cfg 2",2022-10-25 18:05:14
Comment,1,its4alg,,0,1666735502.0,"I was able to install SD without any problems. Also, I did use that program you mentioned and the images look incredible.

Thank you!!

Just one last question, If I want to install a pretrained model that people are using can I just drop the file in the folder or it needs to be converted?",2022-10-25 18:05:02
Comment,2,its48ii,,0,1666735478.0,FINALLY One of these scripts that didn't crash multiple times getting up and running. THANK YOU!,2022-10-25 18:04:38
Comment,1,its487c,,0,1666735474.0,Have not even made it that far. I cant code lmao. I just tried to follow some online guides and cant manage to make it work. I will probably just wait until i get an nvidia in a few years or wait until someone makes a windows amd guide i can understand.,2022-10-25 18:04:34
Comment,1,its47ak,,0,1666735463.0,they can't know it .How they can tell if a dog picture is actually a real dog ? They can't . Anyway the abuse in photoshot of that place do unreal thing anyway,2022-10-25 18:04:23
Comment,1,its45p8,,0,1666735443.0,"Simple rule would be that you should only use it anywhere you'd use an illustration, not a photo.",2022-10-25 18:04:03
Comment,1,its3zwf,,0,1666735371.0,"That would cover a Img2Img with a mild setting, not a ""in the style of"".

When it talks about striking similarity, it's talking about similarity of the work itself, not similarity in general style.",2022-10-25 18:02:51
Comment,1,its3zl2,,0,1666735367.0,"Tricky twist nothing is real real ,if you know how work photography or art .",2022-10-25 18:02:47
Comment,1,its3xl0,,0,1666735343.0,"Yeah - I agree - I think it's inevitable isn't it. I really think it will take another generation tho - the current old duffers in the electorate will never wrap their head around it.

re the music thing...

>..scramble to try to get gigs at anyplace they could find them, often including dive bars and clubs and some very shady places to work,

That's literally the most fun part of being an unknown artist! ; )",2022-10-25 18:02:23
Comment,1,its3vp6,,0,1666735319.0,Lol lead the way… by banning it.,2022-10-25 18:01:59
Comment,1,its3s7y,,0,1666735275.0,Isn't this the same thing as training without prior preservation?,2022-10-25 18:01:15
Comment,1,its3qrd,,0,1666735257.0,yes. 4090 is very old technology now 😁,2022-10-25 18:00:57
Comment,2,its3ojk,,0,1666735231.0,"Head's up: if you're getting `CUDA error: an illegal memory access was encountered` on the training step, it's either because you have dashes instead of underscores in your filenames OR because you're running Colab's __PRO__ GPU instead of their __standard__ GPU.

Sorry I can't tell which – those were the things I changed to get it going.",2022-10-25 18:00:31
Comment,1,its3oho,,0,1666735230.0,Are only these permissions available or are all multiples of 512? Are large resolutions processed completely or are they cut into pieces?,2022-10-25 18:00:30
Comment,3,its3oec,,0,1666735229.0,"in the prompt, 

add man before an instance of a man and woman before an instance of a woman and so on, also use this as a negative prompt :

((((ugly)))), (((duplicate))), ((morbid)), ((mutilated)), \[out of frame\], extra fingers, mutated hands, ((poorly drawn hands)), ((poorly drawn face)), (((mutation))), (((deformed))), ((ugly)), blurry, ((bad anatomy)), (((bad proportions))), ((extra limbs)), cloned face, (((disfigured))), out of frame, ugly, extra limbs, (bad anatomy), gross proportions, (malformed limbs), ((missing arms)), ((missing legs)), (((extra arms))), (((extra legs))), mutated hands, (fused fingers), (too many fingers), (((long neck)))",2022-10-25 18:00:29
Comment,2,its3n1w,,0,1666735213.0,Fantastic work! Thank you so much for sharing!,2022-10-25 18:00:13
Comment,1,its3lrp,,0,1666735199.0,"Awww, cute!  Must be going after all that salmon meat floating in the river",2022-10-25 17:59:59
Comment,2,its3h98,,0,1666735143.0,Your personal data is not public ( viewable ). Control over personal data is talking about private data that the world doesn't have access to.,2022-10-25 17:59:03
Comment,1,its3g3e,,0,1666735130.0,"lucky try diference a ""author ""thing from ia generate .Lucky with that .",2022-10-25 17:58:50
Comment,2,its3fku,,0,1666735123.0,"Maybe they will. If it's indistinguishable from an actual photo, and it's free, why not? Someone might even come up with models specifically trained for that purpose.


Once AI images go completely mainstream and everyone gets used to what they can do, photos (real or AI generated) will have the same illustrative weight as drawings in news media.",2022-10-25 17:58:43
Comment,2,its37i4,,0,1666735026.0,"Something like a translation is derivative.

A collage is transformative, not derivative.

And what AI does is far more transformative than a collage.

You're using completely wrong words.",2022-10-25 17:57:06
Comment,2,its36pr,,0,1666735016.0,"Few, if any, of the artists whose work was used to train Stable Diffusion, Midjourney, etc, had any knowledge that their work was included in training the models. If they didn't know, then consent was obviously not given, either.

It's kinda whack that we might all agree that we should have control over our personal data, but when it comes to our life's work... Meh. Who cares? Gotta train AIs somehow.",2022-10-25 17:56:56
Comment,1,its31fp,,0,1666734954.0,"I don't know what everyone is complaining about, the cat's out of the bag...",2022-10-25 17:55:54
Comment,1,its2yhx,,0,1666734918.0,"Yep I also rendered quite a few images of Ana De Armas with standard model, the results were nice but not really accurate or consistent enough for me. A trained model will render more accurately pretty much 100% of the time. It becomes less effort for SD to render and frees resources to be invested in the rest of the prompt and scene elements",2022-10-25 17:55:18
Comment,1,its2xc8,,0,1666734905.0,Astonishing. Cheers ill try get it going later on.,2022-10-25 17:55:05
Comment,1,its2x1q,,0,1666734901.0,"If you read between the lines up there, yeah, I'd say it sounds like Shutterstock is going to work with OpenAI to generate a model where they know the provenance of, and have explicit license to, the training data used.",2022-10-25 17:55:01
Comment,2,its2uvj,,0,1666734877.0,">only ever worked with tiny tensors

Saying tensors makes very little sense in this context. You're not fooling anyone.",2022-10-25 17:54:37
Comment,2,its2s0a,,0,1666734842.0,this is good stuff. wish you the best.,2022-10-25 17:54:02
Comment,1,its2kkn,,0,1666734755.0,Amazing Graphics,2022-10-25 17:52:35
Comment,1,its2j3r,,0,1666734738.0,"I would say that this is half right.

If you ask me, I would say that the Internet opened up a lot of opportunities for musicians to have their music be heard, to collaborate with other musicians, and to reach audiences that they never would have on their own. 

I would also say that the music industry, famous for being predatory to artists, used the transition to the Internet, as did certain tech/music startups, to seize control and wring all of the money out of the industry and give the artists very little. I'm not so sure that's a problem inherent to the Internet as much as it is to an industry that is -very- well versed at milking artists for profit. 

But has it actually gotten worse for 'unknown' artists?  I'm not convinced. Before the internet, unknown artists had to scramble to try to get gigs at anyplace they could find them, often including dive bars and clubs and some very shady places to work, anything to get exposure. The only real chance to make it big came from either being such a hit that you grew organically from clubs and bars until you got big or lucky enough to get noticed, or you sent tracks in like mad to the record labels, hoping to impress some industry producer who would sign you.

Still a lot of disappointed unknown artists in that picture, I'm not sure that I'm convinced that things have actually become worse for them. 

And I'm with you on the universal wage. I think that day is coming, if we don't march to our own destruction first. Automation is taking over more and more of what we need the workforce to do, AI art is just one more example of this.  Sooner or later, we're going to need to learn to unshackle our identities and our livelihoods from our jobs, because eventually, there won't be enough jobs -for- everyone to work.",2022-10-25 17:52:18
Comment,1,its2hu5,,0,1666734724.0,Shady as fuck.  This is how it all ends.,2022-10-25 17:52:04
Comment,1,its24nl,,0,1666734570.0,So OpenAi is retraining Dall-E 2?,2022-10-25 17:49:30
Comment,1,its21a9,,0,1666734529.0,Was bound to happen.  Thanks for the effort.,2022-10-25 17:48:49
Comment,3,its219x,,0,1666734529.0,"That's so oddly specific, I was expecting a list of negative prompts haha. Good to know!",2022-10-25 17:48:49
Comment,0,its203q,,0,1666734515.0,"Derivative works is a **legal term**. I'm not talking about derivative in the art critic sense of ""being too heavily inspired by"", I'm talking about the legal term meaning that the derived work is a violation of the copyright of the original works.

Being too heavily inspired is not illegal - your eyes are not considered a copying device.

If you take a photograph of an original artwork and modify it, you owe royalties to the owner of the original artwork (even though you own the copyright on the derived work). You may not even be *permitted* to make the derivative work (for example if it offends the original creator).

AI generated art is clearly derived from the input art. Are you disagreeing with that fact? In the case of purely prompt based generation (no inpainting etc), it's entirely equivalent as if you selected just one of the input images based of a trivial keyword search and printed it.

The only reason it's not as clear a violation as, say, a photograph, is that the law is ill-equipped and that powerful lobbyists are on the side of ""not illegal"". The AI music side is facing a much tougher battle, since there the money is on the other side.

I've no idea how this is going to play out in the end. Is the visual arts lobby even remotely capable of beating the likes of Google, who's entire business model relies on converting the content of others into representative tensors?",2022-10-25 17:48:35
Comment,2,its1p5s,,0,1666734384.0,"Currently not.

I'm not sure if I'll add it because I don't think it's compatible with anything else in the program.",2022-10-25 17:46:24
Comment,2,its1ojj,,0,1666734376.0,I think op just accidentally time traveled from 2025,2022-10-25 17:46:16
Comment,1,its1l2w,,0,1666734335.0,God I wish that were me,2022-10-25 17:45:35
Comment,1,its1kav,,0,1666734327.0,Tool -->[Here](https://www.birme.net),2022-10-25 17:45:27
Comment,1,its1j0t,,0,1666734313.0,"It's got a lot of momentum and there are loads of people who understand it, and likely the whole of 4chan as a pool of amateur devs and testers. I think it's possible that it'll burn through loads of them and get chipped into a better shape bit by bit, at least until something better catches their eye, but the community is notoriously loyal. It's likely to just slow down, the audience split over a few projects and form a couple of factions before fizzling out or changing direction.

It's a pity though because it could become something modular, a powerhouse of development that feeds and drives other projects instead of cobbling bits together from other places to make something that kinda works against all odds.",2022-10-25 17:45:13
Comment,5,its1c9w,,0,1666734235.0,"Yeah....this seems idk...wrong?

So the model thinks you're a whole new concept instead of a subset of an existing concept, won't it have trouble applying things it learnt to apply to the class to you?

Someone who's trained a model using this method try making yourself do things ( playing a sport, walking, running ) or in different clothes and see if they work..",2022-10-25 17:43:55
Comment,1,its1b4z,,0,1666734223.0,Did you train ana de armas face on this version or just used her name in the prompt?,2022-10-25 17:43:43
Comment,3,its1976,,0,1666734200.0,...5090?,2022-10-25 17:43:20
Comment,1,its18uv,,0,1666734196.0,"Yeah - these are below, well below what I've been able to get done with the Shivam notebook.",2022-10-25 17:43:16
Comment,2,its17j5,,0,1666734182.0,Thanks a lot,2022-10-25 17:43:02
Comment,18,its1714,,0,1666734176.0,"> ""Its authorship cannot be attributed to an individual""

also

>We plan to sell that shit anyway",2022-10-25 17:42:56
Comment,1,its14l6,,0,1666734148.0,">  Added model folder manager: You can now add additional model folders to load models

is it possible to load [onnx models to run on amd cards](https://gist.github.com/averad/256c507baa3dcc9464203dc14610d674)?",2022-10-25 17:42:28
Comment,1,its12fr,,0,1666734123.0,and yet they plan to sell AI generated content on the site,2022-10-25 17:42:03
Comment,1,its10ku,,0,1666734102.0,">People displaying fake photos as real will be prosecuted like today.

I hate to tell you, but unless things are very different wherever you live, you have some serious misunderstandings of the law.  

At least here in the US, there's absolutely nothing illegal about displaying a 'fake' photo. I could photoshop a picture of a pig and put it in the white house, and tell everyone it was a photo of Donald Trump, and I'd be legally free and clear. There's no laws I'd be breaking, and I can think of one or two that would actually shield me from lawsuits for doing it. 

You could be prosecuted for fraud if you used artwork as part of a dishonest scheme, but the imagery themselves would not be illegal. It would be the story and the attempt to damage or steal through fraudulent means that was what would be prosecuted. The images would just count as evidence, at worst.

You have some interesting and strong opinions on the subject, but  I think you really need to spend more time becoming familiar with some of the facts, particularly the legal ramifications associated with this stuff.",2022-10-25 17:41:42
Comment,1,its10fk,,0,1666734100.0,"What is the ""celebrity combination hack"" ?",2022-10-25 17:41:40
Comment,2,its0ssw,,0,1666734014.0,"Trained on 6 people, 2000 steps. Getting hilarious results. I see the people's likeness in the generated images, but certain features are strongly overblown so they're closer to caricatures which is honestly really funny. Very impressed that it could even do this much.",2022-10-25 17:40:14
Comment,2,its0s99,,0,1666734008.0,Cries in 3070,2022-10-25 17:40:08
Comment,2,its0q4k,,0,1666733984.0,12GB+,2022-10-25 17:39:44
Comment,1,its0py6,,0,1666733982.0,"I was hopeful.

I disabled all browser add-ons, extensions, and added the website mentioned in that linked thread AND the specific one I got from the bash file process, and still see the same unable to connect messages.

Thank you for trying to help though.",2022-10-25 17:39:42
Comment,1,its0nm4,,0,1666733957.0,How is that different from https://lexica.art/?,2022-10-25 17:39:17
Comment,1,its0m2t,,0,1666733940.0,"Thanks for that, my (mistaken) understanding was that just 'uneeded' data was removed, so they should be the same.",2022-10-25 17:39:00
Comment,10,its0jqm,,0,1666733914.0,"Lol that woman is sure gonna have a lot of back pain. You guys create nothing  but out of proportion women, it’s hilarious that you think these look good.",2022-10-25 17:38:34
Comment,1,its0hrk,,0,1666733891.0,"I use the automatic1111 gui so I have not used this before, don't know much about programming although I'm starting to study on my own!",2022-10-25 17:38:11
Comment,1,its0dx0,,0,1666733847.0,"Errr, the internet absolutely well and truly decimated the opportunity for musicians to earn money from recorded music.

It literally ruined an enormous part of the industry, the bit where all the 'unknown' artists could make and sell albums.  The only way to make money now is very successful tours, which you can only get by doing the socials.

It ripped the heart out of so many parts of the industry, and we now have subs to spotify and artists getting fuck all.

edit: oh, sorry - yeah of course it \*did\* enable all those stock music sites where musicians can get 50 quid for their song to appear on a horrible corporate video for a plumber.  For now - till AI takes even that away.

And don't get me started on what the digital age has done to journalism, 24 news cycle, and the absolute state of local press (in the UK).  Fake news factories.  It unequivocally made things a lot worse.  I don't understand this It's All Fine Just Suck It Up and Keep Going, Don't Look Down It'll Be Fine, Sunshine attitude.

Don't get me wrong, if I had my way we'd all get a universal wage so artists wouldn't need to make money old school.  But we don't have that, but nevertheless the digital age just keeps carving culture and industries and society up regardless.

I know this sounds luddite (as somebody else accused me of being), but I don't mean to suggest we turn back the clock.  New technology should be built ethically, sympathetically and with purpose.  But I know it's a losing battle, because humans just aren't built like that.",2022-10-25 17:37:27
Comment,1,its0d2e,,0,1666733838.0,"Yes i am not even starting it without it crashing! Haha
So, i downloaded the one it said to do. Which is the sdv1.4 
Can I use the 1.5 pruned? And where do i set the model to?",2022-10-25 17:37:18
Comment,1,its0bh9,,0,1666733820.0,Whats the VRAM requirement?,2022-10-25 17:37:00
Comment,2,its0499,,0,1666733740.0,Aged like milk ?,2022-10-25 17:35:40
Comment,1,its047t,,0,1666733740.0,DeepSpeed works on Windows? When I tried it a week ago it didn't,2022-10-25 17:35:40
Comment,2,its036s,,0,1666733728.0,"Here's a sort of guide I made for a different piece: https://imgur.com/a/HFmTxzp

Basically I to t2i until I get something with a good pose, a high level of detail, and if I'm lucky a passable face.  Then I'll either inpaint or do iterations of photoshop and i2i to clean up all of the weird spots until I'm happy with it.",2022-10-25 17:35:28
Comment,0,its016m,,0,1666733705.0,I created a simple webapp to train dreambooth model https://app.aipaintr.com . Its not free but super cheap $2 for 1000 steps.,2022-10-25 17:35:05
Comment,1,itrzzbs,,0,1666733684.0,"I agree with you here. I think in a few decades the controversy will be gone and AI art will be here to stay, just like many other artistic movements or new mediums. 

And I agree that conversations can turn pretty toxic. You've got people coming with very different groups of interests and concerns, from artists who fear a loss of their livelihood, to artists who are thrilled to explore a new medium, techies excited by the code aspects, art critics or appreciators who have very strong opinions on what qualifies as art, it's a volatile mix.

Add to that that ""Art"" is one of the few words that most people can't agree on a solid definition for, and it's not surprising that the subreddit turns toxic whenever discussion of rights and politics gets brought up. 

And I wouldn't mind it being banned here, but I think you'd need a good team of mods to enforce that hard for a while before it stuck.. and there would need to be subreddits where that kind of conversation was allowed, because there's no way those discussions are fully going away anytime soon. 

As for the community.. Artist communities are very often volatile places. I've never known a place that was specifically packed with artists who didn't have people pushing the boundaries of what was acceptable. The trick is, you can't represent every voice. You can work on finding a sane core of people who can begin to try to draft and articulate some suggestions on how to make things work, but I expect a lot of time initially is going to be fought over useless battles.  I expect a wave of lawsuits from artists who publicly posted their artwork, which was then used to train SD, or some other AI art.

I also expect the vast majority of those lawsuits to fail, but I don't think there's any way to skip past all the drama, sadly.",2022-10-25 17:34:44
Comment,3,itrzuv2,,0,1666733633.0,"many times, drowned by the waifu stuff",2022-10-25 17:33:53
Comment,2,itrzq3i,,0,1666733579.0,the pruned version can't be converted using the conversion script from the diffusers repo,2022-10-25 17:32:59
Comment,1,itrzq07,,0,1666733578.0,"Checkpoint Merger option ?  
With option is better Sum or Add ?",2022-10-25 17:32:58
Comment,2,itrzodh,,0,1666733560.0,"no, I just used the 1.5 ckpt for training and im running it with the VAE file",2022-10-25 17:32:40
Comment,1,itrzo0e,,0,1666733556.0,"Yeah, just download the model and switch to it when you do inpainting. Switch back to regular 1.5 when doing anything else",2022-10-25 17:32:36
Comment,1,itrzmyo,,0,1666733544.0,"Such a nice render! Looks so refined and beautiful! Awesome work  
Is it post-processed in any way?",2022-10-25 17:32:24
Comment,1,itrzmdl,,0,1666733536.0,"Well first of all, A111 is copyrighted. We can't use it as we want without walking through a minefield. By itself that good enough for more open source advocates including myself.

But we're not talking about making another UI here. We're talking about a backend. So A111 is anyway irrelevant. And you're designing this from scratch as you said. So why not join another team which already has a backend and collaborate instead of having two teams doing the same. Especially since the nataili already has the core components working and an existing team with existing implementations based on it such as the stable horde and the many tools around it.

From what I see, the main sticking point is that you want full control to lie with you. Correct me if I'm wrong.",2022-10-25 17:32:16
Comment,2,itrziwo,,0,1666733497.0,"you need to run the first cells, only skip the ""setting up"" cells",2022-10-25 17:31:37
Comment,3,itrzior,,0,1666733495.0,"A Zelda with her Link. As it must be ::)

Many thanks.",2022-10-25 17:31:35
Comment,1,itrzgab,,0,1666733468.0,Have you seen that happen with good informative posts?,2022-10-25 17:31:08
Comment,1,itrzfwd,,0,1666733463.0,Thanks will try tomorrow 😁,2022-10-25 17:31:03
Comment,1,itrz93o,,0,1666733387.0,"for 68 images, use 2000 steps

there is no instance prompt in this method, just rename all the images to on random key word, for example trriaabcd

and for inference, use the identifier as the name of the style

A screenshot of an adventurer standing outside of a house, style trriaabcd",2022-10-25 17:29:47
Comment,2,itrz88g,,0,1666733377.0,Is there a way to run this locally?,2022-10-25 17:29:37
Comment,1,itrz6zn,,0,1666733363.0,Yeah maybe a little. There is a textual inversion of her but it creates too skinny woman so I dont use it :P but I like her face,2022-10-25 17:29:23
Comment,1,itrz6tk,,0,1666733361.0,This is really great.  Can you talk more about your method?,2022-10-25 17:29:21
Comment,11,itrz6et,,0,1666733357.0,"More likely... ""two of your works were included in the dataset of 50 billion works. 10 million AI works were sold in 2023.  Your total royalties are $0.00000000000001.""",2022-10-25 17:29:17
Comment,4,itrz66d,,0,1666733354.0,"So based on what you've told me, I actually just put in to the prompt ""sitting upright"" or ""standing upright"" and that's helping as well. I was getting some real nightmare fuel with the figures lying down.",2022-10-25 17:29:14
Comment,2,itrz4tr,,0,1666733339.0,"Both xformers and deepspeed works on windows now, any other reason why it shouldn't work without Linux/WSL?",2022-10-25 17:28:59
Comment,2,itrz4ro,,0,1666733338.0,So nice!,2022-10-25 17:28:58
Comment,1,itrz0zt,,0,1666733296.0,"just 1:1, the resolution doesn't matter as long as it's above 512",2022-10-25 17:28:16
Comment,2,itrz09e,,0,1666733288.0,Awesome artworks! Love the consistency it creates with her. Base SD is so bad with Zelda and always mixing it with Link!,2022-10-25 17:28:08
Comment,1,itryxn8,,0,1666733258.0,"I simply don't see much of a vision in any of these other project, what is it they wish to accomplish. We already have AUTO1111's WebUI which is very awesome, optimized, and on top of things. None of these other projects announce why I should use theirs over AUTO1111. Has tons of upscalers, strong workflow, feature-complete, etc. Truth is nobody cares what the code looks like, what they care is getting something way better. They're not going to use my stable-core either if it accomplishes more or less the same as 1111.

I'm making this project on my path to make the world's best AI animations, and to make it available to everyone, and this is my dream software to accomplish it!

I believe in my vision more than theirs, simply put. I want to design the core API and lead with my standards and dreams. I'm happy to hear it if you think my approach suck or why I should join their projects instead, I'm leaving the argument out on the court.",2022-10-25 17:27:38
Comment,1,itryxkc,,0,1666733257.0,"How does this work, I just use this model instead of the regular one? Or do I load this separately? I'm using automatics GUI.",2022-10-25 17:27:37
Comment,1,itryw5l,,0,1666733241.0,"Do you have an IG? I like making cats (and other things) in SD. If you have an IG, let me know, I'd love to see more of your work. Mine is: [https://www.instagram.com/electroblep/](https://www.instagram.com/electroblep/)",2022-10-25 17:27:21
Comment,1,itryvsj,,0,1666733237.0,"don't use the word style, just a random identifier is enough",2022-10-25 17:27:17
Comment,1,itryqzd,,0,1666733183.0,"try 1500 steps per instance, 3000 for 2 instances",2022-10-25 17:26:23
Comment,1,itrynxs,,0,1666733149.0,You should choose which ever model you like better. The pruned ema one should be better than the other one technically.,2022-10-25 17:25:49
Comment,1,itrylia,,0,1666733122.0,https://imgur.com/a/sYqInRr,2022-10-25 17:25:22
Comment,1,itryk49,,0,1666733107.0,Is this only for faces or will it work for styles too?,2022-10-25 17:25:07
Comment,10,itryayw,,0,1666733005.0,"All images above are made in 1.5 with the updated VAE and my Hypernetwork at 80%

[You can get the Hypernetwork here!](https://huggingface.co/wavymulder/zelda-diffusion-HN)

More info at that link.

The hypernetwork is trained on screenshots of Zelda from BOTW, so all images featured also have the negative prompt ""cel"" to help with the cel shading bias.

[Here's a comparison of Hypernet Off VS On 80% (not cherrypicked, 36 batch grids on same seed, prompt was ""princess zelda"" with ""cel"" as negative prompt)](https://i.imgur.com/NixQGid.jpg)

And here's your [Link](https://i.imgur.com/ck4Jywg.png) in the comments, SD generated",2022-10-25 17:23:25
Comment,1,itry9qb,,0,1666732991.0,"Really interesting you think such a company would be profitable, let alone successful. Anyone can use AI to generate their own images in minutes, why would they pay someone else for that? It's different when you have to spend hours making something or employing a skillset you don't already have. It takes a minute to learn how to use an AI image generator.",2022-10-25 17:23:11
Comment,1,itry73q,,0,1666732962.0,did you find out a solution?  the removal of concept is also what Im looking for.,2022-10-25 17:22:42
Comment,2,itry60e,,0,1666732950.0,"I love it! I've made some of my cat riding a stand up paddle board, but none came out as good as this.",2022-10-25 17:22:30
Comment,1,itrxyix,,0,1666732867.0,way too many variables.,2022-10-25 17:21:07
Comment,1,itrxwom,,0,1666732847.0,Redditi indirir girerim karşıma çıkana bak. Yetenek abidesi. Kendini cidden çok geliştirmişsin. Tebrikler..,2022-10-25 17:20:47
Comment,-3,itrxusd,,0,1666732826.0,"female portrait?

downvote without even opening thread

&#x200B;

now that I opened though, I'm digging that the boob sizes are going up.",2022-10-25 17:20:26
Comment,2,itrxuma,,0,1666732824.0,"I've been thinking the same thing.

&#x200B;

Every guide so far on Dreambooth and textual inversion are very technical, so I'm waiting for a supereasy fully automated thing... where I just dump some sample photos in a folder and press ""go"". 

&#x200B;

Also, on 6 GB VRAM... =)",2022-10-25 17:20:24
Comment,2,itrxrrc,,0,1666732793.0,"This is exactly what I assumed would happen. A large part of the training of things like SD were stock images, As a stock agency it would be stupid to not see the opportunity to cut out your biggest cost - paying artists for the stock images/videos you sell or the production of the images/videos. 

Once these things get as good as stock photo its over for stock photographers whom by default are making generic images.",2022-10-25 17:19:53
Comment,8,itrxr09,,0,1666732785.0,">He also requested that I don't share the prompt for these as he had a hand in most of the keywords/tokens that were used.

Sounds like he doesn't want us to know what his fantasies are",2022-10-25 17:19:45
Comment,12,itrxpwn,,0,1666732773.0,"Yes.  Figures that get distorted by laying on their sides or seen from a side profile lying  down like this can be fixed using im2img and rotating the input image 90 degrees clockwise first.  It will then understand how to render a character that is not distorted.  Needs a vertical orientation, SD is terrible at horizontal and sideways prone poses.  But works great with vertically aligned standing figures.

When you get an image you're happy with from the process simply rotate that image back 90 degrees counter clockwise.  This ""trick"" works with every subject that difficulty being rendered while horizontal, which is almost everything that isn't horizontal aspect in the data but vertical.",2022-10-25 17:19:33
Comment,1,itrxodg,,0,1666732756.0,[https://www.reddit.com/r/StableDiffusion/comments/yd7uok/evolve\_a\_zoom/](https://www.reddit.com/r/StableDiffusion/comments/yd7uok/evolve_a_zoom/) this took an evening on a 3060 laptop,2022-10-25 17:19:16
Comment,1,itrxo8y,,0,1666732754.0,"It's really weird that this is the hill they choose to die on. There's so much misattributed content already in the shutterstock catalog. Plagiarism, public domain works, things so generic the copyright office wouldn't touch it... but AI is problem? Well, it's cheaper to address",2022-10-25 17:19:14
Comment,1,itrxmj0,,0,1666732735.0,The process of training on a concept kind of sucks right now.,2022-10-25 17:18:55
Comment,1,itrxhpk,,0,1666732681.0,"I'm using SD UI, here's a screenshot of my settings, including prompt.

[https://i.imgur.com/1XK9zxG.png](https://i.imgur.com/1XK9zxG.png)",2022-10-25 17:18:01
Comment,2,itrxdxd,,0,1666732640.0,Thanks! Joined :),2022-10-25 17:17:20
Comment,2,itrxby4,,0,1666732618.0,"I don't know why ""being hit by a nuclear explosion"" makes such colorful images but it do",2022-10-25 17:16:58
Comment,3,itrxb6q,,0,1666732609.0,"Ok, fine. You don't like that one. How about this one:

If I put all the same words in the exact same order as J.K. Rowling, I can produce Harry Potter. So who gets the copyright? (Obviously Rowling. It doesn't matter if someone else comes along later and duplicates it exactly.)",2022-10-25 17:16:49
Comment,1,itrx990,,0,1666732588.0,"I've been playing around with getting two separate subjects into my images and just has some success with the following process. Unfortunately I don't have the full prompts, as I didn't realize that file names don't save the whole prompt if it is too long. These are missing the names of two artists that were slapped on at random. 

Image 1: (img2img) Prompt - Lovecraftian sea monster breaching the ocean. pirate ship firing it cannons. in a storm, ocean scape, horror, hyperrealism, storm, dark, detailed textures,  photorealistic 3 d

Settings: Euler A, Steps 30, CFG 7, Denoising 0.2

Image 2: (inpaint with mask over the right side) Prompt - pirate ship firing it cannons in a storm, ocean scape, horror, hyperrealism, storm, dark, detailed textures, photorealistic 3 d

Settings: Euler A, Steps 30, CFG 7, Denoising 0.75

Image 3: (img2img) Prompt - a Lovecraftian monster breaches the surface of the ocean, ocean scape, horror, hyperrealism, storm, dark, detailed textures, photorealistic 3 d

Settings: Euler A, Steps 30, CFG 7, Denoising 0.5

Image 4: Flipped the sea monster in Paint 3D with magic select

Image 5: (txt2img) Prompt - a Lovecraftian monster breaches the surface of the ocean, ocean scape, horror, hyperrealism, storm, dark, detailed textures, photorealistic 3 d

Settings: Euler A, Steps 30, CFG 7

Any suggestions to the process? Specifically of getting multiple different subjects into an image. I am pretty ignorant of the deep mechanics of SD and kind of playing with the few tools I know.",2022-10-25 17:16:28
Comment,2,itrx7vr,,0,1666732572.0,6GB is the magic number for me,2022-10-25 17:16:12
Comment,1,itrx7cq,,0,1666732566.0,"Prompt:

picture of extremely cool and suave anthropomorphic male Ragdoll cat, jet black jacket, dark sunglasses, glare on glasses, high fantasy, highly detailed, detailed faces, smooth, sharp focus, chiaroscuro, dnd, digital painting, concept art, rossdraws and moebius and jon mcnaughton


  
Negative prompt:

Disfigured, bad art, amateur, poorly drawn, ugly, flat, deformed, poorly drawn, extra limbs, close up, b&w, weird colors, lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry


  
Steps: 50, Sampler: PLMS, CFG scale: 9, Seed: 3574365338 + a lot of inpainting",2022-10-25 17:16:06
Comment,2,itrx6lp,,0,1666732558.0,"I don’t have a lot to say, just that it looks interesting and cool.
Have a good one",2022-10-25 17:15:58
Comment,1,itrx66e,,0,1666732553.0,"It will be only about real, not altered photography of course. People displaying fake photos as real will be prosecuted like today. I can see no problem with photography. You could photoshop anything 10 years ago but you didn't go with it to the press.

Art will be mixed becasue there will be no tools to verify originality of the works. Especially when established artists will also use AI. However, names will matter too in art. Works signed by known artists wil sell for much higher prices.

We will learn to live with fake images. This process already begun.",2022-10-25 17:15:53
Comment,1,itrx5pw,,0,1666732548.0,that would be absolutely amazing,2022-10-25 17:15:48
Comment,1,itrx4zy,,0,1666732540.0,"I use a recent laptop with a 3060 GPU and works fine, a bit faster might be nice, but it is sufficient.",2022-10-25 17:15:40
Comment,2,itrx1up,,0,1666732506.0,"It depends on the sampler, and more importantly, the complexity/content of the prompt. In most cases, 20-50 should be sufficient. Some prompts will be better with more steps, but it's impossible to know without testing it. In most cases it's not worth it, and better to simply do more prompts, because there's no guarantee that even 10 prompts at 150 steps will give you what you want, while 30 prompts at 50 steps will be more likely to give you something you'd want.

Higher number doesn't mean more accuracy. Neural networks essentially compete with each other, and that's what steps are. Each steps are these neural networks arguing over what to do, and what data to give importance or not. The more steps, the more it argues. But after a certain point, no amount of arguing will change the outcome, or change it much.",2022-10-25 17:15:06
Comment,2,itrwp89,,0,1666732364.0,"I'd have said the 3rd one because it reminds me of the Game Overlord 2.. and because it's something I don't often see in subs like these.

Hanging said that I vote 4.

All the others are good too.
But 1. Is very generic in the scope of AI generated Art (very beautiful though!)
And 2. Is gorgeous.. but does not convey an epic feeling like the other 3.",2022-10-25 17:12:44
Comment,1,itrwp5g,,0,1666732363.0,"So, assuming you just want to do one image at a time, how is this any different from just using something like automatic1111 to upscale using whatever model and then running it through again?",2022-10-25 17:12:43
Comment,1,itrwm3r,,0,1666732329.0,"thanks so much, hope you have a wonderful day",2022-10-25 17:12:09
Comment,1,itrwkx6,,0,1666732316.0,"To be honest, the accuracy and usability for this, for me, is far below that of the Shivam notebook. Most of the subjects looked like bad Daz3D models in the one that I trained this evening, and no amount of CFG tweaking or () [] etc. helps.",2022-10-25 17:11:56
Comment,2,itrwig2,,0,1666732289.0,This looks like Anya Taylor Joy.,2022-10-25 17:11:29
Comment,1,itrwchg,,0,1666732223.0,"Sure, if Mr X has agreed to have his works used in the training data.",2022-10-25 17:10:23
Comment,1,itrw6bo,,0,1666732156.0,"However... If they ask you when submitting them ""*Have these been made by AI or with the assistance of an AI*"" you can claim all the stuff you want about whatever it is an Yes or No question and you lying is you commiting fraud with intenion.",2022-10-25 17:09:16
Comment,1,itrw5p9,,0,1666732149.0,I'm running a 10 year old desktop (AMD FX-6300 3.50 GHz) and a new GTX 2060 12gb graphics card.  It runs well enough to generate a 512x512 50 steps image in 10-12 seconds.  The GPU is what matters the most for SD.  I wouldn't buy a card with less than 12GB VRAM.,2022-10-25 17:09:09
Comment,3,itrw33w,,0,1666732121.0,"Thanks!

https://www.reddit.com/r/dndai/",2022-10-25 17:08:41
Comment,2,itrw0yq,,0,1666732097.0,https://www.reddit.com/r/pcmasterrace/comments/y985os/comment/it4wtbl/?utm\_source=share&utm\_medium=web2x&context=3,2022-10-25 17:08:17
Comment,3,itrvw8f,,0,1666732045.0,Shutterstock and every other stock image service will soon go extinct. There's literally no need for them anymore.,2022-10-25 17:07:25
Comment,2,itrvvad,,0,1666732034.0,"No... Not as simple as that. Not at all. You can take a similar photo, you just can't say that it is THE SAME photo or similar photo on purpose of being that photo by Adam's. You can make similar photo with different context as long as you show the intention clearly.

The jurisdiction in Finland has 3 parts in defining who gets copyright. 1. Must be a natural person 2. Show personality of that natural person 3. Must show freedom of thought and will.",2022-10-25 17:07:14
Comment,2,itrvmp3,,0,1666731941.0,Doesn't have to be a perfect copy to run afoul of copyright law. It would be up to a jury to decide if IP infringement has taken place. The right lawyer with the right jury could succeed at getting damages for his client.,2022-10-25 17:05:41
Comment,1,itrvmjp,,0,1666731940.0,"So I tried using the Colab following the instructions. I used 48 pics that I had used previously on the 1.4 model using DreamBooth on a runpod (results were brilliant with this).

Results from the Colab were kind of janky, faces are reproduced are distorted and its no where near as good as my existing model. I tried 600 steps and I'm rendering with Euler.",2022-10-25 17:05:40
Comment,1,itrvmea,,0,1666731938.0,I'd play a Disco Elysium like game as El Risitas. That second image is incredible.,2022-10-25 17:05:38
Comment,2,itrvlol,,0,1666731930.0,This genuinely looks really cool! I can’t wait until it’s publicly released! :),2022-10-25 17:05:30
Comment,1,itrvkn7,,0,1666731920.0,Can’t wait. I have a RTX 3060 12gb and would love to do this although I’m happy it can crush SD.,2022-10-25 17:05:20
Comment,2,itrvhse,,0,1666731889.0,"Messing with img2img alternative test

a dslr photo of a cute green cat

negative prompt: multiple tails, dull, bland, ugly

seed: 3678211369",2022-10-25 17:04:49
Comment,1,itrvepp,,0,1666731857.0,"Modernist got shat on when they first started to do their think. Picasso spent years trying to unlearn all the classical things he had learned.

I agree we need to work on the public image of AI-assited art... However... Just looking at this subreddit. I'm actually kind ashamed to use my real name in connection to any of this directly. There are... so fucking toxic people with such toxic attitudes fighting against other toxic people with toxic attitudes on both sides.... and then attack people in the middle (like me) who tries to negotiate both worlds.

How the fuck you work on perception of a community that chants ""*Fuck copyright, fuck the artist, fuck the corporations! We are entitled to everything!*"" and then is desperately trying to make even the slightest hiccup in to a life and death drama.

Like in this case. We have a private company that doesn't want AI generated stuff to their platform for reasons x,y,z with motivations r,i,j.  And the comment sections is fucking dumbster fire of toxic waste every time there is thread on these matters. So much so that I actually asked the mods to regulate or ban these topics... just so this subreddit would be less toxic as those people would slowly move elsewhere in seek of that drama.",2022-10-25 17:04:17
Comment,3,itrvdto,,0,1666731848.0,"I was talking about Midjourney, not DALL-E.

You are wrong about Midjourney's TOS however:

**""Subject to the above license, you own all Assets you create with the Services. This does not apply if you fall under the exceptions below.""** (this is a grant of copyright to paid users; the exceptions cover non-paying users, who are granted a creative commons license, and corporate users, who have different payment terms).

The passage that reads ""Midjourney is an open community which allows others to use and remix your images and prompts whenever they are posted in a public setting. By default, your images are publically viewable and remixable. As described above, you grant Midjourney a license to allow this. If you purchase a private plan, you may bypass some of these public sharing defaults"" is granting ***Midjourney*** a license to remix your work, not the general public.

For example, I have a paid user sub and privacy turned on. Images I create are explicitly owned by me according to this TOS, and I'm only granting Midjourney the right to remix.

EDIT: Furthemore, Midjourney wouldn't have to distinguish between licensing when it comes to paid vs. non-paid if no copyright was involved. By default, the copyright to Midjourney images would be held by Midjourney according to this TOS, granting non-paid users a creative commons license. Only paid users receive full rights. In both cases, the images can be generated in public view, but that doesn't change the licensing status Midjourney lays out in the TOS. That is, if I produced images in public view as a paid user, it doesn't mean my images lack a copyright and all the rights that come with it. The TOS is still explicitly granting me one.

As for your comment: ""You have to agree though there is a HUGE difference in effort and the ""sweat of the brow"" argument wouldn't hold up in court for me typing a sentence and press generate 1000 times.""

I do not agree.",2022-10-25 17:04:08
Comment,1,itrvcyg,,0,1666731839.0,"Anyone saying AI art, as a concept or technology, is blatantly unethical is misguided IMO; as many folks argue, I agree, it's simply a fascinating new tool that will change the way visual (and other) art is generated forever. The ethics/legality comes in to play when you understand that the given output of that tool is only a result if its specific inputs; different inputs will produce different outputs. It's my opinion, and I'm sure the courts are going to agree at some point in the near future, that using copyright protected works without consent as training data is wrong/unethical. And I'm not going to debate the ""well I can see and learn from it"" argument.

As for the ""you can't trace it back to any artist"" argument, search this sub for the ""iPhone case"" thread. Maybe an outlier, sure, but it throws that argument on its head.

And I'll ask you a rhetorical question that I've asked a ton of folks and have never received an answer: What if I trained a model solely on one living artist's lifetime body of copyright protected work and used that model to generate ""new"" for-profit works? Would that be fair/ethical/legal?",2022-10-25 17:03:59
Comment,1,itrvbe7,,0,1666731822.0,Is it?  There's a reason every OSS project you've ever likely heard of contains a license file.  Because removing this ambiguity is really important to everyone involved.,2022-10-25 17:03:42
Comment,1,itrv7q2,,0,1666731783.0,I also noticed that even though SD has more robust ecosystem the results from dall-e are more aesthetically pleasing from the get go as well as taking all parts of my prompt under consideration when creating the final.image.,2022-10-25 17:03:03
Comment,1,itrux35,,0,1666731668.0,Have you tried the NovelAI model?,2022-10-25 17:01:08
Comment,3,itrutw6,,0,1666731634.0,Great. Thanks a lot. Using your repo every day for textual inversion. I will go back to try again Dreambooth,2022-10-25 17:00:34
Comment,2,itrusde,,0,1666731618.0,Anybody know if there's an upcharge for extra fingers?,2022-10-25 17:00:18
Comment,3,itrun2m,,0,1666731563.0,">Meta will SYNTHESIZE THEIR LIVES to populate the metaverse!

Oh my god, of course you're right! I can't wait!",2022-10-25 16:59:23
Comment,3,itrufpt,,0,1666731485.0,Nataili is not starting from scratch. It's based on popular sd webui and already supports most things. Why don't you consider joining forces with sygil. The code is OSS so you'd still own whatever you contribute,2022-10-25 16:58:05
Comment,2,itru6u0,,0,1666731389.0,"Ooh, I might have misunderstood.  You're getting CUDA out of memory before you even start generating images? Which version of the CKPT file are you using?  You might want to use a pruned one.",2022-10-25 16:56:29
Comment,2,itru3ru,,0,1666731356.0,">I think what they may be more worried about is being a huge lawsuit magnet.

Or stock photo companies might be the ones planning to launch a huge lawsuit against AI software companies that don't pay them to learn from their images. A lawsuit forcing everyone to pay for usage of the basic models would at least stop things like stable diffusion from being given away for free as open source software.",2022-10-25 16:55:56
Comment,1,itrtxan,,0,1666731288.0,"Step 1: reduce your batch size.  If you're trying to generate more than one image at a time, that uses more memory.

Step 2: reduce your generated image resolution.  Bigger image: more memory.  The upscalers that are packaged with most versions of SD tend to be less memory-hungry than the image generation itself.  Generate smaller, then upscale. (Especially if you're working bigger than 512x512... The model's built to make images that size natively, and going bigger is kinda outside SD's original scope.)

Step 3: try a different frontend.  I've never used Deforum, but the first version of SD WebUI (from like, the beginning of September) was much more memory hungry than Automatic 1111 (which is what I use now)",2022-10-25 16:54:48
Comment,1,itrtw30,,0,1666731275.0,"Well considering new AI let's people effortlessly remove thier watermarks, and eye for an eye I guess?",2022-10-25 16:54:35
Comment,3,itrtvgd,,0,1666731269.0,"a photo of a human skull AND a fire tornado, ((epic)), ((enchanting)), detailed, 4k, Leica 35mm F2.8, Fuji Superia Reala 100

I forgot to mention, I know the AND function works in Automatic1111's webui but I'm not sure about elsewhere. Not much to the prompt really, the photography terms can be switched out with other types/left out all together, and the 'epic' and 'enchanting' can be replaced with other descriptors, really you can do whatever.


EDIT: Forgot the other two -

a photo of a sewer tunnel AND a photo inside a cresting wave, ((epic)), ((enchanting)), detailed, 4k, Leica 35mm F2.8, Fuji Superia Reala 100

a photo of a ((tarantula)) AND rebar rubble, ((epic)), ((enchanting)), detailed, 4k, Leica 35mm F2.8, Fuji Superia Reala 100",2022-10-25 16:54:29
Comment,3,itrtr5b,,0,1666731224.0,"Easiest way I have seen so far, working well for me. https://github.com/n00mkrad/text2image-gui/blob/main/DreamBooth.md

A few other ways
https://www.reddit.com/r/StableDiffusion/comments/ycmpu3/trading_with_dreambooth_100_local/",2022-10-25 16:53:44
Comment,1,itrtm5v,,0,1666731171.0,"As I said, I don't deny that AI art -can- be generated that way. And I didn't know there was an NAI subreddit, but I'm not surprised that it isn't a bastion of artistic integrity. 

The ""1girl"" level of artwork is much like stick figures with breasts being drawn on bathroom walls. People have done it ever since we learned how to draw, but it could be hotly debated as whether or not that counts as 'art', and on what levels. 

What set me off on this recently was I came across an established artist who had begun branching out into AI-assistance in his artwork. He posted some of his recent work, and AI art critics really descended on him, treating his artwork as if it were worthless, even when he pointed out that he hand-painted the figures, and just used AI to detail the background.   It was pretty vicious and hateful, and really made me see that we need to work on the public perception.",2022-10-25 16:52:51
Comment,2,itrtle4,,0,1666731164.0,Looks like it's [this one](https://www.reddit.com/r/dndai/comments/ycomut/c2_the_dark_lord_of_the_valley_of_barovia_count/),2022-10-25 16:52:44
Comment,4,itrtkza,,0,1666731160.0,"As others have mentioned, artistic styles can't be copyrighted. Substantial similarity relies on the image looking so similar to an existing image that there are no doubts the person was attempting to copy it. AI art can run afoul of this with simple images (generating copyrighted characters like Pikachu, for instance) but good luck getting Stable Diffusion to replicate an actual painting by Greg Rutkowski.",2022-10-25 16:52:40
Comment,0,itrtk4r,,0,1666731151.0,Don't listen to this guy.  We need speed not VRAM.  :-D,2022-10-25 16:52:31
Comment,2,itrtgt7,,0,1666731116.0,Could you provide the prompts for us to get a better understanding?,2022-10-25 16:51:56
Comment,2,itrtez3,,0,1666731096.0,I always use the latest and greatest because I'm like that!,2022-10-25 16:51:36
Comment,13,itrtbgj,,0,1666731058.0,"> he is definitely a male author, so all of his female characters are indeed breasted boobily.

It's a matter of personal taste, not gender",2022-10-25 16:50:58
Comment,2,itrt8zh,,0,1666731032.0,"Here's the neat part: you can try and see the difference. If you specify the same seed, the same prompt, and the same model, then you'll always get the same picture. Changing the number of steps will only change some details. Experiment!

My own personal experience is that 50 is enough for most cases. If I need more intricate details, 100 or 150 steps will be where I'll go.",2022-10-25 16:50:32
Comment,3,itrt88m,,0,1666731024.0,"It's good to do a plot of steps, different samplers have different point of diminishing returns, there has been comparison posts between samplers where you can see that most of them converge to same image after 20-60 steps, (with few outliers) so I usually do 20 for rough scetch or prompt planning and then crank to 60 steps, makes the thing go way faster if I do a batch of 16 images for example to see different variations of the current prompt.

So when I want to see if I like the current prompt I might do like a xy plot for 4,6,8,10,12,15,20 cfg and 20,40,60,80,120,150 steps

It takes a while, but I do this at work, so while it's churning I get some work done and I get a pretty good feel of what I can expect from current prompt, then I just pick my favorite and move to in / out painting or image to image",2022-10-25 16:50:24
Comment,1,itrt2jk,,0,1666730964.0,">Here is the thing. With same prompt, seed and configuration. I can make the picture you made with SD. So who gets to claim copyright on it?

I'm not sure where this argument is going. With the same camera, setting, and film stock, I can shoot Ansel Adams's Yosemite and come up with substantially the same photograph. But the point is Ansel Adams is the one who thought of it, and he's the one who bothered to do it first, so he gets the copyright.",2022-10-25 16:49:24
Comment,1,itrt1qo,,0,1666730955.0,Any idea why anyone would use this over Automatic 1111?,2022-10-25 16:49:15
Comment,1,itrszue,,0,1666730935.0,"I don't know anything about the code and potential risks, but if you are really concerned you could create a throw away account and use that for this purpose. Then there wont be any issue",2022-10-25 16:48:55
Comment,1,itrszap,,0,1666730929.0,do you merged 1.5 and VAE in a single file before training?,2022-10-25 16:48:49
Comment,1,itrsz0u,,0,1666730926.0,This is a really sensible position. The opposite will happen.,2022-10-25 16:48:46
Comment,1,itrsywg,,0,1666730925.0,So you need to be good at a thing you like ? Alright mate,2022-10-25 16:48:45
Comment,1,itrsuor,,0,1666730879.0,"I think it happened more like this:

&#x200B;

[https://ibb.co/P1ZG8cz](https://ibb.co/P1ZG8cz)",2022-10-25 16:47:59
Comment,3,itrsty7,,0,1666730872.0,"Yay! This is awesome to see all coming together. Best of all it actually has a proper OSS licence, which is really gonna enable it to grow further and be implemented more widely.",2022-10-25 16:47:52
Comment,16,itrstmj,,0,1666730868.0,"I doubt they're going to pay anyone a cent, and anyone who asks why they're not receiving payments will be told it's because their works weren't used in the dataset.

Basically, they don't want to *tell* the artists they're about to get fucked with no lubrication, but that's exactly what's going to happen.",2022-10-25 16:47:48
Comment,1,itrsos1,,0,1666730816.0,"I doubt it. 

If only because, with the example of press photography, you're talking about trained professionals who have a lot of reason and self-benefit to be organized about press photos. They'll be publishing them and trying to make money from them, they'll be called on the accuracy of their reporting, they will want it stored with accurate metadata so they can call it up for future needs, etc. 


With AI generated art, you have none of that, and a huge base of amateurs who are experimenting with it for the first time and still posting. They don't have the training, need, or see the benefit from being that organized. 

And frankly, with art, the whole idea of it being an ""honest reality"" is a manufactured concept from the beginning.",2022-10-25 16:46:56
Comment,0,itrsni3,,0,1666730803.0,So many people like to act like they know what they're talking about when they don't,2022-10-25 16:46:43
Comment,7,itrsn4a,,0,1666730799.0,It'll probably be a lot worse than Getty/iStock. Even thousands of sales equals only a few dollars since it's pennies per sale. Subscription models also drastically cut revenue and purged most contributors a few years ago when all the stock sites transitioned to subscription. Great for consumers but horrible for contributors (except a tiny fraction at the top with millions of sales/downloads),2022-10-25 16:46:39
Comment,2,itrsgn1,,0,1666730730.0,"**[Sweat of the brow](https://en.wikipedia.org/wiki/Sweat_of_the_brow)** 
 
 >Sweat of the brow is an intellectual property law doctrine that is chiefly related to copyright law. According to this doctrine, an author gains rights through simple diligence during the creation of a work, such as a database, or a directory. Substantial creativity or ""originality"" is not required. Under a ""sweat of the brow"" doctrine, the creator of a work, even if it is completely unoriginal, is entitled to have that effort and expense protected; no one else may use such a work without permission, but must instead recreate the work by independent research or effort.
 
^([ )[^(F.A.Q)](https://www.reddit.com/r/WikiSummarizer/wiki/index#wiki_f.a.q)^( | )[^(Opt Out)](https://reddit.com/message/compose?to=WikiSummarizerBot&message=OptOut&subject=OptOut)^( | )[^(Opt Out Of Subreddit)](https://np.reddit.com/r/StableDiffusion/about/banned)^( | )[^(GitHub)](https://github.com/Sujal-7/WikiSummarizerBot)^( ] Downvote to remove | v1.5)",2022-10-25 16:45:30
Comment,2,itrsfop,,0,1666730720.0,"Primary was arcane, secondary robo, tertiary SD 1.5, with .3 multiplier weighted sum.
Run it in A1111 and after a minute (for me atleast), you can start using it, but I think it is necessary to use ""arcane style, nousr robot"" and depending on what you want, you can switch up the location of these two with your prompt to get more arcane or robot.",2022-10-25 16:45:20
Comment,-1,itrsevk,,0,1666730711.0,"> It can be argued there is human authorship in the operation of AI software to generate the image, in the same way there is human authorship in the operation of a camera to produce a photograph.

You have to agree though there is a HUGE difference in effort and the ""sweat of the brow"" argument wouldn't hold up in court for me typing a sentence and press generate 1000 times.

https://en.wikipedia.org/wiki/Sweat_of_the_brow

> They are selling rights to images you create on the platform when you pay for a subscription.

No, Dall-E says:

> Starting today, users get full usage rights to commercialize the images they create with DALL·E, including the right to reprint, sell, and merchandise. This includes images they generated during the research preview.

avoiding saying anything about copyright. And midjourney:

> You basically own all Assets you create using Midjourney’s image generation and chat services. 

""basically"", yeah, a lawyer signed off on that ;p

> Midjourney is an open community which allows others to use and remix your images and prompts whenever they are posted in a public setting. By default, your images are publically viewable and remixable.

AKA: copyright free",2022-10-25 16:45:11
Comment,17,itrs0qc,,0,1666730561.0,"and even if you are an artist in the dataset, the interrogator AI still has to flag it as resembling your work. that job is not going to a person.",2022-10-25 16:42:41
Comment,1,itrry6k,,0,1666730534.0,"thanks for sharing!, do you merge arcane style and robot with 0.5 or what was the strength?",2022-10-25 16:42:14
Comment,1,itrry6f,,0,1666730534.0,"So you just lump everything in and give it a class name like ""example_style"" and it will put everything in its right place? Woah",2022-10-25 16:42:14
Comment,2,itrruol,,0,1666730496.0,Looks really cool! What's the name of the sub?,2022-10-25 16:41:36
Comment,1,itrru56,,0,1666730490.0,Do you know what the CFG was set to? I can't seem to get any results even close. Just weird mutated robot eyes and faces.,2022-10-25 16:41:30
Comment,1,itrrtnx,,0,1666730485.0,"This is amazing! I'm trying to get it working but I'm receiving this error.

)

Any help would be greatly appreciated, thank you!",2022-10-25 16:41:25
Comment,1,itrrsul,,0,1666730476.0,"If I want to train a terraria style model do I also leave it for around 600 steps or would more be better? Also would 68 screenshots be enough or should I use more?

Also when referencing the model do I use ""style"" in the prompt? Ex: ""A screenshot of an adventurer standing outside of a house, style Terraria""?",2022-10-25 16:41:16
Comment,1,itrrsk6,,0,1666730473.0,"1 hour remaining to end the train, then convert to ckpt snd test it.",2022-10-25 16:41:13
Comment,1,itrrq04,,0,1666730445.0,"rightclick Window button on bottom left -> click System -> on right side, click Advanced System Settings -> click Environment Variables...",2022-10-25 16:40:45
Comment,1,itrrnij,,0,1666730420.0,Let us know if it worked in the end.,2022-10-25 16:40:20
Comment,3,itrrl68,,0,1666730396.0,"Nothing you cited above supports the idea that the US copyright office would deny a registration for a single AI image. It can be argued there is human authorship in the operation of AI software to generate the image, in the same way there is human authorship in the operation of a camera to produce a photograph.

As for DALL-E, Midjourney is already doing exactly what you say is legally impossible. They are selling rights to images you create on the platform when you pay for a subscription.",2022-10-25 16:39:56
Comment,1,itrrgga,,0,1666730347.0,"Well, default is 50 images per class.. 6 classes for 6 subject. 7200 steps, 1200 for each subject i guess. And saving every 1200 steps.. my drive have 15gb",2022-10-25 16:39:07
Comment,1,itrraif,,0,1666730283.0,">It's important to stress that, because a lot of people assume that AI art is made in a way that is quick, boring, mechanical, and cold.

Here is the thing... By quick scan of the subreddits and sites relating this - majority of it is just that. Just write a prompt set patch size to 10 and amount to 100 and post it online. NAI subreddit seems to have just ""1girl"" then all the prompts relating to massive boobies and off you go posting it all.

>I think you weren't giving yourself enough credit when you claimed to work by typing in a prompt followed by a single click. What you do deserves more recognition than that.

Sure... But still... I want to be LEGALLY sure of it. I have personally have no problem to just saying they are AI-assisted and citing/crediting all the scientic publications and published developments if I were to do a exhibition (like I want to) and event the artists I prompted. I have NO ISSUES with that - I might do that regardless. However what I can not risk is the legal and possible academic effects that would have if I don't have the copyright/legal rights to use of this material. 

If my engineering studies have taught me anything, it is to appreciate paperwork, regulations, standards and the law. When you consdier those things from the begging, many problems can be avoided.

Before I my engineering studies and during it I worked as a welder and as a fabricator... I take every single step, no shortcuts, I document everything at every weld repair jo, because I want to make sure that if something is my fault I can own up to it but if it isn't I can prove it.

I have worked in theater, in circus. I'm friends with creative people in media and arts. I respect that side of society and I want to protect it. In many situations they have very little protection granted by the society - the last thing I want to do is to work hard only to be punished for it. It is not the lack of reward that I fear - it is the possible punishment for unintentional wrong.",2022-10-25 16:38:03
Comment,1,itrr906,,0,1666730267.0,The AI can't seem to make a reasonable firearm for anything.,2022-10-25 16:37:47
Comment,2,itrr8vy,,0,1666730266.0,Breaking OP's link out: https://youtu.be/wLS0WUNd7nQ,2022-10-25 16:37:46
Comment,2,itrr5in,,0,1666730231.0,"For your first question, personally I think you can argue that the AI software involved functions as a camera. The human author (the prompter) uses the AI software to generate the work by constructing a prompt in the same way a photographer configures the camera and composition to take the photograph. But that's just my opinion.

>Therefore it fails to meet the definition of a copyrightable works (until someone makes that case). If a work is uncopyrightable it is in the public domain.

This is the jump in logic that I think is unsupported. The default assumption when it comes to copyright is that I hold the copyright to something I create (provided it meets all the standards, which is a large part of what we've been discussing: it's not an idea, it's not a process, and so on). You can certainly use someone's AI art operating under the assumption that it is public domain, but my whole point in this discussion is that the cards may be stacked against you if you make that assumption: for example, if I create an image with Midjourney as a paid user, and the Midjourney TOS says as a paid user I own the rights to the image (which it does), and then I put it on my website as part of some commercial project, and then *you* take that image and publish it elsewhere, I can sue you for violating my copyright. Nothing stops me from doing that. You now have to pay thousands to defend yourself in court. The jury is out whether I'd win in the end, *but* I at least have a chain of ownership in this situation, and you do not. All you have is the claim that my photo is public domain, and no real proof of that or reason to argue that based on existing copyright law.",2022-10-25 16:37:11
Comment,1,itrr2rm,,0,1666730201.0,ah i see then. i only have 16gb,2022-10-25 16:36:41
Comment,1,itrr20b,,0,1666730193.0,Stable hoard. Colab. Your own VPS. I can give you specifics if you want.,2022-10-25 16:36:33
Comment,2,itrr1ot,,0,1666730190.0,Oh that would be amazing and I'm sure the community would love it too.  Thank you so much for sharing the mix for your model! I really appreciate it!,2022-10-25 16:36:30
Comment,2,itrr0ue,,0,1666730181.0,You don’t have to use the prompt marketplace at all. I recommend at least looking through the free prompts that users have posted just to see what other people are doing though.,2022-10-25 16:36:21
Comment,1,itrr012,,0,1666730173.0,"I honestly dont know which hardware you mean. 

If you men the ancient 7950 GT from nvidia: dont bother.
However I think you meant a ryzen 7950X. Then you are in no trouble, CPU is not a problem. I am rocking a i7 6700k and it is doing fine.

I also suspect you asking about a RTX 4080 TI? That card is not released yet. 

However my GTX 1080 worked good enough and my new RTX 3090 is really enough. You dont need more. But maybe you like more ;-)",2022-10-25 16:36:13
Comment,2,itrqtzx,,0,1666730109.0,"I'm running an I5-12400 and a RTX 3070.  512x512 images take ~5 seconds each.

I also built an add-on box with Tesla M40 and P100 cards.  They're much slower, but I can batch up absolutely absurd batch sizes and run dozens of images at a time.

Honestly, with what I've heard about the upcoming 4080/4090, I wouldn't be surprised if it could be nearly real-time.",2022-10-25 16:35:09
Comment,1,itrqrcs,,0,1666730081.0,"About class image, i use generated by the colab. Default options",2022-10-25 16:34:41
Comment,2,itrqpmn,,0,1666730063.0,"Thanks, I will try to figure out Hugging face and post some Textual inversion models, and also try to make a guide of my workflow, which is easy if you use A1111. Just merge 3 models ->   
[https://huggingface.co/nitrosocke/Arcane-Diffusion](https://huggingface.co/nitrosocke/Arcane-Diffusion)   
[https://huggingface.co/nousr/robo-diffusion](https://huggingface.co/nousr/robo-diffusion)  
And SD 1.5",2022-10-25 16:34:23
Comment,3,itrqp06,,0,1666730056.0,"I mean PGAI is great too, but I don’t know how appropriate it is to promote them on someone else’s dev project post. Just sayin.",2022-10-25 16:34:16
Comment,2,itrqo1j,,0,1666730045.0,I think we will deal with fake world in quite opposite way. Soon we will count as real only photos tagged with registered name of the person. This person will be legally responsible for the photo to be real. There will be a huge base of real photos. All other images will be perceived as generated. It will be like this is today with press photography. Name of the author will guaranty this is an honest reality.,2022-10-25 16:34:05
Comment,2,itrqnzv,,0,1666730045.0,"Wait...you nuked the cat?  


She seems fine.  :-D",2022-10-25 16:34:05
Comment,1,itrqnez,,0,1666730039.0,Ok... Im training with 1200 steps for concept,2022-10-25 16:33:59
Comment,2,itrqjxn,,0,1666730002.0,How will they check this?!,2022-10-25 16:33:22
Comment,0,itrqem9,,0,1666729946.0,"> We reached out to the U.S. Copyright Office, which in statement said:

> “It is standard practice for the Copyright Office to decline to comment on specific registration applications. Copyright under U.S. law requires human authorship. The office will not knowingly grant registration to a work that was claimed to have been created solely by machine with artificial intelligence.”

[...]

> “There are many open questions on the copyright, licensing, rights, and ownership of synthetic content and AI-generated art,” the CEO wrote. “We need to do all that we can to not only protect the intellectual property rights of our contributors alongside the advent of this technology, but also ensure that they’re empowered to take advantage of this new creative medium.

https://gizmodo.com/ai-art-shutterstock-getty-fur-infinity-1849574917

Again, there is a reason why Dall-E and co aren't selling commercial rights to their images, because legally they can't. Do you think they would leave money on the table? No.",2022-10-25 16:32:26
Comment,2,itrqacr,,0,1666729902.0,"man, it is probably the best and clearest description Ihave read about one of these complex terms that surround the ai, the presentation of the 3 cases, without encoder, with encoder without variation and with variation, is exemplary. You have a talent for this my friend.",2022-10-25 16:31:42
Comment,1,itrq96z,,0,1666729889.0,"Boy, you're spending a whole lot of time leaning on drama and trying to shame.

It's fun how that page says something really very different than what you said, yet you find it to be confirming you

If you're able to reply without an insult or a shaming, I'll continue, but that's four in a row, and I'm getting pretty tired of this

Cornell is not, of course, wrong.  They just didn't say what you said, and what they said directly supports what I said.

And, of course, a quick read of a webpage written years ago isn't very relevant given recent decisions in context.

&nbsp;

> Dude, I don't know what sort of emotional need you're trying to fulfill with these exchanges

(sigh)",2022-10-25 16:31:29
Comment,1,itrq6oj,,0,1666729863.0,You say aspect ratio 1:1. Does it need to be 512x512 or is more possible?,2022-10-25 16:31:03
Comment,1,itrq6dd,,0,1666729860.0,"Who do you claim the human author of AI generated art is? You can claim the prompt, the software developers can claim the software. So far nobody has been able to make the case that AI generated art has a human author.

Therefore it fails to meet the definition of a copyrightable work (until someone makes that case). If a work is uncopyrightable it is in the public domain.",2022-10-25 16:31:00
Comment,2,itrq5h6,,0,1666729850.0,I have 2GB 😂,2022-10-25 16:30:50
Comment,1,itrq3lz,,0,1666729830.0,"Merging objects with atmospheric effects (used in these skull images was fire tornado/tornado) can create some pretty cool combinations. Two items that have similar shapes can create awesome results as well...

For example, a tunnel and a the inside of a wave, or a tarantula and rebar - https://imgur.com/a/qSGwotw",2022-10-25 16:30:30
Comment,2,itrq212,,0,1666729814.0,"Yes, 32 GB of ram",2022-10-25 16:30:14
Comment,8,itrq04z,,0,1666729794.0,"You did a fantastic job and brought the community another important step forward.
Now to one of the most important questions - will you work with A1111 to make this ""more Mainstream"" for local users? (pretty please)",2022-10-25 16:29:54
Comment,0,itrpx2j,,0,1666729763.0,"www.law.cornell.edu/wex/precedent

Can't wait for your explanation for why they're wrong too. 

Dude, I don't know what sort of emotional need you're trying to fulfill with these exchanges, but I don't think it's working.",2022-10-25 16:29:23
Comment,1,itrpwve,,0,1666729761.0,"Amazing, good job!!

Im running in a AMD 5600 XT 6gb, Windows 11, cpu amd Ryzen 7 3700",2022-10-25 16:29:21
Comment,8,itrpt6r,,0,1666729721.0,">I like the idea but the price seems a bit steep.

yep $29/month? $599/year? we're definitely being scammed for instant pictures of a few seconds of computing power.",2022-10-25 16:28:41
Comment,1,itrpsp2,,0,1666729716.0,"Python 3.10
Diffusers 0.6.0
ort-nightly-directml 1.14.0.dev20221022001

Models:
Stable Diffusion 1.5
Stable Diffusion 1.5 vae mse
Stable Diffusion 1.4",2022-10-25 16:28:36
Comment,3,itrpsdo,,0,1666729712.0,"I mean, you're right. People file frivolous, baseless lawsuits all the time. 

You see this all the time in fiction. I don't know what the numbers are, but every time a property becomes popular (e.g., Harry Potter, Lord of the Rings, etc.) a *bunch* of people come out of the woodwork claiming that they had the idea for a golden ring first, or they thought of a boy wizard back when they were in high school, and they file a frivolous claim.",2022-10-25 16:28:32
Comment,2,itrpqtc,,0,1666729696.0,"img2img with ""sketch"" and other prompt info

Also making up sources isn't hard when you already have a result to aim for, i'm not saying you should do this or that this is a good idea, i'm saying it will be _difficult_ to catch people if they don't tell you it's ai art and additionally you have to consider that the new model types used are still in the early stages meaning they will probably get better.    

If you want to be extra stealthy you can use img2img to turn a sketch into finished art in which case you skipped the drawing part and still have 100% of the real ""proof of human"".",2022-10-25 16:28:16
Comment,1,itrpp5d,,0,1666729678.0,do you have more than 16gb of normal ram? im confused how you can do more than 512x512 despite us both having 8gb vram,2022-10-25 16:27:58
Comment,1,itrpe1y,,0,1666729560.0,I wish I knew a way to fix that other than increasing the amount of available ram.,2022-10-25 16:26:00
Comment,3,itrpdg5,,0,1666729554.0,"Again, it is your opinion that a single AI-generated artwork does not meet the standard of creativity. You have not cited any prior precedent in copyright law or behavior of the US copyright office to support your opinion.

(EDIT: And I would argue that a case can be made that prompt engineering meets the qualification for creativity, but that's a different discussion.)",2022-10-25 16:25:54
Comment,1,itrp5gn,,0,1666729471.0,"See my edit, which cites from the text.",2022-10-25 16:24:31
Comment,0,itrp4ye,,0,1666729466.0,You are really CREATive lol  \\o/,2022-10-25 16:24:26
Comment,1,itrp494,,0,1666729459.0,"i dont get it.. no inpainting? I can just drag and drop my local SD images into gimp, why would i need this?",2022-10-25 16:24:19
Comment,3,itrp3ly,,0,1666729452.0,"Yeah I don't think news articles and such will start to use AI generated images of... Sauli Niinistö the president of Finland, instead of an actual photo of them.

Even the graphics in the articles been made or gotten somewhere and they have credits attached to them and most definitely paid for them.

Like Shutterstock, getty... etc make their money in licensing photos for news and media use. As in REAL photos of real people, things or sitautions.  Althought I sure we will start to see AI generated fakes flooding my country's news as we get closer to the election cycle. Boy... That is goign to be fucking joy to deal with.",2022-10-25 16:24:12
Comment,1,itrp394,,0,1666729449.0,"Im getting this error at the ""start dreambooth"" cell:  


/bin/bash: accelerate: command not found

Something went wrong
  


any idea what could be causing this?",2022-10-25 16:24:09
Comment,3,itrp34k,,0,1666729448.0,Incredible,2022-10-25 16:24:08
Comment,1,itrp1c5,,0,1666729429.0,"> excited to announce

the first rule of the actual press release style guide my PR company had was to never say “excited”

it always comes off as disingenuous and yet something like half of press releases keep using it",2022-10-25 16:23:49
Comment,1,itroxnf,,0,1666729391.0,"""Plagiarize"" oh my :D  
I'll just say this – img2img.",2022-10-25 16:23:11
Comment,0,itroxl4,,0,1666729390.0,"You're the expert, so I will defer to you.",2022-10-25 16:23:10
Comment,0,itrox5q,,0,1666729385.0,"Of course it's meaningful, there is reason why there is literally a wiki page about that:

https://en.wikipedia.org/wiki/Copyright_in_compilation

> In the copyright law in the United States, such copyright may exist when the materials in the compilation (or ""collective work"") are selected, coordinated, or arranged creatively such that a new work is produced.

And the whole ""sweat of the brow"" doctrine applies here as well. There is no ""work"" required to generated thousands of images and selecting a single one and copyright that image. But there is work in generating thousands and arrange them in a way to tell a story.",2022-10-25 16:23:05
Comment,2,itrove1,,0,1666729366.0,"Are you running with prior preservation, i.e. class images? How many? I did 300 for my previous training and at 6k I was already starting to see some overfitting artifacts at most CFG levels. Just a quick note, 300 is per concept, no need to multiply accordingly.

Set a --save_interval= value of something like 1000 or 500 to save weights at those intervals, it's very useful in the end to come back to a previous state. Right now it saves as diffusers so if you want to use it in Automatic's you'll have to convert them to ckpt files. You can input the path to the specific model you want in the cell after the train function in the colab and convert.

I'm still trying to figure out a formula for good results depending on subject amount and instance images used but it looks like if you run without class images you can get there quicker.

EDIT: Quick note, if you are saving to a free google drive account with 15gb, since each diffusers model is around 4gb, make sure you download the saved intervals to your pc and delete the folder afterwards, otherwise you'll fill the drive pretty quickly. If you want to convert to ckpt upload them after the training is complete, it's a bit cumbersome but its free lol.",2022-10-25 16:22:46
Comment,2,itrotv6,,0,1666729350.0,Awesome and thank you for replying. If you happen to recall or find the mix for the model or any of your other custom stuff it would be amazing if you shared (or shared for any of your future custom made ones 🙂). Your image results are absolutely fantastic!,2022-10-25 16:22:30
Comment,0,itrotau,,0,1666729344.0,"Brother read the compendium. He was challenging the rule preventing non-human created work from being created, he challenge was denied. It might change in the future but the rule stands.

Section 313:
> Uncopyrightable Material
The U.S. Copyright Office has no authority to register works that are not protected by copyright law. Some of the more common types of uncopyrightable material are discussed in Sections 313.1 through 313.6 below.
>Although uncopyrightable material, by definition, is not eligible for copyright protection, the Office may register a work that contains uncopyrightable material, provided that the work as a whole contains other material that qualifies as an original work of authorship (e.g., a selection, coordination, and/or arrangement of uncopyrightable elements where the resulting work as a whole constitutes an original work of authorship).

313.2:
> Works That Lack Human Authorship
As discussed in Section 306, the Copyright Act protects “original works of authorship.” 17 U.S.C. § 102(a) (emphasis added). To qualify as a work of “authorship” a work must be created by a human being. See Burrow-Giles Lithographic Co., 111 U.S. at 58. Works that do not satisfy this requirement are not copyrightable.
>The U.S. Copyright Office will not register works produced by nature, animals, or plants. Likewise, the Office cannot register a work purportedly created by divine or supernatural beings, although the Office may register a work where the application or the deposit copy(ies) state that the work was inspired by a divine spirit.",2022-10-25 16:22:24
Comment,3,itrorvw,,0,1666729329.0,Just wow. Great stuff OP.,2022-10-25 16:22:09
Comment,2,itroqww,,0,1666729318.0,ok thank you!,2022-10-25 16:21:58
Comment,1,itroqh1,,0,1666729314.0,"u/zxdunny thanks for the feedback, fixed some of the mistakes. Hope it's better",2022-10-25 16:21:54
Comment,3,itroofd,,0,1666729291.0,"scrubbing the git history isn't going to protect you. It's not about being afraid a111 will send a DMCA, it's about no other FOSS project being able to integrate with such problematic code.

Why not just join the Sygil team which has clean code in the first place and they're looking to do the same kind of thing you do?",2022-10-25 16:21:31
Comment,2,itrolw5,,0,1666729265.0,"""*Because they get to profit from it and I don't!*""",2022-10-25 16:21:05
Comment,1,itroj5u,,0,1666729236.0,"It contains a lot of custom stuff, like merging of 3 models (arcane style v3 + robo diffusion v1 + SD 1.5)
And a custom textual inversion I made.
It is also a lot of inpainting with different prompts.
So it is probably hard to reproduce but it goes like this:

Determined menacing look steampunk, cmgirl, arcane style, nousr robot",2022-10-25 16:20:36
Comment,1,itrof5x,,0,1666729195.0,"The same as for the actors. Sometimes adding ""princess"" or the movie she was from",2022-10-25 16:19:55
Comment,-1,itrodss,,0,1666729181.0,"Only the plugin, the core features all new code. I will scrub the git history soon. He's free to send a DMCA if he wants to, it'd be a bit of a walk of shame.",2022-10-25 16:19:41
Comment,1,itroaqs,,0,1666729149.0,">ckpt\_path 

The ckpt trained using the huggingface token was entered into the ckpt\_path. This time it works without problems. I wonder what the reason is.",2022-10-25 16:19:09
Comment,8,itro9od,,0,1666729138.0,What's the point in sharing if you don't share the prompts,2022-10-25 16:18:58
Comment,2,itro46l,,0,1666729080.0,"I'm sorry but you are misreading the ruling:

""On November 3, 2018, Thaler filed an application to register a copyright claim in the  
Work. The author of the Work was identified as the “Creativity Machine,” with Thaler listed as the claimant alongside a transfer statement: “ownership of the machine.” In his application, Thaler left a note for the Office stating that the Work “was autonomously created by a computer algorithm running on a machine” and he was “seeking to register this computer-generated work **as a work-for-hire to the owner of the Creativity Machine**.” In an August 12, 2019, letter, a Copyright Office registration specialist refused to register the claim, finding that it “**lacks the human authorship necessary to support a copyright claim**.” Initial Letter Refusing Registration from U.S. Copyright Office to Ryan Abbott (Aug. 12, 2019).""

The registration lacked human authorship *because it was a work for hire to the owner of the Creativity Machine,* so the structure of the registration was critical in this denial. A machine can't be a work-for-hire employee to Thaler.",2022-10-25 16:18:00
Comment,2,itro43i,,0,1666729079.0,"that's a different problem.

Sadly, weaponizing the court systems absolutely will happen.

companies do this with IP all the time, just trying to intimidate little guys, hoping they just pay up instead of defending themselves (which is expensive)",2022-10-25 16:17:59
Comment,0,itro38a,,0,1666729070.0,With same logic someone can sue for some random human generated art.,2022-10-25 16:17:50
Comment,1,itro04c,,0,1666729038.0,"No, that’s not why he was denied. Read the compendium, specifically 313.2. The art that was trying to be copyrighted lacked human authorship. It doesn’t matter who was on the application, the art is (currently) uncopyrightable.",2022-10-25 16:17:18
Comment,0,itrnzrz,,0,1666729035.0,"Ask for proof of the process of making it. I got files of my photobashes. I can tell you where the source material came form. For my physical paintings I got the original and sketches: Images and scan.

 Besides... It isn't like you are entitled to have your material on their service. If they think the burden of proof has not been met then they just don't let that in to the service. I'm sure they got a whole list of restriction there in addition to this.",2022-10-25 16:17:15
Comment,2,itrntoq,,0,1666728970.0,"I disagree that the distinction is meaningful. You're the one making that claim tho, so you have to support it.",2022-10-25 16:16:10
Comment,0,itrns6g,,0,1666728955.0,"Although that was hyperbole, you can't really prove me wrong. The control you have with AI is much inferior compared to hand-drawn. You will always be limited by the extent of which you could describe a picture with words, and you will be limited by the amount of images that it has in its dataset.

Take a pretty easy prompt like ""A horse pulling a car with a rope"", which is easy for humans but impossible for AI. Open up SD and try to generate a pic that is an actual car and not a carriage. Aww, I'm guessing the AI doesn't really have a lot of references of horses pulling cars to plagiarize from?",2022-10-25 16:15:55
Comment,1,itrns5b,,0,1666728955.0,".... it is

but it won't protect people from frivolous lawsuits from companies that wish to weaponize the courts.",2022-10-25 16:15:55
Comment,1,itrnqwe,,0,1666728942.0,"you don't need to use those cells, once you reach the cell ""FAST Method"" , run it, then directly run the Start Dreambooth cell",2022-10-25 16:15:42
Comment,1,itrnp36,,0,1666728924.0,"I half understood, it's not because I'm dull, the truth is that English is not my natural language, if someone can make a video tutorial, I'll subscribe",2022-10-25 16:15:24
Comment,1,itrnojd,,0,1666728918.0,"Okay.. Let's back up a little here. 

I disagree with none of this.  I live in another country with completely different copyright laws, so I'd be a fool to.  However, my last post was not intended to be about copyright, at least not in any direct way.

There are a lot of people out there who think the -literal workflow- for creating AI art is to spend a few seconds typing a prompt, click a button to generate an image, take that single generated image and post it online, possibly for profit.

My point was that for many artists, including yourself, the process is is a lot more involved, and presents a lot more opportunity for the individual artist to truly craft the image, than the ""Type a prompt and click a button' descriptor implies. 

The amount of work you put in, from start to finish, in both paint medium and digital, represents the whole of your artistic involvement and creation. There is a lot that remains personal, meaningful, and deliberate about the process and the result. 

It's important to stress that, because a lot of people assume that AI art is made in a way that is quick, boring, mechanical, and cold. And, I'm not going to deny that one -can- work that way, but it's unfair to AI artists to present that as the norm for creating AI art. There's a lot more personal investment for a lot of creators, and right now the anti-AI-art crowd is completely disregarding that fact, if they were even aware of it to begin with. 

I think you weren't giving yourself enough credit when you claimed to work by typing in a prompt followed by a single click. What you do deserves more recognition than that.

Now, as to how that all ties into copyright, I think showing that the artist's intentions still matter in the creation process is key towards getting the kind of understanding that will allow copyrights of AI assisted artwork.",2022-10-25 16:15:18
Comment,0,itrnnw2,,0,1666728912.0,I wish someone who does hardware benchmarks would add a Stable Diffusion test to their usual list of gaming performance metrics.,2022-10-25 16:15:12
Comment,1,itrnlyr,,0,1666728893.0,Robots are cool. Nice.,2022-10-25 16:14:53
Comment,1,itrnkbf,,0,1666728875.0,"What are you arguing?

The US copyright office denied Thaler because he wanted to register the work in the name of the AI (that is, he wanted to register a copyright *as owned by an AI*), and you can't do that because AI are not human. He was not trying to register the copyright to work he created using the AI with himself as the author, as is the case in the Midjourney registration.",2022-10-25 16:14:35
Comment,1,itrnjru,,0,1666728870.0,Don’t remind me 😭,2022-10-25 16:14:30
Comment,1,itrnj02,,0,1666728862.0,"As a start, simply run the last cell inthe notebook, and it will run an A1111 instance using the trained model",2022-10-25 16:14:22
Comment,0,itrneuh,,0,1666728820.0,Literally just a worse version of playgroundai.com,2022-10-25 16:13:40
Comment,0,itrneg2,,0,1666728815.0,"Lol, shutterstock, stock  price be like ⬇️",2022-10-25 16:13:35
Comment,1,itrn9up,,0,1666728767.0,"nope, with a free colab, you can train many models per day",2022-10-25 16:12:47
Comment,1,itrn8b6,,0,1666728751.0,"> The US copyright office granting registration of the Midjourney novel is an example of the exact behavior I am talking about.

Do you not understand that the copyright is for the WHOLE NOVEL and not just a single AI generated image? If all those images in the novel are UNEDITED AI generated images, I could literally copy one of the panels and sell it and the creator couldn't do anything to stop me because he only copyrighted the collection of images and not the individual images.",2022-10-25 16:12:31
Comment,1,itrn82t,,0,1666728749.0,The ears 😹,2022-10-25 16:12:29
Comment,1,itrn6y8,,0,1666728737.0,the model will recognize them,2022-10-25 16:12:17
Comment,3,itrn5a6,,0,1666728720.0,Share prompt please,2022-10-25 16:12:00
Comment,2,itrn57k,,0,1666728719.0,"Why you always posting negative stuff. Be more positive! 😜

Seriously though, thanks for sharing your tests!",2022-10-25 16:11:59
Comment,2,itrn4mk,,0,1666728712.0,"Yeah same process, all kinds of custom stuff. I hope maybe in the future there will be an easier way to check and share these custom settings. For now it's a lot of experimentation for me.",2022-10-25 16:11:52
Comment,6,itrn1zm,,0,1666728685.0,">Emulating someones style isn't grounds for a lawsuit

You're right, it's not. But that doesn't stop someone from filing nuisance lawsuits that can take years to work through courts before ultimately being shown to be baseless.",2022-10-25 16:11:25
Comment,0,itrn0om,,0,1666728671.0,"It doesn’t matter who he was trying to assign the copyright to. That’s not what the copyright office’s ruling was about.

https://www.copyright.gov/rulings-filings/review-board/docs/a-recent-entrance-to-paradise.pdf

Read it for yourself.

It cites https://www.copyright.gov/comp3/chap300/ch300-copyrightable-authorship.pdf 313.2 as being what Thaler is challenging. That requiring works to be created by a human is unconstitutional. They ruled against him and held that works must be created by a human to be copyrighted.

A comic book of art created by a human doesn’t need to be copyrighted as a collection because it is already a work created by a human. AI art would need to be part of some human created work for it to be copyrighted. Like a graphic novel somebody created for instance.",2022-10-25 16:11:11
Comment,3,itrmy19,,0,1666728642.0,"As far as I know this is the best walkthrough: [https://rentry.org/sd-e621-textual-inversion](https://rentry.org/sd-e621-textual-inversion)

Ignore the whole furry thing, it's irrelevant to the actual steps posted. It'll also give you descriptions and a guide to the difference between hypernetworks and textual inversions.",2022-10-25 16:10:42
Comment,57,itrmxx4,,0,1666728641.0,Is your friend's book about living with back pain?,2022-10-25 16:10:41
Comment,1,itrmwp8,,0,1666728629.0,"How though? Instead of just people do I include things like cars, trees, backgrounds etc too? And what do I name them?",2022-10-25 16:10:29
Comment,11,itrmum2,,0,1666728608.0,That's good too,2022-10-25 16:10:08
Comment,1,itrmrzy,,0,1666728582.0,Thanks! https://clickable.so,2022-10-25 16:09:42
Comment,2,itrmqf4,,0,1666728565.0,"I'm running it on a 1080 and an i5-7600k. Generating 1 at a time, at 50 steps that's like 20 seconds per image.",2022-10-25 16:09:25
Comment,2,itrmp88,,0,1666728553.0,">Taking down all that they suspect as such    
   
I too like the blindfold and shotgun aproach

>asking verification from the client that uploaded it.   

How would they verify that it is human drawn art?",2022-10-25 16:09:13
Comment,5,itrmnpq,,0,1666728538.0,">Edit: what ""other posts"" am I supposed to be also defending where I use the word ""combine""?

&#x200B;

>I'm directly reproducing material based on their work. I'm just pressing a button on a machine, just **like I was pressing the button on a photocopier**, or **printing a PNG that encodes their content**. The result is similarly inexact.

[Source](https://www.reddit.com/r/StableDiffusion/comments/yd5sb0/comment/itr6vrm/?utm_source=reddit&utm_medium=web2x&context=3)

&#x200B;

>Derived works aren't any less derivative just because they **combine hundreds of thousands of work**s via automation.

[Source](https://www.reddit.com/r/StableDiffusion/comments/yd5sb0/comment/itrdz2f/?utm_source=reddit&utm_medium=web2x&context=3)

&#x200B;

I would call those so inaccurate as to represent either a fundamental misunderstanding or intentional deception. No reasonable person who understands how diffusion models work could use a photocopier as an analogy (except as an accident), even if talking to a non-technical person or child.

&#x200B;

As to why it isn't a derivative work, it's because calling them derivative works (specifically for txt2img, img2img is pretty self-evidently a ""derivative work"" in the normal sense of the phrase) would make all art derivative works. Just like Stable Diffusion, I have been ""trained"" by countless photographs as well as artistic depictions of cats. If you asked me to produce a novel drawing of a cat, that would engage my memory and learning from seeing existing artworks and produce a new art based on those ""weights.""

&#x200B;

Diffuser models don't have access to the training set at all, they have access to their weightings, which is fundamentally different. Once the number of inputs exceeds some amount, it would become statistically impossible to re-create existing art. We shouldn't overly anthropomorphize linear algebra, but just like a human, models ""understand"" that cats have four legs, fur, ears, etc. (though they can be sloppy with number of limbs sometimes), which is how it generates new art work of cats.

&#x200B;

There are edge cases where this is untrue (Starry Night seems to be memorized by some models because there's countless copies of it in the dataset by accident), but SD is creating something that has never existed before based on a set of random noise and a mathematical representation of ""rules"" as to what constitutes successfully implementing each of the tokens (typically one relevant word like ""sitting"" or ""cat""). The original works are not meaningfully present in the generation, and can't be.",2022-10-25 16:08:58
Comment,1,itrmn73,,0,1666728532.0,🤣🤣🤣🤣,2022-10-25 16:08:52
Comment,24,itrmlz1,,0,1666728519.0,I don't think I would want to live in a world where this \*isn't\* happening right now.,2022-10-25 16:08:39
Comment,2,itrmlr9,,0,1666728517.0,"This is amazing, thank you!

I've never used colab for dreambooth (only runpod). Is buying compute units/collab pro a must?  


EDIT: well, I tried using the free tier and everything seemed to work ok. it finished the steps and after it reached 100% on the training cell it gave a vague error. I didn't give a path to my google drive and I also don't have 4gb free on it. Cloud this be the problem?",2022-10-25 16:08:37
Comment,1,itrmlbx,,0,1666728513.0,"Still exhausting the vram, weird. I doubt it matters, but what python version are you on?",2022-10-25 16:08:33
Comment,3,itrmkr7,,0,1666728507.0,I wish I could do that at will. It would certainly make break-ups quick and easy.,2022-10-25 16:08:27
Comment,2,itrmkq4,,0,1666728506.0,">I still don’t understand why the two 1.5 models produce different results, shouldn’t they be the same?

No, because the EMA-only model is technically different data (which is why it's about half the size).  They have (roughly) the same capabilities, but because of how it functions, the results won't be identical.  Think of it like if you changed every comma in a prompt to a space or an underscore or a plus sign (+).  It doesn't change the functionality (obviously), but you get a different result, even when using the same seed.",2022-10-25 16:08:26
Comment,1,itrmk47,,0,1666728500.0,What are the prompts?,2022-10-25 16:08:20
Comment,1,itrmjos,,0,1666728496.0,"> ...getting upgraded literally every ~~week~~ day.

FTFY",2022-10-25 16:08:16
Comment,3,itrmh4q,,0,1666728468.0,10th gen i7 and 3080ti will run it anyhow.  Just started playing with it.  Also tried the method of running it through Google Collab and that seemed slightly faster.  I normally do batch sizes of 3-4 and a little bigger than 512.  About 30 seconds per image.,2022-10-25 16:07:48
Comment,2,itrmedv,,0,1666728439.0,How?,2022-10-25 16:07:19
Comment,2,itrm8pf,,0,1666728380.0,"YES, we neeeeeeeeed Dreambooth to run on 8GB VRAM!",2022-10-25 16:06:20
Comment,2,itrm6zl,,0,1666728362.0,">But there is no precedent that shows otherwise and I would argue in case of copyright, that's the important thing.

Shows otherwise to what? The US copyright office granting registration of the Midjourney novel is an example of the exact behavior I am talking about.

As for your corporate question: Midjourney already grants paid users of their platform the rights to the images they generate in their TOS, which means Midjourney believes the AI art generated by paid users is owned by those users (that there is a copyright to the images generated, and the paid user holds it).",2022-10-25 16:06:02
Comment,1,itrm6a4,,0,1666728355.0,"OK, thanks. I think it is going to take some time and a lot of reading for me to grasp how to get what I want out of deform. My brain is not used to these kinds of concepts.",2022-10-25 16:05:55
Comment,2,itrm3ji,,0,1666728326.0,Wow this is gorgeous. Did you also make this from the custom models/embeddings that you mentioned in your wonder woman post?,2022-10-25 16:05:26
Comment,1,itrm1m4,,0,1666728306.0,Can you make it make videos traveling between the images?,2022-10-25 16:05:06
Comment,2,itrm1fq,,0,1666728305.0,"This is grossly inaccurate and beyond hyperbole, your argument extends to using the fill tool with a pattern and claiming that means you didn't make any art.

&#x200B;

>Derived works aren't any less derivative just because they combine hundreds of thousands of works via automation.

You come off as one of those pretentious critics that looks at art and says ""oh how derivative""  AI can be used for more than ripping off styles and even if you do, derivative or not, does not make it any less a piece of art. Perhaps less respected, but still art.     
You are a victim of your own lack of creativity if you cannot see outside these boundaries you've artificially created. 

&#x200B;

&#x200B;

If you draw a human being with AI, is it not art because humans already exist?  Is not every photo after the first not just a rip-off of the initial? 

ridiculous attitude",2022-10-25 16:05:05
Comment,0,itrlxoq,,0,1666728265.0,Following.,2022-10-25 16:04:25
Comment,2,itrlx42,,0,1666728259.0,"I'll wait for automatic1111 to implement this. Honestly, I'm yet to try like 80% of the functional of what's in auto's repo",2022-10-25 16:04:19
Comment,1,itrlwj4,,0,1666728253.0,thank you! still working out a few things to take it up a few levels,2022-10-25 16:04:13
Comment,2,itrlvoh,,0,1666728244.0,"> AI-generated content may not be uploaded to Shutterstock because AI content generation models leverage the IP of many artists and their content

Human artists too build their work on the input they get from paintings they look at (among other things). AI art and human art is not the same, but let's not pretend human creativity works in a vacuum.",2022-10-25 16:04:04
Comment,1,itrlu90,,0,1666728229.0,"Thanks, i start training 6 subjects with 1200 steps for each one, 7200 total steps.

Do you think its ok?",2022-10-25 16:03:49
Comment,0,itrlrcv,,0,1666728198.0,"11pm EDT happens when this comment is 6 hours and 56 minutes old.

You can find the live countdown here: https://countle.com/EeczD1eSV

---

I'm a bot, if you want to send feedback, please comment below or send a PM.",2022-10-25 16:03:18
Comment,1,itrlnx0,,0,1666728163.0,I'll take a look- thank you!,2022-10-25 16:02:43
Comment,1,itrlmef,,0,1666728146.0,"**Nobody knows!** There is no set laws or legal framework for this! I couldn't find any for EU or Finland, the jurisdictions I am in. Stability follows the UK law and since they buggered off from the union they got their whole own thing going on over there - so the model is governed under that (Probably for a reason since UK allows **training** of the model on copyrighted content-  far as I know the stance on outputs is also a ""Dunno \*shrug\* "")

I am actually writing on officially question the ministry that is THE authority on copyright law here - as in... THEY MAKE THE LAWS. Specicially on my img2img workflow's outputs.",2022-10-25 16:02:26
Comment,2,itrlmac,,0,1666728145.0,">The US Copyright Office has repeatedly determined that a human must have created a work for it to be copyrighted. That might change, but right now that’s where we are. The comment I linked presents one of those instances.

But this isn't true at all. The copyright office has only so far denied copyright registration in cases where the author tried to register AI artwork **in the name of the AI**.

As for your first paragraph, you're trying to make a distinction that a collection of AI art = copyrightable, whereas individual AI art pieces = public domain work/not copyrightable. **But what is your evidence to support this distinction?** I've written this like 10 times already in this thread and no one seems to be able to provide a direct answer: if the US copyright office has already granted a registration to a Midjourney graphic novel—which I would argue **is not** a collection of AI images any more so than a comic book can be argued to be a collection of drawings by a comic artist—then what is your evidence that the US copyright office would deny a registration for an individual AI-generated image?",2022-10-25 16:02:25
Comment,2,itrllyk,,0,1666728142.0,"Are hypernetworks and textual inversion the same thing otherwise? (I'm not the OP you replied to btw). I had no idea of the difference when I was trying it, but my solution to the inconvenience problem was to add hypernetworks to the quick settings area so it shows up next to the models at the top.",2022-10-25 16:02:22
Comment,19,itrllo4,,0,1666728139.0,"Assuming we live in an infinite universe/multiverse, is this effectively a photo of something that's happening right now?",2022-10-25 16:02:19
Comment,0,itrlksm,,0,1666728130.0,"But there is no precedent that shows otherwise and I would argue in case of copyright, that's the important thing. 

If Dall-E randomly made the images open to use commercially, then trust me, those lawyers tried and got told off.",2022-10-25 16:02:10
Comment,1,itrli2w,,0,1666728101.0,"oh definitely-- even the ""glitches"" make it kinda special :)",2022-10-25 16:01:41
Comment,1,itrlgxn,,0,1666728089.0,![gif](giphy|Cm7zPqMlUHWV0Yktas|downsized),2022-10-25 16:01:29
Comment,1,itrlgal,,0,1666728082.0,"Right, that sounds like an issue of curation, search result ranking and filters, not terms -- also, AI-generated art will become much better over time, whereas their AI-disallowed terms now kind of lock them in.

Sites like [Stockai.com](https://Stockai.com) might benefit from them disallowing it, though. It brings people to their business. Even then, as GPU power increases and a local StableDiffusion is as good and fast as what Stockai offers, I wonder if even they will be replaced...",2022-10-25 16:01:22
Comment,1,itrlg6y,,0,1666728080.0,Thanks :)),2022-10-25 16:01:20
Comment,1,itrlcky,,0,1666728041.0,"Holy shit, that's amazing.",2022-10-25 16:00:41
Comment,1,itrlamr,,0,1666728021.0,"There is a difference between you don't know the outcome of what the computer does to knowing fully well what will happen when you press a button.

For example, generating a random cloud in photoshop is not copyrightable. But creating those random clouds, paint them blue and white and say it's clouds in the sky, you enter the realm of copyrightable since you made artistic choices that you could influence with full knowledge of the outcome.",2022-10-25 16:00:21
Comment,2,itrl8wz,,0,1666728003.0,"The reason I ask is because a hypernetwork is applied to every image you're generating in that model, which makes it kind of weird to use to generate a face with. I mean you CAN, but it's kind of extra work. You're basically saying 'I want this applied to every single image I generate.' 

Which is why I was curious why you didn't just use Textual Inversion to create a token that you can call to use that specific face, only when you want it. 

It's true that Dreambooth would probably work better, but it's also rather excessive in a lot of ways.",2022-10-25 16:00:03
Comment,-1,itrl5xw,,0,1666727972.0,"I'll say it again with an even more precise comparison to save you the effort: invoking an AI on a prompt is literally identical *in terms of artistic expression* as pressing ""print"" after typing that same prompt into Google image search. Both produces a derived work of the input art (even if you draw on it with a crayon afterwards).

It's not identical *in result* nor in underlying mechanism (though not as different as even you might think). Surely you're not going to get all literal and pedantic here.

Every time this comes up, I see either technological arguments that rely on the extraction processing being different to other reproduction technology, or legal arguments that rely on precedent established by legal systems ill-equipped to deal with that same technology (and powerful lobbyists).

Note that I'm not a 2D artist, I can't draw or paint for shit, if you think that's the bias I'm coming from. I'm a programmer and I've spent way too much time dealing with the concept of derivative works in software which are vastly harder to argue than this one (except the expensive lawyers are on the opposite side).",2022-10-25 15:59:32
Comment,1,itrl3c8,,0,1666727944.0,"I'm new to dream booth - after it's done, what is the file output and how can it be used with like A1111?",2022-10-25 15:59:04
Comment,10,itrl2z8,,0,1666727940.0,"In my experience, I'm far better off generating a ""close enough"" image, and then using inpainting and masking to independently move the subjects to where they need to be.",2022-10-25 15:59:00
Comment,2,itrl2kb,,0,1666727935.0,ouch... but yes I do...,2022-10-25 15:58:55
Comment,3,itrl2e4,,0,1666727934.0,I wonder how they will detect AI art. Sure some stuff is very easy to tell right away and some online versions place a watermark but I use a local version with the watermark disabled and do lots of photoshop back and forth. Even if I gave you all my prompts and seed you can just generate the same image.,2022-10-25 15:58:54
Comment,2,itrl1mm,,0,1666727925.0,"You're the best =)
Haha",2022-10-25 15:58:45
Comment,-1,itrkvsv,,0,1666727863.0,"Given that seed to seed SD and Dall-E etc. all create VASTLY different outcomes, one could very easily argue that the human has NO artistic input beside the prompt.

You can not tell me what the output is before you see it and that's pretty much all the court would need to know.

If you guide it, you'd still don't know the outcome.

BUT if you create a flower, a mountain, a building and mash them together in photoshop there the artistic input is clearly visible and the finale product is copyrightable.

Hell, one could argue a simple comic text bubble (non ai generated) with a frame and some hand drawn lines is enough artistic expression. But don't count on that, courts don't have precedent here and can claim it's still not enough human authorship.",2022-10-25 15:57:43
Comment,1,itrkuqb,,0,1666727851.0,issue solved-- please let me know what you think!,2022-10-25 15:57:31
Comment,1,itrkt9z,,0,1666727835.0,issue solved :) please let me know what you think!,2022-10-25 15:57:15
Comment,0,itrkt9d,,0,1666727835.0,"The copyright office didn’t allow the copyright for AI generated work. It allowed a copyright for a collection of public domain work. Just like how a person could create a selection of public domain literature and copyright their creative process in determining which works to include and the order to present them.

You could copyright a Best 1000 AI Cat Pictures book. You, a human, is deciding what pictures to include. You’re deciding how you want to present those images. That is a copyrightable creative process.

The US Copyright Office has repeatedly determined that a human must have created a work for it to be copyrighted. That might change, but right now that’s where we are. The comment I linked presents one of those instances.",2022-10-25 15:57:15
Comment,2,itrkrpf,,0,1666727819.0,Think I will just keep my own installation.  Don't like gated,2022-10-25 15:56:59
Comment,1,itrkrgv,,0,1666727817.0,"Reminds me of the animated film ""Mad God"". Creepy.",2022-10-25 15:56:57
Comment,1,itrkpkt,,0,1666727797.0,">	The REAL danger for artists isn’t in being used to train an AI, it’s in signing over their rights for a fraction of the table scraps these companies will “award” them for playing along.

No one is forcing them to sign. The value is in the service, not the art.",2022-10-25 15:56:37
Comment,2,itrkn8d,,0,1666727773.0,"sry just found it,",2022-10-25 15:56:13
Comment,3,itrkmpk,,0,1666727767.0,">It only proves that you have to assist the machine to do for you what you can't otherwise.

Should people using any kind of software have copyright on their work then?",2022-10-25 15:56:07
Comment,1,itrklbc,,0,1666727752.0,"What do you we have to write in the ""subject typ""e and ""instance name"" boxes when we want to train the model for 1 man and 1 woman in the same time for example?",2022-10-25 15:55:52
Comment,3,itrkfcr,,0,1666727691.0,"Not if we have trained the model at all, or applied multiple generations to specific masked areas of the image, or composed several individual pieces to create the final product.  How much human intervention prevents it from being considered not just a sole work of AI interpretation?",2022-10-25 15:54:51
Comment,2,itrkduh,,0,1666727675.0,where is that? I don't mean the ckpt but rather the steps. I am going to try it later anyway I am on the process of making my refs images. and will try to find that feature Thank you so much.,2022-10-25 15:54:35
Comment,3,itrkb9t,,0,1666727648.0,">But the art you create with SD or Dall-E etc. is not your artistic expression, it's that of the machine. You do understand that right?

I don't necessarily agree with that, but you can certainly make that argument. But that is a matter of opinion; I'm talking about *precedent* established by law, or prior behavior of the US copyright office. There is no current legal precedent that supports your opinion, or behavior of the US copyright that you can cite to support it. That's what I'm getting at. You can hold your opinion but it's not a matter of fact.",2022-10-25 15:54:08
Comment,2,itrk8ds,,0,1666727618.0,"""assist the machine to do for you what you can't otherwise""
That's extremely vague. You'd have to be way more precise with your definition for it to apply to AI and not other stuff.

But if as you said, that use case already counts as sufficient artist input then the original image might as well also count. This is all done inside SD and the inpainting or img2img is done by AI, it's just that now we can be very specific when manipulating the outcome we want.",2022-10-25 15:53:38
Comment,1,itrk6cj,,0,1666727597.0,Soon we will not be able to tell what image is real or not.,2022-10-25 15:53:17
Comment,2,itrk080,,0,1666727532.0,Do you take hints on English usage and spelling?,2022-10-25 15:52:12
Comment,1,itrjuaz,,0,1666727470.0,"But the art you create with SD or Dall-E etc. is not your artistic expression, it's that of the machine. You do understand that right?

Just because he tried to give the copyright to the machine doesn't mean the copyright office suddenly reverses it's opinion on what merits human authorship.

When all you do is type 10 words, that's not your work, that's the machine randomly generating an image that slightly looks like what you typed.",2022-10-25 15:51:10
Comment,1,itrjqt7,,0,1666727434.0,"But why do you think this? Is there legal precedent that makes you think this? Or is it just your opinion? Because I've presented an example of the US copyright office allowing someone to register their copyright for AI generated artwork. There is nothing established in copyright law right now that precludes AI-generated artwork from being copyrightable. If there is, please present it.",2022-10-25 15:50:34
Comment,17,itrjodi,,0,1666727408.0,"Which, the sooner the better.",2022-10-25 15:50:08
Comment,1,itrjo73,,0,1666727406.0,"using euler (not euler a) ?

add this to the negative prompt :

((((ugly)))), (((duplicate))), ((morbid)), ((mutilated)), \[out of frame\], extra fingers, mutated hands, ((poorly drawn hands)), ((poorly drawn face)), (((mutation))), (((deformed))), ((ugly)), blurry, ((bad anatomy)), (((bad proportions))), ((extra limbs)), cloned face, (((disfigured))), out of frame, ugly, extra limbs, (bad anatomy), gross proportions, (malformed limbs), ((missing arms)), ((missing legs)), (((extra arms))), (((extra legs))), mutated hands, (fused fingers), (too many fingers), (((long neck)))",2022-10-25 15:50:06
Comment,1,itrjmzf,,0,1666727393.0,Thanks. I've sorted the problem now. It was a file sharing setting.,2022-10-25 15:49:53
Comment,1,itrjit5,,0,1666727348.0,Do the same thing,2022-10-25 15:49:08
Comment,1,itrjiet,,0,1666727344.0,"Right... So here is a thing... I can claim copyright in the watercolour I made. **By current laws**. HOWEVER! There is no fucking ground work for me legitimately claim one way or another or the 1st or the last iteration of the set.

At best I can fullfill 2 of the 3 conditions set here BY LAW as the standard for copyright being made. I am going to ask for if it meets the 3rd.

And I'm sorry... Unless you are one of the officials in the copyright board of Finnish Culture and Education ministry which communicates with European unin on this - I will not take your opinion as worth anything but theory.

Because if the copyright board says that it doesn't meet standad for copyright... Then it doesn't **by law**. Opinion doesn't matter at that point; they are the one who tell the courts how to interpet the law.

So you can bang on about theory and opinion - I am going to ask to those who's opinion actually matter - those who's opinion sets the standad. **There is no decision one way or another on this matter in my juridisction. So no one can claim it does or does not meet the criteria. I am asking because I think it does and I will frame the question to them from that perspective.**",2022-10-25 15:49:04
Comment,3,itrjhvl,,0,1666727339.0,">And any artist that uploaded a video of their work process, where they carefully crafted a prompt, masked and inpainted, did hand edits, etc. would meet a reasonable person's standard for ""human authorship.""

Realistically, unless there is some hard evidence suggesting that you weren't involved in the creation, you don't need to prove that you were.

The reason why Thaler's two attempts failed was because he was very specific about stating that he was not involved (despite the fact that he absolutely was -- without his involvement, that image would not exist), and that he was not attempting to register the copyright in his name, but in the name of a piece of software.  He keeps trying to get the USPTO to assign legal rights to his python code, because he wants to go down in history as the person who got AI legal rights.

I really hate these people who want to treat AI like it's sentient or some shit.  The worst part about it is that inherently, good AI will be able to convince people that it is sentient.  If people like Thaler get their way, you'll be obligated to pay Stable Diffusion an hourly wage.",2022-10-25 15:48:59
Comment,1,itrjhe7,,0,1666727333.0,"You're joking right? Chess maybe, but not Go.",2022-10-25 15:48:53
Comment,3,itrjcyc,,0,1666727287.0,">It does. Creating prompts and creating thousands of randomly seeded images is not human artistic expression.

You need to read more closely, my bud. You're arguing that AI artwork is *not creative enough to qualify for copyright*, which is an entirely different thing that  what the US copyright office is asserting above. *That* passage is saying that if you're not human, then no expression you can have will qualify. It's not a matter of degrees of creativity. It's because you're not human. This is consistent with the Thaler ruling and the result of the monkey case.",2022-10-25 15:48:07
Comment,2,itrjcu9,,0,1666727285.0,Yes the fp16 option changes the output model to fp16,2022-10-25 15:48:05
Comment,1,itrj9sd,,0,1666727255.0,the training is highly tied to the quality of the input images,2022-10-25 15:47:35
Comment,2,itrj7hh,,0,1666727232.0,They don't want AI to be uploaded because they want to be sure it doesn't infringe on any copyrights. And the only way they could solve that problem was by granting themselves a monopoly on AI art. Funny how that works out!,2022-10-25 15:47:12
Comment,1,itrj6si,,0,1666727225.0,Looks like an image of a well known actress. Curious on the legalities of using her likeness.,2022-10-25 15:47:05
Comment,1,itrj6ml,,0,1666727223.0,"That’s not your comment, just like ai generated art isn’t your art to copyright. You’d have to modify the comment in some way to be able to claim it as your own.",2022-10-25 15:47:03
Comment,1,itrj5xy,,0,1666727216.0,Thanks,2022-10-25 15:46:56
Comment,1,itrj3kn,,0,1666727191.0,This is awesome! I love seeing people doing something really different.,2022-10-25 15:46:31
Comment,2,itrj37b,,0,1666727187.0,"I wasn't sure, but it is indeed very safe I would think, saw others post ""nsfw"" so thought I might as well just in case.
Maybe the prompt is nsfw",2022-10-25 15:46:27
Comment,1,itrj277,,0,1666727177.0,I found that is you transform some word like pornn instead of porn it will work but they often have a NSFW detector that will blur or hide the result image. those people are puritain but now I can run stable diffusion locally \^\^,2022-10-25 15:46:17
Comment,0,itrix4g,,0,1666727124.0,So they're not allowing AI to be uploaded because they want to have a monopoly on it? Am I misunderstanding?,2022-10-25 15:45:24
Comment,1,itriv5f,,0,1666727103.0,"Glad you like it! Thanks for the bug report, we’re looking into this.",2022-10-25 15:45:03
Comment,1,itritks,,0,1666727087.0,"Then prove me wrong, copyright one of your images by specifically tellin the copyright office that you only provided a prompt and didn't modify anything on the output image. I'm 99.99% sure it will be rejected. Only in the UK this would pass.",2022-10-25 15:44:47
Comment,3,itrisab,,0,1666727074.0,Great Article!,2022-10-25 15:44:34
Comment,1,itriry1,,0,1666727070.0,Why is this labeled NSFW? Are we supposed to label any image that looks like a pinup as NSFW even when not showing anything?,2022-10-25 15:44:30
Comment,28,itrirxc,,0,1666727070.0,"I stole most of your prompt and reworked the bee cat I was working on and got this: https://i.imgur.com/zhAH9pu.png

    a [dog dressed as a bumble bee:dog :0.50] pollinating a beautiful flower, love scene, low angle, detailed, high detail, dynamic lighting, warm lighting, volumetric, godrays, vivid, beautiful, huge scene, trending on artstation, by jordan grimmer, art greg rutkowski
    Negative prompt: Disfigured, bad art, deformed, poorly drawn, extra limbs, close up, b&w, weird colors, lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry
    Steps: 55, Sampler: Euler, CFG scale: 13.5, Seed: 968962039, Face restoration: GFPGAN, Size: 512x512, Model hash: 81761151",2022-10-25 15:44:30
Comment,1,itrir5d,,0,1666727062.0,So... you're linking to my own comment? Which says the opposite?,2022-10-25 15:44:22
Comment,1,itriper,,0,1666727044.0,"> A precedent is just a ruling that informs how the law will apply in similar situations moving forward. 

This is not correct, and one of the many reasons that someone like you should remember that you never went to that thar lawyerin' school, in tarnation.

&nbsp;

> I don't know why you keep accusing me of misusing the word.

I can see that.

&nbsp;

> The reason your example doesn't apply here is

(loud sigh)

We've already gone over this.  

I see that you think repeating something someone already said why they don't agree with is a form of holding conversation.",2022-10-25 15:44:04
Comment,0,itrilfi,,0,1666727001.0,"Here's something you might not know about art.

When an artist gets to be a big name, in many fields they often aren't the one hands on-making the art anymore.

They set the design, they tell the artists working under them how to do their work, and the master artist might put on the final finish in the end, but by and large their effort and input into the artwork can be very hands-off.

That's still counted as legitimate, even though one could argue he 'commissioned' the artwork from younger artists. 

In the case of AI art, all of the artistic direction comes from one person, the creator. Even though I'm not hand painting an image, necessarily, I can still put hours and hours and hours into getting the AI to generate the image I have in my head, making sure that the details and composition and everything else are to the standards I've set. 

Hell, I may even hand-paint a rough image, then have AI upscale the detail on that image, or even just a small part of it. Then you've got a hybrid artwork with a blend of handmade and AI imagery on the same page.. and apparently, according to you, that doesn't actually count as 'my' artwork, since I didn't ""Totally rework"" the image it generates.

You present this issue like it's able to be neatly defined and wrapped up, and it's anything but.",2022-10-25 15:43:21
Comment,1,itriiuv,,0,1666726973.0,"It does. Creating prompts and creating thousands of randomly seeded images is not human artistic expression.

YOU can not predict what the AI spits out for ""woman standing next to a lake landscape, artstation, trending, by greg rutkowski"". That's literally the opposite of artistic expression, because in the end all you do is select what looks good from a collection of randomly generated images. That's not art and I'm 100% certain it never will be.

Once you start modifying the images with photoshop and mash together many different AI generated images, then it becomes art and it is copyrightable.

And that's fine, that's how it's supposed to be.",2022-10-25 15:42:53
Comment,2,itrihlf,,0,1666726960.0,"""An actor who is good in a lot of things, but should not play Mario, playing Mario""",2022-10-25 15:42:40
Comment,1,itrigh1,,0,1666726948.0,"How about you put in some effort first, then I'm happy to oblige. Tell me how it's *not* a derived work, except because the law is entirely unprepared for derivation at such scale.

That first question already suggests you think ML is some dark technical mystery. It really isn't. Indeed, a photocopier is arguably more sophisticated in that it requires slightly novel use of physics whereas nearly all of ML is the almost accidentally surprising result of our recent ability to do trivial things extremely quickly upon extremely large amounts of data.

Edit: what ""other posts"" am I supposed to be also defending where I use the word ""combine""?",2022-10-25 15:42:28
Comment,0,itrifiu,,0,1666726938.0,https://www.reddit.com/r/StableDiffusion/comments/yd5sb0/shutterstock_finally_banned_ai_generated_content/itrfwkn/?utm_source=share&utm_medium=ios_app&utm_name=iossmf&context=3,2022-10-25 15:42:18
Comment,2,itrifg6,,0,1666726937.0,"yes, but keep in mind that all the frames will be generated with the same number of steps as the first frame. The schedule is made so the init picture is generated with a higher quality (steps count is `steps` exactly) and then it undergoes smoother transitions with the lower number of `steps * (1-strength)`",2022-10-25 15:42:17
Comment,1,itriejg,,0,1666726928.0,"the 1600 1.4 also 70% likeness, the 1400 1.5 , maybe 80-85. Still nowhere near as on point as the one trained with Person a few weeks ago.",2022-10-25 15:42:08
Comment,-1,itriea7,,0,1666726925.0,"You’re either on Progress’s side, or in its way. It was obvious where Shuttershock stood",2022-10-25 15:42:05
Comment,2,itrid1o,,0,1666726912.0,"for now it uses more than 12GB of VRAM, but soon it will be possible to run in with 8GB",2022-10-25 15:41:52
Comment,1,itrib9o,,0,1666726894.0,Does the fp16 option change the output model to fp16 or is it used only for the training?,2022-10-25 15:41:34
Comment,2,itri8c1,,0,1666726864.0,"the links are working, the error you're getting is cause by the conversion process, try a path to an already trained model and see if it works",2022-10-25 15:41:04
Comment,1,itri89s,,0,1666726863.0,Not entirely sure but I imagine that would work yeah,2022-10-25 15:41:03
Comment,1,itri767,,0,1666726852.0,You are correct! Thanks.,2022-10-25 15:40:52
Comment,2,itri6j2,,0,1666726845.0,Please cite where the US copyright office says AI-images cannot be copyrighted.,2022-10-25 15:40:45
Comment,1,itri59p,,0,1666726832.0,Does this make use of the new SD 1.5 Inpainting model?,2022-10-25 15:40:32
Comment,3,itri2d4,,0,1666726801.0,"nothing... I train 6 models, with 30 pics each one, 1100 steps per model (6600 total steps).

Results are similar to my prev sample... single models generated with the prev training method are much better!",2022-10-25 15:40:01
Comment,1,itri1xm,,0,1666726796.0,"this method doesn't require any prompt or class image, just instance images named with the instance name",2022-10-25 15:39:56
Comment,0,itri18q,,0,1666726789.0,The US Copyright Office,2022-10-25 15:39:49
Comment,1,itrhx66,,0,1666726747.0,Ok so this is for faces but what if we want to train it on a style in general?,2022-10-25 15:39:07
Comment,3,itrhx5z,,0,1666726747.0,">non-human expression means an AI created the art and the human had little to no input.

Correct. So the passage you cited from the copyright office doesn't support what you're arguing.",2022-10-25 15:39:07
Comment,3,itrhx25,,0,1666726746.0,"There is a save steps option, added in this colab before shivam's colab",2022-10-25 15:39:06
Comment,1,itrhtkg,,0,1666726709.0,"So to keep it simple for my super low level of maths understanding, are you saying I can just set the strength to 0 and us the steps slider instead?",2022-10-25 15:38:29
Comment,1,itrhsyr,,0,1666726702.0,"Wrote the above article and wanted to get feedback on it, thanks in advance.",2022-10-25 15:38:22
Comment,1,itrhp3w,,0,1666726662.0,"Ok thanks but how should the prompt be formulated? Will it preserve the instance name for both the style and the character i.e ""portrait of (instance name) person in the style of (style instance name)?",2022-10-25 15:37:42
Comment,2,itrhnjo,,0,1666726646.0,"NO, the novel is a COMPILATION/SELECTION of images which IS copyrightable. 

https://en.wikipedia.org/wiki/Copyright_in_compilation

non-human expression means an AI created the art and the human had little to no input.",2022-10-25 15:37:26
Comment,1,itrhkmy,,0,1666726616.0,">The work in question, A Recent Entrance to Paradise, was put forth twice by Steven Thaler on behalf of the “Creativity Machine,” the stated “author” of the work.

The entire reason it was shot down, same as his previous attempt, was because he was trying to register it to a piece of software.  Software cannot hold a copyright, because it is not a person, and only people can hold copyrights.

If he had registered it under his own name, it would have been registered without an issue.  The point is that Steven Thaler is a fucking nutjob and keeps trying to get the US legal system to assign rights to software.",2022-10-25 15:36:56
Comment,1,itrhho2,,0,1666726586.0,"Yes for sure, we’ve put a lot of work into the mobile and tablet versions of this UI. Let me know what you think!",2022-10-25 15:36:26
Comment,1,itrhhbg,,0,1666726582.0,Amazing,2022-10-25 15:36:22
Comment,1,itrhgsl,,0,1666726576.0,Better for sure. Going to try 1600 now.,2022-10-25 15:36:16
Comment,1,itrhfoh,,0,1666726565.0,"Of course when you modify the images and edit it to a higher degree, then there is LITERALLY artistic input. I can for example take pictures from the public domain and mash them together in photoshop and create new copyrightable work of art.

Perfectly acceptable.",2022-10-25 15:36:05
Comment,1,itrhdua,,0,1666726545.0,"Try checkpoint merging it'd merge the two models
I'd start it with more of the character model than style but ye

Either that or make an image of the character then use img2img with the style model",2022-10-25 15:35:45
Comment,0,itrhb47,,0,1666726516.0,">If I paint an image, the guy who made the -brush- doesn't get a claim to my work.

You're not painting anything, though. You're ""commissioning"" the image from the AI. Now, if you totally rework the image it generates, I think that could be argued to confer the copyright to you.",2022-10-25 15:35:16
Comment,1,itrhaw0,,0,1666726513.0,Does this work with stable diffusion UI or NMKD GUI?,2022-10-25 15:35:13
Comment,1,itrhaqb,,0,1666726512.0,"It should be randomising automatically without the switch on. I’ll look into that, what browser are you running it on may I ask? Thanks",2022-10-25 15:35:12
Comment,3,itrh79y,,0,1666726475.0,"This is a great place to start for any developers looking to get into the SD community, their Discord has a very friendly on-boarding process with lots of friendly faces to help you get started.",2022-10-25 15:34:35
Comment,1,itrh3mq,,0,1666726435.0,"I'd settle for textual inversions, which in theory are much simpler but don't work either...",2022-10-25 15:33:55
Comment,1,itrgyf4,,0,1666726381.0,"I don't have a  ""problem"" with that, but I do have a ""problem"" with how AI art is being treated as ""unethical"" in general.

The ""problem"" I have is that AI art is not stealing and they're acting like it is, when anyone who knows how a neural network works can tell you otherwise. Every generation is grabbing patterns from millions of images to the point where you can't actually trace back any of it to a particular artist.

If the way you are describing it is how they want to go about it, they're gonna need a lot of artists to sign up for that, and they'll have to agree to share their art inputs with every other artist on the platform, best of luck to them.",2022-10-25 15:33:01
Comment,0,itrgy22,,0,1666726377.0,"And any artist that uploaded a video of their work process, where they carefully crafted a prompt, masked and inpainted, did hand edits, etc. would meet a reasonable person's standard for ""human authorship.""

&#x200B;

What would fail that case's standard is if I created an algorithm that picked words at random, and sent them to an API automatically.

&#x200B;

This is like the ""monkey selfie"" in that someone was trying to prove a very specific and bizarre legal theory.",2022-10-25 15:32:57
Comment,2,itrgx0p,,0,1666726366.0,">And let me quote the US Copyright office  
>  
>While the Board is not aware of a United States court that has considered whether artificial intelligence can be the author for copyright purposes, the courts have been consistent in finding that non-human expression is ineligible for copyright protection.

But you're misreading this. *Non-human expression* means a non-human can't register for a copyright. This is consistent with the Thaler case and the monkey photo. ***Non-humans*** **can't register for copyright**. That doesn't preclude **humans** from registering a copyright to AI-generated artwork, ***which has already happened with the Midjourney graphic novel.***

Again, you have presented no evidence that AI generated artwork can't be copyrighted.",2022-10-25 15:32:46
Comment,3,itrgsn1,,0,1666726320.0,This isn't the issue. They are selling a service from OpenAI where images can be created in the style of Mr X also. This is all about the money going directly to them via their new OpenAI partnership.,2022-10-25 15:32:00
Comment,1,itrgneh,,0,1666726264.0,"I was trying to get him fatter by time, so it was prompted :D",2022-10-25 15:31:04
Comment,-1,itrgkof,,0,1666726235.0,"It only proves that you have to assist the machine to do for you what you can't otherwise.

But I literally mentioned that use case:

> You can mash ai generated art together and merge it into something else, THAT is copyrightable, but not something created purely by a machine.

But even then the amount of actual work necessary to make it copyrightable will be quite a gray zone.",2022-10-25 15:30:35
Comment,2,itrgkav,,0,1666726231.0,">The images are public domain because, right now, ai generated images are not protected by copyright laws

How do you come to this conclusion? What makes you think this? Can you cite legal precedent for this?

*""I can copyright the exact same images used for this graphic novel in an order that I find more pleasing, or that fits my creative idea better.""* In the case of the Midjourney novel that was granted a registered copyright, you certainly cannot. The author would be liable to sue you for violating his derivative rights, and because he has a *registered* copyright he can sue you for a lot more money than if he had not registered his copyright.

*""Images generated by AI, chosen by AI, and organized by AI would not meet the current standard for holding a copyright.""*

According to what?",2022-10-25 15:30:31
Comment,1,itrgk02,,0,1666726228.0,Okay this is Brilliant but the only thing I would like to have that is in shivam's colab is the save steps and a way to know were the training started to fail like maybe rendering and saving every 200 steps and adding a way to resume the training https://i.imgur.com/pOT39Eq.png,2022-10-25 15:30:28
Comment,-1,itrgjtq,,0,1666726226.0,"Setting up dreambooth on windows is literally the easiest thing.
I've been using this https://github.com/ShivamShrirao/diffusers/tree/main/examples/dreambooth which btw, is the repo they are trying to integrate, for weeks already.

It kinda seems like the guy working on this fork is a bit incompetent to take this long to make it work.",2022-10-25 15:30:26
Comment,4,itrghu3,,0,1666726206.0,"No, no, nonono.  That's the last argument I'd make, most especially because it obviously isn't there.

If I argued that the AI was sentient, then at best I would share the copyright with it, and that makes things way more messy.

My point is that AI is a tool that is just doing what artists have ALWAYS done.  Sure, it does it faster and, for many people, better, than they could by hand.. But that's what tools are -for-.   

If you're going to claim that AI art is infringing, then you have to open the door for one artist to try to sue another over infringing on their style. Good luck with that.",2022-10-25 15:30:06
Comment,0,itrgd91,,0,1666726158.0,Shutter stock is interpreting copyright in a way that they need to protect their business.. there is no precedent for AI generated art as being a copy… it is arguably more akin to an artist imitating or being inspired by another persons work.. it might be derivative but that’s not an easy case to make unless it’s clearly plagiarism.. unless someone has heard of a recent court case that sets precedence here..,2022-10-25 15:29:18
